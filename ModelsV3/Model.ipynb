{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0f53cf5f",
   "metadata": {},
   "source": [
    "ComputedDataV2/ModelPerformance/nn_modelV2.pth: 這裡是增加肇因後的模型表現<br/>\n",
    "ComputedDataV2/ModelPerformance/nn_modelV3.pth: 這裡是增加三次交互的模型表現<br/>\n",
    "ComputedDataV2/ModelPerformance/nn_modelV4.pth: 這裡只考慮二次交互並指定人車路的表現<br/>\n",
    "ComputedDataV2/ModelPerformance/nn_modelV5.pth: 做refit，考慮所有二三維但各取20，目前存到v6篩選的版本<br/>\n",
    "ComputedDataV2/ModelPerformance/nn_modelV6.pth: Refit V3內容<br/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "274c1fac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "current_dir = os.getcwd()\n",
    "parent_dir = os.path.dirname(current_dir)\n",
    "analyze_path = os.path.join(parent_dir, \"utils\")\n",
    "\n",
    "os.chdir(analyze_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ba53b21c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['font.family'] = ['Arial Unicode Ms']\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
    "from utils_model import eval_loop, to_tensors, model_preprocess, print_results, get_importance\n",
    "\n",
    "from utils import read_data, read_taiwan_specific\n",
    "from config import cause_mapping, countycity_dct\n",
    "from config_new import for_poly, group_translation\n",
    "\n",
    "version = \"V5\"\n",
    "computeddata = 'ComputedDataV2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07b971db",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_data = read_data()\n",
    "taiwan, grid_filter = read_taiwan_specific(read_grid=True)\n",
    "\n",
    "def map_cause(cause):\n",
    "    for category, causes in cause_mapping.items():\n",
    "        if cause in causes:\n",
    "            return category\n",
    "    return \"Unknown\"\n",
    "\n",
    "combined_data[\"cause_group\"] = combined_data[\"肇因研判子類別名稱-主要\"].apply(map_cause)\n",
    "combined_data['cause_group'].value_counts()\n",
    "\n",
    "all_features_df = pd.read_csv(f\"../{computeddata}/ForModel/all_featuresV2.csv\")\n",
    "X_train, X_test, y_train, y_test, X_resampled_test, y_resampled_test, le =\\\n",
    "     model_preprocess(grid_filter, all_features_df, for_poly=for_poly, dim='mixed')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb144220",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9d5694c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid_lr = {\n",
    "    'penalty': ['elasticnet'],\n",
    "    'solver': ['saga'],\n",
    "    'l1_ratio': [0.1, 0.5, 0.9],\n",
    "    'C': [0.01, 0.1, 1, 10]\n",
    "}\n",
    "\n",
    "param_grid_rf = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [None, 10, 20],\n",
    "    'min_samples_leaf': [1, 2, 5]\n",
    "}\n",
    "\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2985a56a",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression(\n",
    "        penalty='elasticnet', solver='saga', l1_ratio=0.5,\n",
    "        class_weight='balanced', max_iter=1000, \n",
    "        random_state=42, \n",
    "        multi_class='multinomial',\n",
    "        n_jobs=-1\n",
    "    )\n",
    "rf = RandomForestClassifier(\n",
    "        n_estimators=300, max_depth=None, min_samples_leaf=1,\n",
    "        class_weight='balanced', n_jobs=-1, random_state=42,\n",
    "    )\n",
    "\n",
    "# for name, clf in [('Logistic', lr), ('RandomForest', rf)]:\n",
    "#     scores = cross_val_score(clf, X_train, y_train, cv=cv, n_jobs=-1, scoring='roc_auc')\n",
    "#     print(f'{name} CV ROC AUC: {scores.mean():.3f} ± {scores.std():.3f}')\n",
    "\n",
    "lr.fit(X_train, y_train)\n",
    "rf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0221e47b",
   "metadata": {},
   "outputs": [],
   "source": [
    "proba_test_lr = lr.predict_proba(X_resampled_test)\n",
    "proba_test_rf = rf.predict_proba(X_resampled_test)\n",
    "\n",
    "print_results(proba_test_lr, le.classes_, y_resampled_test)\n",
    "print_results(proba_test_rf, le.classes_, y_resampled_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a4c5164",
   "metadata": {},
   "outputs": [],
   "source": [
    "importance_rf, importance_grouped_rf = get_importance(rf, X_train)\n",
    "importance_lr, importance_grouped_lr = get_importance(lr, X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "366c11ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame.from_dict(importance_lr, orient='index', columns=['importance', 'odds_ratio'])\n",
    "df_sorted = df.sort_values(by='importance', ascending=False)\n",
    "df_sorted"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11d9ea72",
   "metadata": {},
   "source": [
    "## Re fit for only important features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e107c7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 這裡寫死是因為V3/V6是完整的三維特徵版本\n",
    "lr = joblib.load(f'../{computeddata}/ModelPerformance/lr_modelV6.pkl')\n",
    "rf = joblib.load(f'../{computeddata}/ModelPerformance/rf_modelV6.pkl')\n",
    "\n",
    "feature_order = lr.feature_names_in_\n",
    "X_sorted = X_resampled_test.reindex(columns=feature_order, fill_value=0)\n",
    "\n",
    "importance_lr_dict, _ = get_importance(lr, X_sorted)\n",
    "df_lr_ranked = pd.DataFrame.from_dict(importance_lr_dict, orient='index', columns=['score', 'exp_score'])\n",
    "df_lr_ranked['abs_score'] = df_lr_ranked['score'].abs()\n",
    "importance_rf_dict, _ = get_importance(rf, X_sorted)\n",
    "df_rf_ranked = pd.DataFrame.from_dict(importance_rf_dict, orient='index', columns=['score', 'exp_score'])\n",
    "df_rf_ranked['abs_score'] = df_rf_ranked['score'].abs()\n",
    "\n",
    "def get_dimension(feature_name):\n",
    "    x_count = feature_name.count(' x ')\n",
    "    if x_count == 0: return 1\n",
    "    if x_count == 1: return 2 \n",
    "    if x_count == 2: return 3\n",
    "    return 0\n",
    "\n",
    "df_lr_ranked['dimension'] = df_lr_ranked.index.map(get_dimension)\n",
    "df_rf_ranked['dimension'] = df_rf_ranked.index.map(get_dimension)\n",
    "\n",
    "lr_dim1 = df_lr_ranked[df_lr_ranked['dimension'] == 1].index.tolist()\n",
    "lr_dim2 = df_lr_ranked[df_lr_ranked['dimension'] == 2].sort_values('abs_score', ascending=False).head(20).index.tolist()\n",
    "lr_dim3 = df_lr_ranked[df_lr_ranked['dimension'] == 3].sort_values('abs_score', ascending=False).head(20).index.tolist()\n",
    "rf_dim1 = df_rf_ranked[df_rf_ranked['dimension'] == 1].index.tolist()\n",
    "rf_dim2 = df_rf_ranked[df_rf_ranked['dimension'] == 2].sort_values('abs_score', ascending=False).head(20).index.tolist()\n",
    "rf_dim3 = df_rf_ranked[df_rf_ranked['dimension'] == 3].sort_values('abs_score', ascending=False).head(20).index.tolist()\n",
    "\n",
    "final_dim1 = list(set(lr_dim1 + rf_dim1))\n",
    "final_dim2 = list(set(lr_dim2 + rf_dim2))\n",
    "final_dim3 = list(set(lr_dim3 + rf_dim3))\n",
    "final_feature_list = final_dim1 + final_dim2 + final_dim3\n",
    "\n",
    "print(f\"原始特徵保留: {len(final_dim1)} 個\")\n",
    "print(f\"二維特徵保留: {len(final_dim2)} 個 (LR與RF聯集)\")\n",
    "print(f\"三維特徵保留: {len(final_dim3)} 個 (LR與RF聯集)\")\n",
    "print(f\"最終模型特徵總數: {len(final_feature_list)} 個\")\n",
    "\n",
    "print(\"top 3 way\")\n",
    "print(df_lr_ranked[df_lr_ranked['dimension'] == 3].sort_values('abs_score', ascending=False).head(5).index.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e11a8ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_refined = X_train[final_feature_list]\n",
    "X_test_refined = X_resampled_test[final_feature_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afc5808b",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid_lr = {\n",
    "    # 'C': [0.1, 1, 10, 100], \n",
    "    'C': [100], \n",
    "    'l1_ratio': [0.9]\n",
    "}\n",
    "\n",
    "lr_refined = LogisticRegression(\n",
    "    penalty='elasticnet', solver='saga', \n",
    "    class_weight='balanced', max_iter=1000, \n",
    "    random_state=42, n_jobs=-1\n",
    ")\n",
    "\n",
    "grid_lr = GridSearchCV(lr_refined, param_grid_lr, cv=5, scoring='roc_auc', n_jobs=-1)\n",
    "grid_lr.fit(X_train_refined, y_train)\n",
    "\n",
    "best_lr_model = grid_lr.best_estimator_\n",
    "print(f\"LR 最佳參數: {grid_lr.best_params_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3ed8be3",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid_rf = {\n",
    "    'n_estimators': [300],\n",
    "    # 'max_depth': [10, 20],\n",
    "    'max_depth': [20],\n",
    "    'min_samples_leaf': [4]\n",
    "}\n",
    "\n",
    "rf_refined = RandomForestClassifier(class_weight='balanced', random_state=42, n_jobs=-1)\n",
    "\n",
    "grid_rf = GridSearchCV(rf_refined, param_grid_rf, cv=5, scoring='roc_auc', n_jobs=-1)\n",
    "grid_rf.fit(X_train_refined, y_train)\n",
    "\n",
    "best_rf_model = grid_rf.best_estimator_\n",
    "print(f\"RF 最佳參數: {grid_rf.best_params_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e10efb29",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_refined"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea862fa7",
   "metadata": {},
   "source": [
    "### Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5695f787",
   "metadata": {},
   "outputs": [],
   "source": [
    "# joblib.dump(best_lr_model, f'../{computeddata}/ModelPerformance/lr_model{version}.pkl')\n",
    "# joblib.dump(best_rf_model, f'../{computeddata}/ModelPerformance/rf_model{version}.pkl')\n",
    "\n",
    "# load model\n",
    "best_lr_model = joblib.load(f'../{computeddata}/ModelPerformance/lr_model{version}.pkl')\n",
    "best_rf_model = joblib.load(f'../{computeddata}/ModelPerformance/rf_model{version}.pkl')\n",
    "\n",
    "model_features = best_lr_model.feature_names_in_\n",
    "X_test_refined = X_test_refined.reindex(columns=model_features, fill_value=0)\n",
    "\n",
    "proba_test_lr = best_lr_model.predict_proba(X_test_refined)\n",
    "proba_test_rf = best_rf_model.predict_proba(X_test_refined)\n",
    "y_pred_lr = np.argmax(proba_test_lr, axis=1)\n",
    "y_pred_rf = np.argmax(proba_test_rf, axis=1)\n",
    "\n",
    "print_results(proba_test_lr, le.classes_, y_resampled_test)\n",
    "print_results(proba_test_rf, le.classes_, y_resampled_test)\n",
    "\n",
    "X_train_refined = X_train_refined.reindex(columns=model_features, fill_value=0)\n",
    "\n",
    "importance_rf, importance_grouped_rf = get_importance(best_rf_model, X_train_refined)\n",
    "importance_lr, importance_grouped_lr = get_importance(best_lr_model, X_train_refined)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39800ee0",
   "metadata": {},
   "source": [
    "## Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a61d662",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Neural Network\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "# INPUT_DIM = X_resampled_test.shape[1]\n",
    "INPUT_DIM = X_test_refined.shape[1]\n",
    "NUM_CLASSES = 2\n",
    "\n",
    "class BinaryMLP(nn.Module):\n",
    "    def __init__(self, in_dim=INPUT_DIM, num_classes=NUM_CLASSES, drop=0.1):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(in_dim, 1024),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(drop),\n",
    "            nn.Linear(1024, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(drop),\n",
    "            nn.Linear(512, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(drop),\n",
    "            nn.Linear(256, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(drop),\n",
    "            nn.Linear(128, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(drop),\n",
    "            nn.Linear(64, num_classes)  # logits\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.net(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "832d54e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# refit version\n",
    "X_train_nn, X_val_nn, y_train_nn, y_val_nn = train_test_split(\n",
    "    X_train_refined, y_train, test_size=0.2, stratify=y_train, random_state=42\n",
    ")   \n",
    "\n",
    "X_train_t, y_train_t = to_tensors(X_train_nn, y_train_nn)\n",
    "X_val_t, y_val_t = to_tensors(X_val_nn, y_val_nn)\n",
    "X_test_t, y_test_t = to_tensors(X_test_refined, y_resampled_test)\n",
    "\n",
    "train_loader = DataLoader(TensorDataset(X_train_t, y_train_t), batch_size=256, shuffle=True, drop_last=False)\n",
    "val_loader = DataLoader(TensorDataset(X_val_t, y_val_t), batch_size=512, shuffle=False)\n",
    "test_loader = DataLoader(TensorDataset(X_test_t, y_test_t), batch_size=512, shuffle=False)\n",
    "\n",
    "model = BinaryMLP().to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "best_val = -np.inf\n",
    "patience = 5\n",
    "wait = 0\n",
    "epochs = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42af0f99",
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(1, epochs+1):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for xb, yb in train_loader:\n",
    "        xb, yb = xb.to(device), yb.to(device)\n",
    "        optimizer.zero_grad(set_to_none=True)\n",
    "        logits = model(xb)\n",
    "        loss = criterion(logits, yb)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item() * xb.size(0)\n",
    "\n",
    "    train_loss = total_loss / len(train_loader.dataset)\n",
    "    val_metrics = eval_loop(model, val_loader, le)\n",
    "    print(f'Epoch {epoch:02d}/{epochs} | loss {train_loss:.4f} | '\n",
    "          f'val_acc {val_metrics[\"acc\"]:.3f} | val_f1 {val_metrics[\"f1\"]:.3f} | val_auc {val_metrics[\"auc\"]:.3f}')\n",
    "\n",
    "    score_for_early = val_metrics[\"auc\"]\n",
    "    if score_for_early > best_val:\n",
    "        best_val = score_for_early\n",
    "        wait = 0\n",
    "        # torch.save(model.state_dict(), 'best_model.pt')\n",
    "    else:\n",
    "        wait += 1\n",
    "        if wait >= patience:\n",
    "            print('Early stopping.')\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4822f09c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save(model.state_dict(), f'../{computeddata}/ModelPerformance/nn_model{version}.pth')\n",
    "\n",
    "model = BinaryMLP().to(device)\n",
    "model.load_state_dict(torch.load(f'../{computeddata}/ModelPerformance/nn_model{version}.pth'))\n",
    "\n",
    "test_metrics = eval_loop(model, test_loader, le)\n",
    "print(test_metrics['report'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "969150fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_refined = X_train[final_feature_list]\n",
    "X_test_refined = X_resampled_test[final_feature_list]\n",
    "X_test_r = X_test[final_feature_list]\n",
    "\n",
    "from utils_model import build_groups_from_prefix, build_groups_with_interactions, build_pair_interaction_groups, PI_ML, PI_NN\n",
    "\n",
    "groups = build_groups_with_interactions(X_test_refined.columns)\n",
    "\n",
    "print('lr')\n",
    "base_lr, perm_lr = PI_ML(best_lr_model, X_test_r, y_test, groups=groups, n_repeats=30)\n",
    "print('rf') \n",
    "base_rf, perm_rf = PI_ML(best_rf_model, X_test_r, y_test, groups=groups, n_repeats=30)\n",
    "print('nn')\n",
    "base_nn, perm_nn = PI_NN(model, X_test_r, y_test, groups=groups, n_repeats=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d675f5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils_model import build_groups_from_prefix, build_groups_with_interactions, build_pair_interaction_groups, PI_ML, PI_NN\n",
    "\n",
    "groups = build_groups_with_interactions(X_test.columns)\n",
    "\n",
    "print('lr')\n",
    "base_lr, perm_lr = PI_ML(lr, X_test, y_test, groups=groups, n_repeats=10)\n",
    "print('rf') \n",
    "base_rf, perm_rf = PI_ML(rf, X_test, y_test, groups=groups, n_repeats=10)\n",
    "print('nn')\n",
    "base_nn, perm_nn = PI_NN(model, X_test, y_test, groups=groups, n_repeats=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b102470a",
   "metadata": {},
   "outputs": [],
   "source": [
    "perm_lr.to_csv(f'../{computeddata}/Permutation/perm_lr{version}.csv')\n",
    "perm_rf.to_csv(f'../{computeddata}/Permutation/perm_rf{version}.csv')\n",
    "perm_nn.to_csv(f'../{computeddata}/Permutation/perm_nn{version}.csv')\n",
    "\n",
    "perm_lr = pd.read_csv(f'../{computeddata}/Permutation/perm_lr{version}.csv')\n",
    "perm_rf = pd.read_csv(f'../{computeddata}/Permutation/perm_rf{version}.csv')\n",
    "perm_nn = pd.read_csv(f'../{computeddata}/Permutation/perm_nn{version}.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99c5f188",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined = pd.concat([\n",
    "    perm_lr.assign(model='LR'),\n",
    "    # perm_rf.assign(model='RF'),\n",
    "    # perm_nn.assign(model='NN')\n",
    "], ignore_index=True)\n",
    "\n",
    "combined[\"group\"] = combined[\"group\"].map(group_translation)\n",
    "\n",
    "order = (combined.groupby('group')['importance'].mean().sort_values(ascending=True).index.tolist())\n",
    "ypos = np.arange(len(order))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ec1a035",
   "metadata": {},
   "outputs": [],
   "source": [
    "triples = [\n",
    "    (perm_lr, 'lr'), \n",
    "    (perm_rf, 'rf'), \n",
    "    (perm_nn, 'nn')\n",
    "    ]\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "for perm_df_i, name in triples:\n",
    "    perm_df_i[\"group\"] = perm_df_i[\"group\"].map(group_translation)\n",
    "    d = (perm_df_i.set_index('group').reindex(order)) # 用統一群組順序對齊\n",
    "    plt.errorbar(\n",
    "        d['importance'],\n",
    "        (ypos),\n",
    "        xerr=d['std'],\n",
    "        fmt='o',\n",
    "        linewidth=2,\n",
    "        capsize=5,\n",
    "        label=name\n",
    "    )\n",
    "\n",
    "plt.yticks(ypos, order)\n",
    "plt.axvline(0.0, linestyle='--', linewidth=1)\n",
    "plt.xlabel('Permutation importance')\n",
    "plt.ylabel('Group')\n",
    "plt.title('Permutation importance (LR / RF / NN)')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "435b038f",
   "metadata": {},
   "source": [
    "# Hitrate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2cede9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils_model import metrics_bin, hitrate_data\n",
    "\n",
    "hitrate_lr = hitrate_data(X_resampled_test, y_resampled_test, y_pred_lr)\n",
    "hitrate_rf = hitrate_data(X_resampled_test, y_resampled_test, y_pred_rf)\n",
    "hitrate_nn = hitrate_data(X_resampled_test, y_resampled_test, test_metrics['pred_y'])\n",
    "\n",
    "hitrate_lr['county'] = hitrate_lr['county'].map(countycity_dct)\n",
    "hitrate_rf['county'] = hitrate_rf['county'].map(countycity_dct)\n",
    "hitrate_nn['county'] = hitrate_nn['county'].map(countycity_dct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e452498",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {\n",
    "    'LR': hitrate_lr.copy(),\n",
    "    'RF': hitrate_rf.copy(),\n",
    "    'NN': hitrate_nn.copy(),\n",
    "}\n",
    "order = (results['LR'].sort_values('f1', ascending=False)['county']).tolist()\n",
    "\n",
    "metrics = ['precision', 'recall', 'accuracy', 'f1']\n",
    "plt.figure(figsize=(16, 10))\n",
    "\n",
    "for i, met in enumerate(metrics, 1):\n",
    "    ax = plt.subplot(2, 2, i)\n",
    "    pos = np.arange(len(order))\n",
    "    width = 0.25\n",
    "    for j, (name, df) in enumerate(results.items()):\n",
    "        d = df.set_index('county').reindex(order)\n",
    "        ax.bar(pos + (j-1)*width, d[met].values, width=width, label=name)\n",
    "    ax.set_title(met)\n",
    "    ax.set_xticks(pos)\n",
    "    ax.set_xticklabels(order, rotation=45, ha='right')\n",
    "    if i == 2:\n",
    "        ax.legend(loc='upper right')\n",
    "    ax.set_ylim(0, 1)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50cf4369",
   "metadata": {},
   "outputs": [],
   "source": [
    "m_lr = metrics_bin(y_resampled_test, y_pred_lr)\n",
    "m_rf = metrics_bin(y_resampled_test, y_pred_rf)\n",
    "m_nn = metrics_bin(y_resampled_test, test_metrics['pred_y'])\n",
    "\n",
    "df = pd.DataFrame([m_lr, m_rf, m_nn], index=['LR','RF','NN'])\n",
    "metrics = ['precision', 'recall', 'f1', 'accuracy']\n",
    "df = df[metrics]\n",
    "\n",
    "plt.figure(figsize=(9, 5))\n",
    "x = np.arange(len(metrics))\n",
    "width = 0.25\n",
    "\n",
    "for i, model in enumerate(df.index):\n",
    "    plt.bar(x + (i-1)*width, df.loc[model].values, width=width, label=model)\n",
    "\n",
    "plt.xticks(x, metrics)\n",
    "plt.ylim(0, 1)\n",
    "plt.ylabel('Score')\n",
    "plt.title('Overall Metrics on Resampled Test')\n",
    "plt.legend(loc='upper right')\n",
    "\n",
    "for i, model in enumerate(df.index):\n",
    "    vals = df.loc[model].values\n",
    "    for xi, v in zip(x + (i-1)*width, vals):\n",
    "        plt.text(xi, v + 0.01, f'{v:.2f}', ha='center', va='bottom', fontsize=9)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d28d8c2",
   "metadata": {},
   "source": [
    "Start Analyze importance_lr based on te concept:\n",
    "- human behaviour vs car\n",
    "- car vs road design\n",
    "- road design vs human behavour"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c653dcc5",
   "metadata": {},
   "source": [
    "### Car vs Road\n",
    "This is only for model with 2 interaction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70acdd1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils_model_analyze import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78a0f5be",
   "metadata": {},
   "outputs": [],
   "source": [
    "structured_cause = car_vs_road(importance_lr)\n",
    "structured_cause = pd.DataFrame(structured_cause)\n",
    "structured_cause = structured_cause[~structured_cause.index.str.contains('車輛撞擊')]\n",
    "\n",
    "plot_interaction('車種', structured_cause, filter_val=10, top_k=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acb50762",
   "metadata": {},
   "source": [
    "### Human vs Road"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aedf9e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "structured_cause = human_vs_road(importance_lr)\n",
    "structured_cause = pd.DataFrame(structured_cause)\n",
    "structured_cause = structured_cause[~structured_cause.index.str.contains('車種')]\n",
    "structured_cause = structured_cause[~structured_cause.index.str.contains('車輛')]\n",
    "\n",
    "plot_interaction('cause-group', structured_cause, filter_val=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70cdaffa",
   "metadata": {},
   "source": [
    "### Human vs Car"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f12e53d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "structured_cause = human_vs_car(importance_lr)\n",
    "structured_cause = pd.DataFrame(structured_cause)\n",
    "\n",
    "plot_interaction('cause-group', structured_cause, filter_val=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e007a45c",
   "metadata": {},
   "source": [
    "## This is only for model with more than 2 interaction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebb6483d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75f0b24a",
   "metadata": {},
   "outputs": [],
   "source": [
    "important_groups = []\n",
    "for k, v in importance_lr.items():\n",
    "    if v[1] > 1:\n",
    "        important_groups.append((k, v))\n",
    "\n",
    "df = pd.DataFrame(important_groups, columns=['feature_name', 'scores'])\n",
    "df['importance'] = df['scores'].apply(lambda x: x[0])\n",
    "df['odds_ratio'] = df['scores'].apply(lambda x: x[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63859b22",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_interaction(row):\n",
    "    parts = row.split(' x ')\n",
    "    road, vehicle, person = \"無\", \"無\", \"無\"\n",
    "    \n",
    "    for p in parts:\n",
    "        p_clean = p.replace('_mean', '')\n",
    "        \n",
    "        if 'county' in p_clean:\n",
    "            # county_臺北市 -> 臺北市\n",
    "            road = p_clean.split('_')[-1]\n",
    "            \n",
    "        # 只改POI\n",
    "        elif 'count' in p_clean:\n",
    "            if 'parkinglot' in p_clean: road = '停車場密度'\n",
    "            elif 'youbike' in p_clean: road = 'YouBike密度'\n",
    "            elif 'mrt' in p_clean: road = '捷運密度'\n",
    "            else: road = p_clean\n",
    "\n",
    "        elif '速限' in p_clean:\n",
    "            road = '速限'\n",
    "\n",
    "        # 道路\n",
    "        # elif any(x in p_clean for x in ['道路', '號誌', '路面', '障礙', '事故類型']):\n",
    "        #     if '_' in p_clean:\n",
    "        #         road = p_clean.split('_')[-1] # 取底線後的值\n",
    "        #     else:\n",
    "        #         road = p_clean\n",
    "\n",
    "        elif any(x in p_clean for x in ['道路', '號誌', '路面', '障礙', '事故類型', '車道', '設施']):\n",
    "            val = p_clean.split('_')[-1] if '_' in p_clean else p_clean\n",
    "            \n",
    "            # \"有\" 或 \"無\" 有包含多種分向設施\n",
    "            if val in ['有', '無']:\n",
    "                # 找出前綴 (例如 \"路面邊線名稱\")\n",
    "                prefix = p_clean.split('_')[0]\n",
    "                # 簡化前綴 (只取最後幾個字，例如 \"路面邊線\")\n",
    "                simple_prefix = prefix\n",
    "                if '名稱' in prefix: simple_prefix = prefix.replace('名稱', '').replace('大類別', '')\n",
    "                if '-' in simple_prefix: simple_prefix = simple_prefix.split('-')[-1]\n",
    "                \n",
    "                road = f\"{val}{simple_prefix}\"\n",
    "            else:\n",
    "                road = val\n",
    "\n",
    "        # 車\n",
    "        elif any(x in p_clean for x in ['車種', '撞擊', '當事者']):\n",
    "            if '_' in p_clean:\n",
    "                vehicle = p_clean.split('_')[-1]\n",
    "            else:\n",
    "                vehicle = p_clean\n",
    "\n",
    "        # 人\n",
    "        elif 'cause' in p_clean:\n",
    "             if '_' in p_clean:\n",
    "                person = p_clean.split('_')[-1]\n",
    "             else:\n",
    "                person = p_clean\n",
    "                \n",
    "    dim = len(parts)\n",
    "    return pd.Series([road, vehicle, person, dim])\n",
    "\n",
    "df[['Road', 'Vehicle', 'Person', 'Dimension']] = df['feature_name'].apply(parse_interaction)\n",
    "# df = df.replace(\"機車\", \"機車與自行車\")\n",
    "# df = df.replace(\"慢車\", \"機車與自行車\")\n",
    "# '機車', '慢車', \n",
    "df = df[~df['Vehicle'].isin(['汽車', '機車與自行車'])]\n",
    "df = df[~df['Road'].str[2].isin(['市', '縣'])]\n",
    "df = df[~((df['Vehicle'] == '人') & (df['Road'] == '車與車'))] # 移除異常\n",
    "df = df[(df['Road'] != '車與車') & (df['Road'] != '人與車')] # 雖然子類別也是道路型態，但會誤導\n",
    "# df = df.head(30)\n",
    "\n",
    "global_min = 0  \n",
    "global_max = df['importance'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64c2deb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "\n",
    "df_3 = df[df['Dimension'] == 3].head(30)\n",
    "df_plot = df_3.copy()\n",
    "\n",
    "df_plot = df_plot.sort_values('importance', ascending=False)\n",
    "fig_parcats = px.parallel_categories(\n",
    "    df_plot, \n",
    "    dimensions=['Road', 'Vehicle', 'Person'],\n",
    "    color=\"importance\",\n",
    "    color_continuous_scale=px.colors.sequential.Inferno,\n",
    "    labels={'Road':'道路設計', 'Vehicle':'車種', 'Person':'肇因'},\n",
    "    range_color=[global_min, global_max]\n",
    ")\n",
    "\n",
    "fig_parcats.update_layout(\n",
    "    title=\"三維交互作用圖\",\n",
    "    height=800,\n",
    "    width=1500\n",
    ")\n",
    "\n",
    "fig_parcats.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "265629d4",
   "metadata": {},
   "source": [
    "# 2 Way interaction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9f7897e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parallel_categories_plot(df_plot, dimensions_dct):\n",
    "    df_plot = df_plot.sort_values('importance', ascending=False)\n",
    "    fig_parcats = px.parallel_categories(\n",
    "        df_plot, \n",
    "        dimensions=dimensions_dct.keys(),\n",
    "        color=\"importance\",\n",
    "        color_continuous_scale=px.colors.sequential.Inferno,\n",
    "        labels=dimensions_dct,\n",
    "        range_color=[global_min, global_max]\n",
    "    )\n",
    "\n",
    "    fig_parcats.update_layout(\n",
    "        title=\"二維交互作用圖\",\n",
    "        height=800,\n",
    "        width=1500\n",
    "    )\n",
    "\n",
    "    fig_parcats.show()\n",
    "\n",
    "df_cause_road = df[(df['Vehicle'] == '無') & (df['Person'] != '無') & (df['Road'] != '無')].head(30).copy()\n",
    "df_cause_road['Interaction'] = '人 vs 路'\n",
    "df_car_road = df[(df['Vehicle'] != '無') & (df['Person'] == '無') & (df['Road'] != '無')].head(30).copy()\n",
    "df_car_road['Interaction'] = '車 vs 路'\n",
    "df_human_car = df[(df['Vehicle'] != '無') & (df['Person'] != '無') & (df['Road'] == '無')].head(30).copy()\n",
    "df_human_car['Interaction'] = '人 vs 車'\n",
    "\n",
    "df_combined = pd.concat([df_cause_road, df_car_road, df_human_car])\n",
    "# df_combined = df_combined[df_combined['importance'] > 0.001]\n",
    "\n",
    "df_combined = df_combined.sort_values('importance', ascending=False)\n",
    "\n",
    "dims = ['Interaction', 'Road', 'Vehicle', 'Person']\n",
    "labels_map = {'Interaction': '交互類型', 'Road':'道路設計', 'Vehicle':'車種', 'Person':'肇因'}\n",
    "\n",
    "fig_combined = px.parallel_categories(\n",
    "    df_combined, \n",
    "    dimensions=dims,\n",
    "    color=\"importance\",\n",
    "    color_continuous_scale=px.colors.sequential.Inferno,\n",
    "    labels=labels_map,\n",
    "    range_color=[global_min, global_max]\n",
    ")\n",
    "\n",
    "fig_combined.update_layout(\n",
    "    title=\"二維交互作用圖\",\n",
    "    height=900,\n",
    "    width=1600\n",
    ")\n",
    "\n",
    "fig_combined.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f163233f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(combined_data['車輛撞擊部位大類別名稱-最初'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b91fc016",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_data[(combined_data['車道劃分設施-分道設施-快車道或一般車道間名稱'] == '禁止變換車道線(無標記)') & \n",
    "              (combined_data['車輛撞擊部位大類別名稱-最初'] == '機車與自行車') &\n",
    "              (combined_data['cause_group'] == 'Posture') ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20fc4d06",
   "metadata": {},
   "outputs": [],
   "source": [
    "col_name = '車道劃分設施-分道設施-快車道或一般車道間名稱_禁止變換車道線(無標記) x 車輛撞擊部位大類別名稱-最初_機車與自行車 x cause-group_Posture'\n",
    "a = X_train_refined[[col_name]]\n",
    "b = pd.concat([a, y_train], axis=1)\n",
    "\n",
    "b[col_name] = b[col_name].apply(lambda x: '有' if x > 0 else '無')\n",
    "b.value_counts()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ST-RTA",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
