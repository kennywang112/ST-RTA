{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0047e98c",
   "metadata": {},
   "source": [
    "This file is to calculate EHSA, based on the concept [here](https://pro.arcgis.com/en/pro-app/latest/tool-reference/space-time-pattern-mining/emerginghotspots.htm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4a761f35",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "current_dir = os.getcwd()\n",
    "parent_dir = os.path.dirname(current_dir)\n",
    "analyze_path = os.path.join(parent_dir, \"utils\")\n",
    "\n",
    "os.chdir(analyze_path)\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "from utils import get_grid, read_data, read_taiwan_specific\n",
    "\n",
    "combined_data = read_data()\n",
    "taiwan, grid_filter = read_taiwan_specific()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c8eb4274",
   "metadata": {},
   "outputs": [],
   "source": [
    "hex_grid_full = pd.read_csv(\"../ComputedDataV7/Grid/grid_data_區級篩選.csv\")\n",
    "import ast\n",
    "from shapely import wkt\n",
    "hex_grid_full['geometry'] = hex_grid_full['geometry'].apply(wkt.loads)\n",
    "hex_grid_full['accident_indices'] = hex_grid_full['accident_indices'].apply(ast.literal_eval)\n",
    "hex_grid_full = gpd.GeoDataFrame(hex_grid_full, geometry='geometry', crs='EPSG:3826')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1d440229",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   grid_id  hour  accident_count accident_indices\n",
      "0        0     0               0               []\n",
      "1        0     1               0               []\n",
      "2        0     2               0               []\n",
      "3        0     3               0               []\n",
      "4        0     4               0               []\n"
     ]
    }
   ],
   "source": [
    "grid_ehsa = hex_grid_full[['geometry', 'COUNTYNAME', 'TOWNNAME']]\n",
    "\n",
    "combined_data['hour'] = (combined_data['發生時間'] // 10000).astype(int)\n",
    "\n",
    "gdf_accidents = gpd.GeoDataFrame(\n",
    "    combined_data, \n",
    "    geometry=gpd.points_from_xy(combined_data['經度'], combined_data['緯度']),\n",
    "    crs=\"EPSG:4326\"\n",
    ").to_crs(\"EPSG:3826\")\n",
    "\n",
    "gdf_accidents = gdf_accidents.reset_index().rename(columns={'index': 'original_accident_index'})\n",
    "\n",
    "if 'grid_id' not in grid_ehsa.columns:\n",
    "    grid_ehsa = grid_ehsa.reset_index().rename(columns={'index': 'grid_id'})\n",
    "\n",
    "joined = gpd.sjoin(gdf_accidents, grid_ehsa[['grid_id', 'geometry']], how=\"left\", predicate=\"within\")\n",
    "\n",
    "joined = joined.dropna(subset=['grid_id'])\n",
    "\n",
    "st_cube = joined.groupby(['grid_id', 'hour']).agg(\n",
    "    accident_count=('original_accident_index', 'count'),\n",
    "    accident_indices=('original_accident_index', lambda x: list(x))\n",
    ").reset_index()\n",
    "\n",
    "all_grids = grid_ehsa['grid_id'].unique()\n",
    "all_hours = range(24)\n",
    "multi_index = pd.MultiIndex.from_product([all_grids, all_hours], names=['grid_id', 'hour'])\n",
    "full_st_cube = pd.DataFrame(index=multi_index).reset_index()\n",
    "\n",
    "grid_ehsa = pd.merge(full_st_cube, st_cube, on=['grid_id', 'hour'], how='left')\n",
    "\n",
    "grid_ehsa['accident_count'] = grid_ehsa['accident_count'].fillna(0).astype(int)\n",
    "grid_ehsa['accident_indices'] = grid_ehsa['accident_indices'].apply(lambda d: d if isinstance(d, list) else [])\n",
    "\n",
    "print(grid_ehsa.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "af96fbf6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/w2/_g9w5yys0f171q4qqm469z1h0000gn/T/ipykernel_13127/2106718916.py:6: FutureWarning: `use_index` defaults to False but will default to True in future. Set True/False directly to control this behavior and silence this warning\n",
      "  w = libpysal.weights.contiguity.Queen.from_dataframe(unique_grids)\n",
      "/Users/wangqiqian/opt/anaconda3/envs/ST-RTA/lib/python3.9/site-packages/libpysal/weights/weights.py:224: UserWarning: The weights matrix is not fully connected: \n",
      " There are 759 disconnected components.\n",
      " There are 35 islands with ids: 14819, 39742, 47224, 55249, 64684, 101938, 110219, 113385, 113386, 147426, 162411, 174776, 191728, 201476, 245333, 255384, 272283, 283803, 289525, 324425, 332090, 346395, 353258, 353344, 357045, 357046, 361494, 369304, 398951, 398952, 416152, 416153, 434639, 439103, 443576.\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing hour 0...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/wangqiqian/opt/anaconda3/envs/ST-RTA/lib/python3.9/site-packages/libpysal/weights/weights.py:224: UserWarning: The weights matrix is not fully connected: \n",
      " There are 759 disconnected components.\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing hour 1...\n",
      "Processing hour 2...\n",
      "Processing hour 3...\n",
      "Processing hour 4...\n",
      "Processing hour 5...\n",
      "Processing hour 6...\n",
      "Processing hour 7...\n",
      "Processing hour 8...\n",
      "Processing hour 9...\n",
      "Processing hour 10...\n",
      "Processing hour 11...\n",
      "Processing hour 12...\n",
      "Processing hour 13...\n",
      "Processing hour 14...\n",
      "Processing hour 15...\n",
      "Processing hour 16...\n",
      "Processing hour 17...\n",
      "Processing hour 18...\n",
      "Processing hour 19...\n",
      "Processing hour 20...\n",
      "Processing hour 21...\n",
      "Processing hour 22...\n",
      "Processing hour 23...\n",
      "Gi* Z-score 計算完成\n"
     ]
    }
   ],
   "source": [
    "import libpysal\n",
    "from esda.getisord import G_Local\n",
    "\n",
    "unique_grids = hex_grid_full[['geometry']]\n",
    "\n",
    "w = libpysal.weights.contiguity.Queen.from_dataframe(unique_grids)\n",
    "w.transform = 'B'\n",
    "\n",
    "grid_ehsa['gi_zscore'] = 0.0\n",
    "grid_ehsa['gi_zscore'] = grid_ehsa['gi_zscore'].astype(np.float32)\n",
    "\n",
    "for h in range(24):\n",
    "    print(f\"Processing hour {h}...\")\n",
    "    current_hour_mask = grid_ehsa['hour'] == h\n",
    "    current_hour_data = grid_ehsa[current_hour_mask].sort_values('grid_id')\n",
    "\n",
    "    y = current_hour_data['accident_count'].values.astype(np.float64)\n",
    "    \n",
    "    # permutations=0 代表只計算解析解 Z-score 不跑模擬\n",
    "    lg = G_Local(y, w, transform='B', star=True, permutations=0)\n",
    "\n",
    "    grid_ehsa.loc[current_hour_mask, 'gi_zscore'] = lg.Zs.astype(np.float32)\n",
    "\n",
    "print(\"Gi* Z-score 計算完成\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "faa37f17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "開始並行計算 450911 個網格的趨勢...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 10 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  70 tasks      | elapsed:    1.3s\n",
      "[Parallel(n_jobs=-1)]: Done 1408 tasks      | elapsed:    1.6s\n",
      "[Parallel(n_jobs=-1)]: Done 27648 tasks      | elapsed:    4.4s\n",
      "[Parallel(n_jobs=-1)]: Done 69120 tasks      | elapsed:    9.8s\n",
      "[Parallel(n_jobs=-1)]: Done 119808 tasks      | elapsed:   16.4s\n",
      "[Parallel(n_jobs=-1)]: Done 179712 tasks      | elapsed:   22.9s\n",
      "[Parallel(n_jobs=-1)]: Done 248832 tasks      | elapsed:   31.2s\n",
      "[Parallel(n_jobs=-1)]: Done 327168 tasks      | elapsed:   40.6s\n",
      "[Parallel(n_jobs=-1)]: Done 414720 tasks      | elapsed:   50.4s\n",
      "[Parallel(n_jobs=-1)]: Done 450911 out of 450911 | elapsed:   54.3s finished\n"
     ]
    }
   ],
   "source": [
    "from joblib import Parallel, delayed\n",
    "import pymannkendall as mk\n",
    "\n",
    "def parallel_mk(grid_id, values):\n",
    "    if len(np.unique(values)) < 2:\n",
    "        return grid_id, 0.0, 1.0 \n",
    "    \n",
    "    res = mk.original_test(values)\n",
    "    return grid_id, res.z, res.p\n",
    "\n",
    "grid_ehsa = grid_ehsa.sort_values(['grid_id', 'hour'])\n",
    "\n",
    "grouped_data = [(name, group['gi_zscore'].values) for name, group in grid_ehsa.groupby('grid_id')]\n",
    "\n",
    "print(f\"開始並行計算 {len(grouped_data)} 個網格的趨勢...\")\n",
    "\n",
    "results = Parallel(n_jobs=-1, verbose=5)(\n",
    "    delayed(parallel_mk)(grid_id, values) for grid_id, values in grouped_data\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "77236da1",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_ehsa.to_csv(\"../ComputedDataV7/Grid/grid_ehsa_區級篩選.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cedd9f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "trend_df = pd.DataFrame(results, columns=['grid_id', 'mk_zscore', 'mk_pvalue']).set_index('grid_id')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3ae1cda",
   "metadata": {},
   "source": [
    "## 尖峰、離峰GI分類\n",
    "這裡針對尖峰非尖峰進行分組，這是為了視覺化以及後續帶入模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "933b99bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "peak_hours = [7, 8, 17]\n",
    "# 計算每個網格在尖峰與離峰的平均集聚強度 (Gi* Z-score)\n",
    "peak_stats = grid_ehsa[grid_ehsa['hour'].isin(peak_hours)].groupby('grid_id')['gi_zscore'].mean()\n",
    "off_peak_stats = grid_ehsa[~grid_ehsa['hour'].isin(peak_hours)].groupby('grid_id')['gi_zscore'].mean()\n",
    "\n",
    "trend_df['peak_z'] = peak_stats\n",
    "trend_df['off_peak_z'] = off_peak_stats\n",
    "\n",
    "def label_st_pattern(row):\n",
    "    is_peak_hot = row['peak_z'] > 1.96\n",
    "    is_off_peak_hot = row['off_peak_z'] > 1.96\n",
    "\n",
    "    if not is_off_peak_hot and is_peak_hot:\n",
    "        return \"Emergent\"      # 離峰安全，尖峰爆發\n",
    "    elif is_off_peak_hot and is_peak_hot:\n",
    "        return \"Persistent\"    # 全天候熱點\n",
    "    elif is_off_peak_hot and not is_peak_hot:\n",
    "        return \"Dissipated\"    # 離峰危險，尖峰反而消失 (SiN)\n",
    "    else:\n",
    "        return \"Stable_Safe\"   # 持續安全\n",
    "\n",
    "trend_df['target_label'] = trend_df.apply(label_st_pattern, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f68e64c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "trend_grid = trend_df.join(hex_grid_full[['geometry', 'COUNTYNAME', 'TOWNNAME', 'num_accidents', 'accident_indices']], on='grid_id', how='left')\n",
    "# trend_grid.to_csv(\"../ComputedDataV7/Grid/trend_grid.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aadd8e84",
   "metadata": {},
   "source": [
    "## Space Time Cluster (STC)\n",
    "基於TOWN的分群"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dc3e105",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tslearn.clustering import TimeSeriesKMeans\n",
    "from tslearn.preprocessing import TimeSeriesScalerMeanVariance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a40aea2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "trend_grid = trend_grid.reset_index()\n",
    "grid_ehsa_with_town = pd.merge(grid_ehsa, trend_grid[['grid_id', 'TOWNNAME']], on='grid_id', how='inner')\n",
    "\n",
    "town_st_cube = grid_ehsa_with_town.groupby(['TOWNNAME', 'hour'])['gi_zscore'].mean().reset_index()\n",
    "\n",
    "town_matrix = town_st_cube.pivot(index='TOWNNAME', columns='hour', values='gi_zscore').fillna(0)\n",
    "\n",
    "X_town_ts = TimeSeriesScalerMeanVariance().fit_transform(town_matrix.values)\n",
    "\n",
    "n_clusters_ts = 3\n",
    "model_town_ts = TimeSeriesKMeans(n_clusters=n_clusters_ts, \n",
    "                                 metric=\"dtw\",\n",
    "                                 metric_params={\"global_constraint\": \"sakoe_chiba\", \n",
    "                                                \"sakoe_chiba_radius\": 3},\n",
    "                                 max_iter=10, \n",
    "                                 random_state=42)\n",
    "\n",
    "town_matrix['DTW_Cluster'] = model_town_ts.fit_predict(X_town_ts)\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "for cluster_id in range(n_clusters_ts):\n",
    "    cluster_data = town_matrix[town_matrix['DTW_Cluster'] == cluster_id].drop(columns=['DTW_Cluster'])\n",
    "    mean_curve = cluster_data.mean(axis=0)\n",
    "    plt.plot(mean_curve.index, mean_curve.values, label=f'Cluster {cluster_id} (n={len(cluster_data)})', linewidth=3)\n",
    "\n",
    "plt.title(\"24-Hour Accident Hotspot by Town Clusters (DTW)\", fontsize=16)\n",
    "plt.xlabel(\"Hour of Day\", fontsize=14)\n",
    "plt.ylabel(\"Average Gi* Z-score\", fontsize=14)\n",
    "plt.xticks(range(0, 24))\n",
    "plt.axvspan(7, 9, color='red', alpha=0.1, label='Morning Peak')\n",
    "plt.axvspan(17, 19, color='orange', alpha=0.1, label='Evening Peak')\n",
    "plt.legend()\n",
    "plt.grid(True, linestyle='--', alpha=0.6)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4544e60e",
   "metadata": {},
   "outputs": [],
   "source": [
    "inertias_ts = []\n",
    "K_range_ts = range(2, 11)\n",
    "\n",
    "for k in K_range_ts:\n",
    "    print(f\"計算 DTW K={k} ...\")\n",
    "    ts_km = TimeSeriesKMeans(n_clusters=k, \n",
    "                             metric=\"dtw\",\n",
    "                             metric_params={\"global_constraint\": \"sakoe_chiba\", \n",
    "                                            \"sakoe_chiba_radius\": 3},\n",
    "                             max_iter=10, \n",
    "                             random_state=42)\n",
    "    ts_km.fit(X_town_ts)\n",
    "    inertias_ts.append(ts_km.inertia_)\n",
    "\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.plot(K_range_ts, inertias_ts, marker='s', linestyle='-', color='r')\n",
    "plt.title('Elbow Method for 24-Hour (TimeSeriesKMeans DTW)', fontsize=14)\n",
    "plt.xlabel('Number of Clusters (K)', fontsize=12)\n",
    "plt.ylabel('Inertia (DTW Distance)', fontsize=12)\n",
    "plt.xticks(K_range_ts)\n",
    "plt.grid(True, linestyle=':', alpha=0.6)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00583c57",
   "metadata": {},
   "outputs": [],
   "source": [
    "dtw_cluster_df = town_matrix[['DTW_Cluster']].reset_index()\n",
    "final_grid = pd.merge(trend_grid, dtw_cluster_df, on='TOWNNAME', how='left')\n",
    "final_grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8375e71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add final_grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50b18ae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_grid.to_csv(\"../ComputedDataV7/Grid/trend_grid.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "134b5a39",
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_county_towns = final_grid.groupby(['DTW_Cluster', 'COUNTYNAME'])['TOWNNAME'].unique()\n",
    "\n",
    "clusters = sorted(final_grid['DTW_Cluster'].dropna().unique())\n",
    "\n",
    "for cluster_id in clusters:\n",
    "    print(f\"================ DTW Cluster {cluster_id} ================\")\n",
    "    county_data = cluster_county_towns[cluster_id]\n",
    "    \n",
    "    for county, towns in county_data.items():\n",
    "        print(f\" {county} (共 {len(towns)} 區):\")\n",
    "        print(f\"  {', '.join(towns)}\")\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8f6666d",
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_summary_df = final_grid.groupby(['DTW_Cluster', 'COUNTYNAME']).agg(\n",
    "    Town_Count=('TOWNNAME', 'nunique'), \n",
    "    Town_List=('TOWNNAME', lambda x: ', '.join(x.unique()))\n",
    ").reset_index()\n",
    "\n",
    "display(cluster_summary_df)\n",
    "\n",
    "# cluster_summary_df.to_csv(\"Cluster_Town_Summary.csv\", index=False, encoding=\"utf-8-sig\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8be05fbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "plt.rcParams['font.sans-serif'] = ['Microsoft JhengHei']\n",
    "# 1. 計算每個 Cluster 在各縣市的「行政區數量」\n",
    "cluster_county_matrix = final_grid.groupby(['COUNTYNAME', 'DTW_Cluster'])['TOWNNAME'].nunique().unstack(fill_value=0)\n",
    "\n",
    "# 2. 為了讓圖表更好看，我們計算「比例」 (每個縣市的行政區，有百分之幾落在各 Cluster)\n",
    "# 這樣可以避免大縣市(如新北29區)在視覺上壓過小縣市(如嘉義市2區)\n",
    "cluster_county_pct = cluster_county_matrix.div(cluster_county_matrix.sum(axis=1), axis=0) * 100\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(cluster_county_pct, annot=True, fmt=\".0f\", cmap=\"Blues\", \n",
    "            cbar_kws={'label': 'Percentage of Towns in County (%)'},\n",
    "            linewidths=0.5)\n",
    "\n",
    "plt.title(\"Spatial Distribution of DTW Clusters across Counties (%)\", fontsize=16, fontweight='bold')\n",
    "plt.xlabel(\"DTW Cluster Types\", fontsize=14)\n",
    "plt.ylabel(\"County\", fontsize=14)\n",
    "\n",
    "plt.xticks(ticks=[0.5, 1.5, 2.5], \n",
    "           labels=['Cluster 0\\n(Rural/Suburbs)', 'Cluster 1\\n(Urban Cores)', 'Cluster 2\\n(Industrial/Hubs)'], \n",
    "           fontsize=12)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ST-RTA",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
