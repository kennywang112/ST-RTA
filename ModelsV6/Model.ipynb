{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "18fec789",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "current_dir = os.getcwd()\n",
    "parent_dir = os.path.dirname(current_dir)\n",
    "analyze_path = os.path.join(parent_dir, \"utils\")\n",
    "\n",
    "os.chdir(analyze_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb3b1b67",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.metrics import classification_report, roc_auc_score\n",
    "\n",
    "import torch\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from utils_nn import BinaryMLP, train_neural_network, predict_nn\n",
    "from utils_model import model_preprocess, print_results, get_importance\n",
    "\n",
    "version = \"V1\"\n",
    "computeddata = 'ComputedDataV6'\n",
    "\n",
    "from imblearn.under_sampling import RandomUnderSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4c00a1ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/w2/_g9w5yys0f171q4qqm469z1h0000gn/T/ipykernel_48706/3769403269.py:1: DtypeWarning: Columns (7) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  final_grid_features = pd.read_csv('../ComputedDataV6/ForModel/final_grid_features.csv')\n"
     ]
    }
   ],
   "source": [
    "final_grid_features = pd.read_csv('../ComputedDataV6/ForModel/final_grid_features.csv')\n",
    "dom_cols = [c for c in final_grid_features.columns if c.endswith('_dom')]\n",
    "final_grid_features = pd.get_dummies(final_grid_features, columns=dom_cols)\n",
    "final_features = final_grid_features[final_grid_features['County_nan'] != 1]\n",
    "data = final_features.drop(columns=['COUNTYNAME', 'geometry', 'num_accidents', 'accident_indices', 'centroid', 'GiZScore', 'GiPValue', 'Speed_Max', 'Speed_Std', 'County_nan', '路面邊線_dom_有', '路面邊線_有'])\n",
    "data = data.drop(columns=[col for col in data.columns if 'ratio' in col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "04452e9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hotspot\n",
      "County_南投縣\n",
      "County_嘉義市\n",
      "County_嘉義縣\n",
      "County_基隆市\n",
      "County_宜蘭縣\n",
      "County_屏東縣\n",
      "County_彰化縣\n",
      "County_新北市\n",
      "County_新竹市\n",
      "County_新竹縣\n",
      "County_桃園市\n",
      "County_臺中市\n",
      "County_臺北市\n",
      "County_臺南市\n",
      "County_臺東縣\n",
      "County_花蓮縣\n",
      "County_苗栗縣\n",
      "County_雲林縣\n",
      "County_高雄市\n",
      "num_mrt\n",
      "num_parking\n",
      "num_youbike\n",
      "lag_num_mrt\n",
      "lag_num_parking\n",
      "lag_num_youbike\n",
      "spd_dlt_mean\n",
      "osm_road_length\n",
      "快車道或一般車道間_ent\n",
      "快慢車道間_ent\n",
      "路面邊線_ent\n",
      "分向設施大類別_ent\n",
      "事故類型及型態子類別_ent\n",
      "道路型態子類別_ent\n",
      "號誌種類_ent\n",
      "快車道或一般車道間_未繪設車道線\n",
      "快車道或一般車道間_禁止變換車道線(無標記)\n",
      "快車道或一般車道間_禁止變換車道線(附標記)\n",
      "快車道或一般車道間_車道線(無標記)\n",
      "快車道或一般車道間_車道線(附標記)\n",
      "快慢車道間_寬式快慢車道分隔島(50公分以上)\n",
      "快慢車道間_快慢車道分隔線\n",
      "快慢車道間_未繪設快慢車道分隔線\n",
      "快慢車道間_窄式快慢車道分隔島(無柵欄)\n",
      "快慢車道間_窄式快慢車道分隔島(附柵欄)\n",
      "路面邊線_無\n",
      "分向設施大類別_中央分向島\n",
      "分向設施大類別_單向禁止超車線\n",
      "分向設施大類別_無\n",
      "分向設施大類別_行車分向線\n",
      "分向設施大類別_雙向禁止超車線\n",
      "事故類型及型態子類別_佇立路邊(外)\n",
      "事故類型及型態子類別_倒車撞\n",
      "事故類型及型態子類別_側撞\n",
      "事故類型及型態子類別_其他\n",
      "事故類型及型態子類別_同向擦撞\n",
      "事故類型及型態子類別_同向通行中\n",
      "事故類型及型態子類別_在路上作業中\n",
      "事故類型及型態子類別_在路上嬉戲\n",
      "事故類型及型態子類別_對向擦撞\n",
      "事故類型及型態子類別_對向通行中\n",
      "事故類型及型態子類別_對撞\n",
      "事故類型及型態子類別_從停車後(或中)穿出\n",
      "事故類型及型態子類別_撞交通島\n",
      "事故類型及型態子類別_撞動物\n",
      "事故類型及型態子類別_撞工程施工\n",
      "事故類型及型態子類別_撞建築物\n",
      "事故類型及型態子類別_撞橋樑(橋墩)\n",
      "事故類型及型態子類別_撞號誌、標誌桿\n",
      "事故類型及型態子類別_撞護欄(樁)\n",
      "事故類型及型態子類別_撞路樹\n",
      "事故類型及型態子類別_撞電桿\n",
      "事故類型及型態子類別_撞非固定設施\n",
      "事故類型及型態子類別_暫停位置不當\n",
      "事故類型及型態子類別_正越過平交道中\n",
      "事故類型及型態子類別_穿越道路中\n",
      "事故類型及型態子類別_衝出路外\n",
      "事故類型及型態子類別_衝進路中\n",
      "事故類型及型態子類別_衝過(或撞壞)遮斷器\n",
      "事故類型及型態子類別_路上翻車、摔倒\n",
      "事故類型及型態子類別_路口交岔撞\n",
      "事故類型及型態子類別_追撞\n",
      "道路型態子類別_三岔路\n",
      "道路型態子類別_休息站或服務區\n",
      "道路型態子類別_其他\n",
      "道路型態子類別_四岔路\n",
      "道路型態子類別_圓環\n",
      "道路型態子類別_地下道\n",
      "道路型態子類別_坡路\n",
      "道路型態子類別_多岔路\n",
      "道路型態子類別_廣場\n",
      "道路型態子類別_彎曲路及附近\n",
      "道路型態子類別_有遮斷器\n",
      "道路型態子類別_橋樑\n",
      "道路型態子類別_涵洞\n",
      "道路型態子類別_直路\n",
      "道路型態子類別_隧道\n",
      "道路型態子類別_高架道路\n",
      "號誌種類_無號誌\n",
      "號誌種類_行車管制號誌\n",
      "號誌種類_行車管制號誌(附設行人專用號誌)\n",
      "號誌種類_閃光號誌\n",
      "Speed_Mean\n",
      "快車道或一般車道間_dom_未繪設車道線\n",
      "快車道或一般車道間_dom_禁止變換車道線(無標記)\n",
      "快車道或一般車道間_dom_禁止變換車道線(附標記)\n",
      "快車道或一般車道間_dom_車道線(無標記)\n",
      "快車道或一般車道間_dom_車道線(附標記)\n",
      "快慢車道間_dom_寬式快慢車道分隔島(50公分以上)\n",
      "快慢車道間_dom_快慢車道分隔線\n",
      "快慢車道間_dom_未繪設快慢車道分隔線\n",
      "快慢車道間_dom_窄式快慢車道分隔島(無柵欄)\n",
      "快慢車道間_dom_窄式快慢車道分隔島(附柵欄)\n",
      "路面邊線_dom_無\n",
      "分向設施大類別_dom_中央分向島\n",
      "分向設施大類別_dom_單向禁止超車線\n",
      "分向設施大類別_dom_無\n",
      "分向設施大類別_dom_行車分向線\n",
      "分向設施大類別_dom_雙向禁止超車線\n",
      "事故類型及型態子類別_dom_佇立路邊(外)\n",
      "事故類型及型態子類別_dom_倒車撞\n",
      "事故類型及型態子類別_dom_側撞\n",
      "事故類型及型態子類別_dom_其他\n",
      "事故類型及型態子類別_dom_同向擦撞\n",
      "事故類型及型態子類別_dom_同向通行中\n",
      "事故類型及型態子類別_dom_在路上作業中\n",
      "事故類型及型態子類別_dom_在路上嬉戲\n",
      "事故類型及型態子類別_dom_對向擦撞\n",
      "事故類型及型態子類別_dom_對向通行中\n",
      "事故類型及型態子類別_dom_對撞\n",
      "事故類型及型態子類別_dom_從停車後(或中)穿出\n",
      "事故類型及型態子類別_dom_撞交通島\n",
      "事故類型及型態子類別_dom_撞動物\n",
      "事故類型及型態子類別_dom_撞工程施工\n",
      "事故類型及型態子類別_dom_撞建築物\n",
      "事故類型及型態子類別_dom_撞橋樑(橋墩)\n",
      "事故類型及型態子類別_dom_撞號誌、標誌桿\n",
      "事故類型及型態子類別_dom_撞護欄(樁)\n",
      "事故類型及型態子類別_dom_撞路樹\n",
      "事故類型及型態子類別_dom_撞電桿\n",
      "事故類型及型態子類別_dom_撞非固定設施\n",
      "事故類型及型態子類別_dom_穿越道路中\n",
      "事故類型及型態子類別_dom_衝出路外\n",
      "事故類型及型態子類別_dom_衝進路中\n",
      "事故類型及型態子類別_dom_路上翻車、摔倒\n",
      "事故類型及型態子類別_dom_路口交岔撞\n",
      "事故類型及型態子類別_dom_追撞\n",
      "道路型態子類別_dom_三岔路\n",
      "道路型態子類別_dom_休息站或服務區\n",
      "道路型態子類別_dom_其他\n",
      "道路型態子類別_dom_四岔路\n",
      "道路型態子類別_dom_圓環\n",
      "道路型態子類別_dom_地下道\n",
      "道路型態子類別_dom_坡路\n",
      "道路型態子類別_dom_多岔路\n",
      "道路型態子類別_dom_廣場\n",
      "道路型態子類別_dom_彎曲路及附近\n",
      "道路型態子類別_dom_有遮斷器\n",
      "道路型態子類別_dom_橋樑\n",
      "道路型態子類別_dom_涵洞\n",
      "道路型態子類別_dom_直路\n",
      "道路型態子類別_dom_隧道\n",
      "道路型態子類別_dom_高架道路\n",
      "號誌種類_dom_無號誌\n",
      "號誌種類_dom_行車管制號誌\n",
      "號誌種類_dom_行車管制號誌(附設行人專用號誌)\n",
      "號誌種類_dom_閃光號誌\n"
     ]
    }
   ],
   "source": [
    "for i in data.columns:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b2d42bc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_training(\n",
    "        X_train, y_train, X_resampled_test, y_resampled_test, le, model_name, set_grid_search=True\n",
    "        ):\n",
    "    param_grid_lr = {\n",
    "        'C': [0.1, 1, 10, 100], \n",
    "        'l1_ratio': [0.1, 0.5, 0.9]\n",
    "    }\n",
    "    param_grid_rf = {\n",
    "        'n_estimators': [100, 300],\n",
    "        'max_depth': [10, 20],\n",
    "        'min_samples_leaf': [1, 4]\n",
    "    }\n",
    "\n",
    "    lr_refined = LogisticRegression(\n",
    "        penalty='elasticnet', solver='saga', \n",
    "        class_weight='balanced', max_iter=1000, \n",
    "        random_state=42, n_jobs=-1\n",
    "        )\n",
    "    rf_refined = RandomForestClassifier(\n",
    "        class_weight='balanced', random_state=42, n_jobs=-1\n",
    "        )\n",
    "\n",
    "    if set_grid_search:\n",
    "\n",
    "        grid_lr = GridSearchCV(lr_refined, param_grid_lr, cv=5, scoring='roc_auc', n_jobs=-1)\n",
    "        grid_rf = GridSearchCV(rf_refined, param_grid_rf, cv=5, scoring='roc_auc', n_jobs=-1)\n",
    "\n",
    "        grid_lr.fit(X_train, y_train)\n",
    "        lr = grid_lr.best_estimator_\n",
    "        print(f\"LR best params: {lr}\")\n",
    "        grid_rf.fit(X_train, y_train)\n",
    "        rf = grid_rf.best_estimator_\n",
    "        print(f\"RF best params: {rf}\")\n",
    "\n",
    "    else:\n",
    "        \n",
    "        lr = LogisticRegression(\n",
    "            penalty='elasticnet', solver='saga', l1_ratio=0.5,\n",
    "            class_weight='balanced', max_iter=1000, \n",
    "            random_state=42, \n",
    "            multi_class='multinomial',\n",
    "            n_jobs=-1\n",
    "        )\n",
    "        rf = RandomForestClassifier(\n",
    "            n_estimators=300, max_depth=None, min_samples_leaf=1,\n",
    "            class_weight='balanced', n_jobs=-1, random_state=42,\n",
    "        )\n",
    "        print('logistic regression training')\n",
    "        lr.fit(X_train, y_train)\n",
    "        print('random forest training')\n",
    "        rf.fit(X_train, y_train)\n",
    "\n",
    "    # nn 沒有grid search\n",
    "    nn_final = train_neural_network(\n",
    "        X_train, y_train, le=le,\n",
    "        input_dim=X_train.shape[1]\n",
    "    )\n",
    "\n",
    "    joblib.dump(lr, f'../{computeddata}/ModelPerformance/lr_model{version}_{model_name}.pkl')\n",
    "    joblib.dump(rf, f'../{computeddata}/ModelPerformance/rf_model{version}_{model_name}.pkl')\n",
    "    torch.save(nn_final.state_dict(), f'../{computeddata}/ModelPerformance/nn_model{version}_{model_name}.pt')\n",
    "    \n",
    "    proba_test_lr = lr.predict_proba(X_resampled_test)\n",
    "    proba_test_rf = rf.predict_proba(X_resampled_test)\n",
    "    proba_test_nn = predict_nn(nn_final, X_resampled_test)\n",
    "\n",
    "    print_results(proba_test_lr, le.classes_, y_resampled_test)\n",
    "    print_results(proba_test_rf, le.classes_, y_resampled_test)\n",
    "    print_results(proba_test_nn, le.classes_, y_resampled_test)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4b9b8f0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/wangqiqian/opt/anaconda3/envs/ST-RTA/lib/python3.9/site-packages/sklearn/base.py:484: FutureWarning: `BaseEstimator._check_n_features` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation._check_n_features` instead.\n",
      "  warnings.warn(\n",
      "/Users/wangqiqian/opt/anaconda3/envs/ST-RTA/lib/python3.9/site-packages/sklearn/base.py:493: FutureWarning: `BaseEstimator._check_feature_names` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation._check_feature_names` instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "y_binary = data['hotspot'].apply(lambda x: 1 if 'Hotspot' in str(x) else 0)\n",
    "X_raw = data.drop(columns=['hotspot'])\n",
    "\n",
    "X_train_raw, X_test_raw, y_train_raw, y_test_raw = train_test_split(\n",
    "    X_raw, y_binary, test_size=0.2, random_state=42, stratify=y_binary\n",
    ")\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = pd.DataFrame(scaler.fit_transform(X_train_raw), columns=X_raw.columns)\n",
    "X_test = pd.DataFrame(scaler.transform(X_test_raw), columns=X_raw.columns)\n",
    "\n",
    "y_test_series = pd.Series(y_test_raw)\n",
    "cls_counts = y_test_series.value_counts()\n",
    "min_count = cls_counts.min()\n",
    "\n",
    "rus_test = RandomUnderSampler(\n",
    "    sampling_strategy={int(c): int(min_count) for c in cls_counts.index},\n",
    "    random_state=42\n",
    ")\n",
    "X_resampled_test, y_resampled_test = rus_test.fit_resample(X_test, y_test_raw)\n",
    "\n",
    "le = LabelEncoder()\n",
    "le.fit(['Not Hotspot', 'Hotspot']) \n",
    "y_train = y_train_raw.astype(int).values\n",
    "\n",
    "model_name = \"Hotspot_Prediction_v1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "647371f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_training(\n",
    "    X_train, \n",
    "    y_train, \n",
    "    X_resampled_test, \n",
    "    y_resampled_test, \n",
    "    le, \n",
    "    model_name, \n",
    "    set_grid_search=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bbf4c2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "version = \"V1\"\n",
    "computeddata = 'ComputedDataV6'\n",
    "model_name = \"Hotspot_Prediction_v1\"\n",
    "base_path = f'../{computeddata}/ModelPerformance'\n",
    "\n",
    "lr_model = joblib.load(f'{base_path}/lr_model{version}_{model_name}.pkl')\n",
    "rf_model = joblib.load(f'{base_path}/rf_model{version}_{model_name}.pkl')\n",
    "\n",
    "device = torch.device(\"mps\") \n",
    "input_dim = X_train.shape[1]\n",
    "nn_model = BinaryMLP(in_dim=input_dim).to(device)\n",
    "nn_model.load_state_dict(torch.load(f'{base_path}/nn_model{version}_{model_name}.pt', map_location=device))\n",
    "nn_model.eval()\n",
    "\n",
    "proba_lr = lr_model.predict_proba(X_resampled_test)\n",
    "proba_rf = rf_model.predict_proba(X_resampled_test)\n",
    "proba_nn = predict_nn(nn_model, X_resampled_test)\n",
    "\n",
    "all_probas = {\n",
    "    'LR': proba_lr,\n",
    "    'RF': proba_rf,\n",
    "    'NN': proba_nn\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be9cab55",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "records = []\n",
    "classes = le.classes_ # ['Not Hotspot', 'Hotspot']\n",
    "\n",
    "for algo_name, proba in all_probas.items():\n",
    "    y_pred = np.argmax(proba, axis=1)\n",
    "    cm = confusion_matrix(y_resampled_test, y_pred)\n",
    "    tn, fp, fn, tp = cm.ravel()\n",
    "    \n",
    "    records.append({\n",
    "        'Algorithm': algo_name,\n",
    "        'Accuracy': (tp + tn) / (tp + tn + fp + fn),\n",
    "        'F1-Score': 2 * tp / (2 * tp + fp + fn),\n",
    "        'Precision': tp / (tp + fp) if (tp + fp) > 0 else 0,\n",
    "        'Recall': tp / (tp + fn) if (tp + fn) > 0 else 0\n",
    "    })\n",
    "\n",
    "df_perf = pd.DataFrame(records)\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "metrics = ['Accuracy', 'F1-Score', 'Precision', 'Recall']\n",
    "\n",
    "for i, metric in enumerate(metrics):\n",
    "    ax = axes[i//2, i%2]\n",
    "    sns.barplot(data=df_perf, x='Algorithm', y=metric, palette='viridis', ax=ax)\n",
    "    ax.set_title(f'Model {metric} Comparison')\n",
    "    ax.set_ylim(0, 1.1)\n",
    "    for container in ax.containers:\n",
    "        ax.bar_label(container, fmt='%.3f')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3adcec1a",
   "metadata": {},
   "source": [
    "## RF Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b18e7763",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.rcParams['font.family'] = ['Heiti TC']\n",
    "plt.rcParams['axes.unicode_minus'] = False "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b22cd89",
   "metadata": {},
   "outputs": [],
   "source": [
    "importances = rf_model.feature_importances_\n",
    "feature_names = X_train.columns\n",
    "\n",
    "df_imp = pd.DataFrame({\n",
    "    'Feature': feature_names,\n",
    "    'Importance': importances\n",
    "}).sort_values(by='Importance', ascending=False)\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.barplot(data=df_imp.head(15), x='Importance', y='Feature', palette='magma')\n",
    "plt.title('Top 15 Important Features for Hotspot Prediction (RF)')\n",
    "plt.xlabel('Feature Importance Score')\n",
    "plt.ylabel('Features')\n",
    "plt.grid(axis='x', linestyle='--', alpha=0.6)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a71a69e",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_coefs = lr_model.coef_[0]\n",
    "df_lr_imp = pd.DataFrame({\n",
    "    'Feature': feature_names,\n",
    "    'Coefficient': lr_coefs\n",
    "}).sort_values(by='Coefficient', ascending=False)\n",
    "\n",
    "top_bottom_features = pd.concat([df_lr_imp.head(10), df_lr_imp.tail(10)])\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "colors = ['red' if x > 0 else 'blue' for x in top_bottom_features['Coefficient']]\n",
    "sns.barplot(data=top_bottom_features, x='Coefficient', y='Feature', palette=colors)\n",
    "plt.title('Top 10 Positive & Negative Features (LR)')\n",
    "plt.axvline(0, color='black', lw=1)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ST-RTA",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
