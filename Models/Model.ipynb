{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eeb03cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "current_dir = os.getcwd()\n",
    "parent_dir = os.path.dirname(current_dir)\n",
    "analyze_path = os.path.join(parent_dir, \"utils\")\n",
    "\n",
    "os.chdir(analyze_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09d1b50e",
   "metadata": {},
   "source": [
    "要先建立輸入到模型的資料\n",
    "- 若是要分類是否是熱點，應該要以一個區域的grid為單位\n",
    "- 所以建立得grid亦包含該地區的所有特徵資料，以比例顯示"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a2ccdee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "\n",
    "from utils import get_grid, calculate_gi\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['font.family'] = ['Arial Unicode Ms']\n",
    "\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from sklearn.preprocessing import LabelEncoder, label_binarize\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix, classification_report, roc_auc_score, average_precision_score, accuracy_score, f1_score, recall_score, precision_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "475cd44b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataA1 = pd.read_csv('../ComputedData/Accident/DataA1_with_MYP.csv')\n",
    "dataA2 = pd.read_csv('../ComputedData/Accident/DataA2_with_MYP.csv')\n",
    "\n",
    "filtered_A2 = dataA2[dataA2['當事者順位'] == 1]\n",
    "filtered_A1 = dataA1[dataA1['當事者順位'] == 1]\n",
    "\n",
    "filtered_A1['source'] = 'A1'\n",
    "filtered_A2['source'] = 'A2'\n",
    "filtered_A1['num_accidents'] = 1 \n",
    "filtered_A2['num_accidents'] = 1\n",
    "combined_data = pd.concat([filtered_A1, filtered_A2], ignore_index=True)\n",
    "\n",
    "# hex_grid = get_grid(combined_data, hex_size=0.01, threshold=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e19c72a",
   "metadata": {},
   "source": [
    "## obtain hotspot's county"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d89cd171",
   "metadata": {},
   "outputs": [],
   "source": [
    "from shapely import wkt\n",
    "import geopandas as gpd\n",
    "import ast\n",
    "\n",
    "taiwan = gpd.read_file('../Data/OFiles_9e222fea-bafb-4436-9b17-10921abc6ef2/TOWN_MOI_1140318.shp')\n",
    "taiwan = taiwan[(~taiwan['TOWNNAME'].isin(['旗津區', '頭城鎮', '蘭嶼鄉', '綠島鄉', '琉球鄉'])) & \n",
    "                (~taiwan['COUNTYNAME'].isin(['金門縣', '連江縣', '澎湖縣']))]\n",
    "\n",
    "TM2 = 3826\n",
    "hex_grid_raw = pd.read_csv('../ComputedData/Grid/hex_grid.csv')\n",
    "hex_grid_raw['geometry'] = hex_grid_raw['geometry'].apply(wkt.loads)\n",
    "hex_grid = gpd.GeoDataFrame(hex_grid_raw, geometry='geometry').set_crs(TM2, allow_override=True)\n",
    "\n",
    "grid_gi_df = pd.read_csv('../ComputedData/Grid/grid_gi.csv')\n",
    "grid_gi_df['accident_indices'] = grid_gi_df['accident_indices'].apply(ast.literal_eval)\n",
    "grid_gi_df['geometry'] = grid_gi_df['geometry'].apply(wkt.loads)\n",
    "grid_gi  = gpd.GeoDataFrame(grid_gi_df, geometry='geometry').set_crs(TM2, allow_override=True)\n",
    "\n",
    "taiwan_tm2 = taiwan.to_crs(TM2)\n",
    "\n",
    "taiwan_cnty = taiwan_tm2[['COUNTYNAME','geometry']].dissolve(by='COUNTYNAME')\n",
    "taiwan_cnty['geometry'] = taiwan_cnty.buffer(0)\n",
    "taiwan_cnty = taiwan_cnty.reset_index()\n",
    "\n",
    "pts = hex_grid.copy()\n",
    "pts['geometry'] = pts.geometry.centroid\n",
    "\n",
    "county_join = gpd.sjoin(\n",
    "    pts[['geometry']], taiwan_cnty, how='left', predicate='within'\n",
    ")[['COUNTYNAME']]\n",
    "\n",
    "print('NaN ratio:', county_join['COUNTYNAME'].isna().mean())\n",
    "grid_gi['COUNTYNAME'] = county_join['COUNTYNAME']\n",
    "county_join.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1ef8ae0",
   "metadata": {},
   "source": [
    "hex_grid目前包含所有事故索引，所以要回推\n",
    "- 回推方式從combined_data獲取，並且計算他們的事故特徵平均"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36ec975a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 會造成重複的資料，因為grid可能覆蓋多個縣市\n",
    "# grid = calculate_gi(6, hex_grid, adjacency='knn')\n",
    "# grid = gpd.sjoin(hex_grid, taiwan[['COUNTYNAME', 'geometry']], how='left', predicate='intersects')\n",
    "# grid.to_csv('../ComputedData/Grid/grid.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec022585",
   "metadata": {},
   "source": [
    "## Features concat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a610abc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from config import select_group\n",
    "from utils_model import extract_features\n",
    "\n",
    "all_features_list = []\n",
    "\n",
    "grid_filter = grid_gi[grid_gi['accident_indices'].str.len() > 0]\n",
    "for rows in range(grid_filter.shape[0]):\n",
    "    features = extract_features(grid_filter, combined_data, select_group, rows)\n",
    "    all_features_list.append(features)\n",
    "\n",
    "all_features_df = pd.concat(all_features_list, ignore_index=True)\n",
    "all_features_df.fillna(0, inplace=True)\n",
    "\n",
    "all_features_df[['mrt_100m_count_mean', 'youbike_100m_count_mean', 'parkinglot_100m_count_mean', '速限-第1當事者_mean']] =\\\n",
    "      all_features_df[['mrt_100m_count_mean', 'youbike_100m_count_mean', 'parkinglot_100m_count_mean', '速限-第1當事者_mean']].\\\n",
    "        apply(lambda x: (x - x.min()) / (x.max() - x.min()))\n",
    "\n",
    "# all_features_df.to_csv(\"../ComputedData/ForModel/all_features.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8443deb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_filter = grid_gi[grid_gi['accident_indices'].str.len() > 0].reset_index(drop=True)\n",
    "all_features_df = pd.read_csv(\"../ComputedData/ForModel/all_features.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a7ccea5",
   "metadata": {},
   "source": [
    "# Model Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c96d0074",
   "metadata": {},
   "outputs": [],
   "source": [
    "from config import for_poly\n",
    "\n",
    "# with county town\n",
    "# 原始資料index並非從1開始所以需reset\n",
    "new_grid = pd.concat([grid_filter[['hotspot', 'COUNTYNAME']], all_features_df], axis=1)\n",
    "county_dummies = pd.get_dummies(new_grid['COUNTYNAME'], prefix='county')\n",
    "new_grid_encoded = pd.concat([new_grid.drop(['COUNTYNAME'], axis=1), county_dummies], axis=1)\n",
    "\n",
    "# binary hotspot\n",
    "new_grid_encoded['hotspot'] = new_grid_encoded['hotspot'].apply(lambda x: 'Hotspot' if 'Hotspot' in str(x) else 'Not Hotspot')\n",
    "\n",
    "le = LabelEncoder()\n",
    "y = le.fit_transform(new_grid_encoded['hotspot'])\n",
    "X = new_grid_encoded.drop(columns=['hotspot'])\n",
    "\n",
    "###\n",
    "from itertools import combinations\n",
    "groups = {base: [c for c in X.columns if c.startswith(base)] for base in for_poly}\n",
    "# 只做不同基底之間的配對\n",
    "base_pairs = list(combinations(for_poly, 2))\n",
    "\n",
    "new_cols = {}\n",
    "for a, b in base_pairs:\n",
    "    cols_a, cols_b = groups[a], groups[b]\n",
    "    for ca in cols_a:\n",
    "        va = X[ca].values\n",
    "        for cb in cols_b:\n",
    "            vb = X[cb].values\n",
    "            prod = va * vb\n",
    "            # 若這個交互列完全為0就跳過（節省維度）\n",
    "            if not np.any(prod):\n",
    "                continue\n",
    "            name = f\"{ca} x {cb}\"\n",
    "            new_cols[name] = prod\n",
    "\n",
    "if new_cols:\n",
    "    X_inter = pd.DataFrame(new_cols, index=X.index)\n",
    "    X = pd.concat([X, X_inter], axis=1)\n",
    "###\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, stratify=y, random_state=42\n",
    ")\n",
    "y_train = pd.Series(y_train, index=X_train.index)\n",
    "y_test  = pd.Series(y_test,  index=X_test.index)\n",
    "\n",
    "# with undersampling\n",
    "cls_counts = y_test.value_counts()\n",
    "min_count = cls_counts.min()\n",
    "rus_test = RandomUnderSampler(\n",
    "    sampling_strategy={int(c): int(min_count) for c in cls_counts.index},\n",
    "    random_state=42\n",
    ")\n",
    "X_resampled_test, y_resampled_test = rus_test.fit_resample(X_test, y_test)\n",
    "\n",
    "print(\"before US\")\n",
    "print(pd.Series(y_test).map(dict(enumerate(le.classes_))).value_counts())\n",
    "print(\"after US\")\n",
    "print(pd.Series(y_resampled_test).map(dict(enumerate(le.classes_))).value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2cbf8b3",
   "metadata": {},
   "source": [
    "# LR and RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a0b4110",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression(\n",
    "        penalty='elasticnet', solver='saga', l1_ratio=0.5,\n",
    "        class_weight='balanced', max_iter=1000, \n",
    "        random_state=42, \n",
    "        multi_class='multinomial',\n",
    "        n_jobs=-1\n",
    "    )\n",
    "rf = RandomForestClassifier(\n",
    "        n_estimators=300, max_depth=None, min_samples_leaf=1,\n",
    "        class_weight='balanced', n_jobs=-1, random_state=42,\n",
    "    )\n",
    "\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "for name, clf in [('Logistic', lr), ('RandomForest', rf)]:\n",
    "    scores = cross_val_score(clf, X_train, y_train, cv=cv, n_jobs=-1,\n",
    "                            # scoring='roc_auc_ovr_weighted',\n",
    "                            scoring='roc_auc'\n",
    "                             )\n",
    "    print(f'{name} CV ROC AUC: {scores.mean():.3f} ± {scores.std():.3f}')\n",
    "\n",
    "lr.fit(X_train, y_train)\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "proba_test_lr = lr.predict_proba(X_resampled_test)\n",
    "proba_test_rf = rf.predict_proba(X_resampled_test)\n",
    "y_pred_lr = np.argmax(proba_test_lr, axis=1)\n",
    "y_pred_rf = np.argmax(proba_test_rf, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dd47588",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "\n",
    "joblib.dump(lr, '../ComputedData/ModelPerformance/lr_model.pkl')\n",
    "joblib.dump(rf, '../ComputedData/ModelPerformance/rf_model.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21c85676",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = y_pred_lr\n",
    "proba_test = proba_test_lr\n",
    "\n",
    "print(\"Confusion Matrix\")\n",
    "print(confusion_matrix(y_resampled_test, y_pred, labels=range(len(le.classes_))))\n",
    "\n",
    "print(\"Classification Report\")\n",
    "print(classification_report(\n",
    "    y_resampled_test, y_pred, target_names=le.classes_, digits=3\n",
    "))\n",
    "\n",
    "if proba_test.shape[1] == 2:\n",
    "    # 二元分類\n",
    "    roc_auc = roc_auc_score(y_resampled_test, proba_test[:, 1])\n",
    "    print(f'ROC AUC: {roc_auc:.3f}')\n",
    "    y_test_bin = label_binarize(y_resampled_test, classes=range(len(le.classes_)))\n",
    "    pr_auc_macro  = average_precision_score(y_test_bin, proba_test[:, 1], average='macro')\n",
    "    pr_auc_weight = average_precision_score(y_test_bin, proba_test[:, 1], average='weighted')\n",
    "    print(f'PR  AUC macro: {pr_auc_macro:.3f}')\n",
    "    print(f'PR  AUC wighted: {pr_auc_weight:.3f}')\n",
    "else:\n",
    "    # 多類分類\n",
    "    roc_auc = roc_auc_score(y_resampled_test, proba_test, average='weighted', multi_class='ovr')\n",
    "    print(f'ROC AUC: {roc_auc:.3f}')\n",
    "    # 多類PR AUC需要 binarize 後用 one-vs-rest，再做 macro/weighted 平均\n",
    "    y_test_bin = label_binarize(y_resampled_test, classes=range(len(le.classes_)))  # shape [n, n_classes]\n",
    "    pr_auc_macro  = average_precision_score(y_test_bin, proba_test, average='macro')\n",
    "    pr_auc_weight = average_precision_score(y_test_bin, proba_test, average='weighted')\n",
    "    print(f'PR  AUC macro: {pr_auc_macro:.3f}')\n",
    "    print(f'PR  AUC wighted: {pr_auc_weight:.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6017ce8",
   "metadata": {},
   "source": [
    "設施平均：該地區的事故點附近平均會有幾個設施"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48e0bbf5",
   "metadata": {},
   "source": [
    "### RandomForest Feature Importance & LinearRegression coefficient\n",
    "- group的寫法可能還要再修"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "855c8fa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils_model import get_importance\n",
    "\n",
    "get_importance(rf, X_train, 'county')\n",
    "get_importance(lr, X_train, 'county')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fbe757c",
   "metadata": {},
   "source": [
    "解釋範例：\n",
    "exp(1.5741) = 4.826\n",
    "在宜蘭，parkinglot 的效應比全台平均強 4.826 倍"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad070af9",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_importance(lr, X_train, 'youbike')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ab0cbaf",
   "metadata": {},
   "source": [
    "## Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd61008b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "INPUT_DIM = X_resampled_test.shape[1]\n",
    "NUM_CLASSES = int(len(set(y)))  # 類別 0/1\n",
    "\n",
    "class BinaryMLP(nn.Module):\n",
    "    def __init__(self, in_dim=INPUT_DIM, num_classes=NUM_CLASSES, drop=0.1):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(in_dim, 1024),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(drop),\n",
    "            nn.Linear(1024, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(drop),\n",
    "            nn.Linear(512, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(drop),\n",
    "            nn.Linear(256, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(drop),\n",
    "            nn.Linear(128, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(drop),\n",
    "            nn.Linear(64, num_classes)  # logits\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.net(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "995912e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_nn, X_val_nn, y_train_nn, y_val_nn = train_test_split(\n",
    "    X_train, y_train, test_size=0.2, stratify=y_train, random_state=42\n",
    ")\n",
    "\n",
    "def to_tensors(X_df, y_arr):\n",
    "    return (torch.from_numpy(np.asarray(X_df, dtype=np.float32)),\n",
    "            torch.from_numpy(np.asarray(y_arr, dtype=np.int64)))\n",
    "\n",
    "X_train_t, y_train_t = to_tensors(X_train, y_train)\n",
    "X_val_t, y_val_t = to_tensors(X_val_nn, y_val_nn)\n",
    "X_test_t, y_test_t = to_tensors(X_resampled_test, y_resampled_test)\n",
    "\n",
    "train_loader = DataLoader(TensorDataset(X_train_t, y_train_t), batch_size=256, shuffle=True, drop_last=False)\n",
    "val_loader = DataLoader(TensorDataset(X_val_t, y_val_t), batch_size=512, shuffle=False)\n",
    "test_loader = DataLoader(TensorDataset(X_test_t, y_test_t), batch_size=512, shuffle=False)\n",
    "\n",
    "model = BinaryMLP().to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "best_val = -np.inf\n",
    "patience = 5\n",
    "wait = 0\n",
    "epochs = 20\n",
    "\n",
    "def eval_loop(loader):\n",
    "    model.eval()\n",
    "    all_logits = []\n",
    "    all_y = []\n",
    "    with torch.no_grad():\n",
    "        for xb, yb in loader:\n",
    "            xb = xb.to(device)\n",
    "            logits = model(xb)\n",
    "            all_logits.append(logits.cpu())\n",
    "            all_y.append(yb)\n",
    "    logits_all = torch.cat(all_logits)\n",
    "    y_all = torch.cat(all_y)\n",
    "    probs = torch.softmax(logits_all, dim=1).numpy()\n",
    "    preds = probs.argmax(axis=1)\n",
    "    acc = accuracy_score(y_all, preds)\n",
    "    f1  = f1_score(y_all, preds, average='binary' if probs.shape[1]==2 else 'weighted')\n",
    "    recall = recall_score(y_all, preds, average='binary' if probs.shape[1]==2 else 'weighted')\n",
    "    if probs.shape[1] == 2:\n",
    "        auc = roc_auc_score(y_all, probs[:,1])\n",
    "    else:\n",
    "        auc = roc_auc_score(y_all, probs, multi_class='ovr', average='weighted')\n",
    "\n",
    "    conf = confusion_matrix(y_all, preds, labels=range(len(le.classes_)))\n",
    "    report = classification_report(y_all, preds, target_names=le.classes_, digits=3)\n",
    "\n",
    "    return {'acc': acc, 'f1': f1, 'recall': recall, 'auc': auc, 'conf': conf, 'report': report, 'pred_y': preds}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "568f8c09",
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(1, epochs+1):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for xb, yb in train_loader:\n",
    "        xb, yb = xb.to(device), yb.to(device)\n",
    "        optimizer.zero_grad(set_to_none=True)\n",
    "        logits = model(xb)\n",
    "        loss = criterion(logits, yb)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item() * xb.size(0)\n",
    "\n",
    "    train_loss = total_loss / len(train_loader.dataset)\n",
    "    val_metrics = eval_loop(val_loader)\n",
    "    print(f'Epoch {epoch:02d}/{epochs} | loss {train_loss:.4f} | '\n",
    "          f'val_acc {val_metrics[\"acc\"]:.3f} | val_f1 {val_metrics[\"f1\"]:.3f} | val_auc {val_metrics[\"auc\"]:.3f}')\n",
    "\n",
    "    score_for_early = val_metrics[\"auc\"]  # 你也可用 f1\n",
    "    if score_for_early > best_val:\n",
    "        best_val = score_for_early\n",
    "        wait = 0\n",
    "        # torch.save(model.state_dict(), 'best_model.pt')\n",
    "    else:\n",
    "        wait += 1\n",
    "        if wait >= patience:\n",
    "            print('Early stopping.')\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "994734e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_metrics = eval_loop(test_loader)\n",
    "print(test_metrics['report'])\n",
    "\n",
    "torch.save(model.state_dict(), '../ComputedData/ModelPerformance/nn_model.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e401838",
   "metadata": {},
   "source": [
    "## Permutation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15e6fa59",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils_model import build_groups_from_prefix, build_groups_with_interactions, build_pair_interaction_groups, PI_ML, PI_NN\n",
    "\n",
    "groups = build_groups_with_interactions(X_test.columns)\n",
    "\n",
    "print('lr')\n",
    "base_lr, perm_lr = PI_ML(lr, X_test, y_test, groups=groups, n_repeats=10)\n",
    "print('rf') \n",
    "base_rf, perm_rf = PI_ML(rf, X_test, y_test, groups=groups, n_repeats=10)\n",
    "print('nn')\n",
    "base_nn, perm_nn = PI_NN(model, X_test, y_test, groups=groups, n_repeats=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7f7ac9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined = pd.concat([\n",
    "    perm_lr.assign(model='LR'),\n",
    "    # perm_rf.assign(model='RF'),\n",
    "    # perm_nn.assign(model='NN')\n",
    "], ignore_index=True)\n",
    "\n",
    "order = (combined.groupby('group')['importance'].mean().sort_values(ascending=True).index.tolist())\n",
    "ypos = np.arange(len(order))\n",
    "\n",
    "triples = [\n",
    "    (perm_lr, 'lr'), \n",
    "    (perm_rf, 'rf'), \n",
    "    (perm_nn, 'nn')\n",
    "    ]\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "for perm_df_i, name in triples:\n",
    "    d = (perm_df_i.set_index('group').reindex(order)) # 用統一群組順序對齊\n",
    "    plt.errorbar(\n",
    "        d['importance'],\n",
    "        (ypos),\n",
    "        xerr=d['std'],\n",
    "        fmt='o',\n",
    "        linewidth=2,\n",
    "        capsize=5,\n",
    "        label=name\n",
    "    )\n",
    "\n",
    "plt.yticks(ypos, order)\n",
    "plt.axvline(0.0, linestyle='--', linewidth=1)\n",
    "plt.xlabel('Permutation importance')\n",
    "plt.ylabel('Group')\n",
    "plt.title('Permutation importance (LR / RF / NN)')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7fdf7ec",
   "metadata": {},
   "source": [
    "# Hitrate\n",
    "le的轉換是1為not hotspot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba8f0810",
   "metadata": {},
   "outputs": [],
   "source": [
    "county_cols = [col for col in X_resampled_test.columns if col.startswith('county_')]\n",
    "\n",
    "\n",
    "df_hitrate = X_resampled_test.copy()\n",
    "df_hitrate['y_true'] = y_resampled_test\n",
    "df_hitrate['y_pred'] = y_pred_lr\n",
    "\n",
    "hitrate = {}\n",
    "for col in county_cols:\n",
    "\n",
    "    mask = df_hitrate[df_hitrate[col] != False]\n",
    "    tn, fp, fn, tp = confusion_matrix(\n",
    "        mask['y_true'], mask['y_pred'], labels=[1, 0] # 這裡0是Hotspot\n",
    "    ).ravel()\n",
    "\n",
    "    # calculate precision, recall, accuracy, f1-score\n",
    "    precision = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
    "    recall = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
    "    accuracy = (tp + tn) / (tp + tn + fp + fn) if (tp + tn + fp + fn) > 0 else 0\n",
    "    f1 = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
    "    hitrate[col] = {\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'accuracy': accuracy,\n",
    "        'f1': f1\n",
    "    }\n",
    "\n",
    "hitrate_df = pd.DataFrame.from_dict(hitrate, orient='index', columns=['precision', 'recall', 'accuracy', 'f1']).sort_values('f1', ascending=False)\n",
    "hitrate_df['county'] = hitrate_df.index\n",
    "hitrate_df['county'] = hitrate_df['county'].str.replace('county_', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a542addf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils_model import hitrate_data\n",
    "\n",
    "hitrate_lr = hitrate_data(X_resampled_test, y_resampled_test, y_pred_lr)\n",
    "hitrate_rf = hitrate_data(X_resampled_test, y_resampled_test, y_pred_rf)\n",
    "hitrate_nn = hitrate_data(X_resampled_test, y_resampled_test, test_metrics['pred_y'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f500132b",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {\n",
    "    'LR': hitrate_lr.copy(),\n",
    "    'RF': hitrate_rf.copy(),\n",
    "    'NN': hitrate_nn.copy(),\n",
    "}\n",
    "order = (results['NN'].sort_values('f1', ascending=False)['county']).tolist()\n",
    "\n",
    "metrics = ['precision', 'recall', 'accuracy', 'f1']\n",
    "plt.figure(figsize=(16, 10))\n",
    "\n",
    "for i, met in enumerate(metrics, 1):\n",
    "    ax = plt.subplot(2, 2, i)\n",
    "    pos = np.arange(len(order))\n",
    "    width = 0.25\n",
    "    for j, (name, df) in enumerate(results.items()):\n",
    "        d = df.set_index('county').reindex(order)\n",
    "        ax.bar(pos + (j-1)*width, d[met].values, width=width, label=name)\n",
    "    ax.set_title(met)\n",
    "    ax.set_xticks(pos)\n",
    "    ax.set_xticklabels(order, rotation=45, ha='right')\n",
    "    if i == 2:\n",
    "        ax.legend(loc='upper right')\n",
    "    ax.set_ylim(0, 1)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e30cb21",
   "metadata": {},
   "outputs": [],
   "source": [
    "def metrics_bin(y_true, y_pred):\n",
    "    return {\n",
    "        'precision': precision_score(y_true, y_pred, pos_label=0),\n",
    "        'recall':    recall_score(y_true, y_pred, pos_label=0),\n",
    "        'f1':        f1_score(y_true, y_pred, pos_label=0),\n",
    "        'accuracy':  accuracy_score(y_true, y_pred),\n",
    "    }\n",
    "\n",
    "m_lr = metrics_bin(y_resampled_test, y_pred_lr)\n",
    "m_rf = metrics_bin(y_resampled_test, y_pred_rf)\n",
    "m_nn = metrics_bin(y_resampled_test, test_metrics['pred_y'])\n",
    "\n",
    "df = pd.DataFrame([m_lr, m_rf, m_nn], index=['LR','RF','NN'])\n",
    "metrics = ['precision', 'recall', 'f1', 'accuracy']\n",
    "df = df[metrics]\n",
    "\n",
    "plt.figure(figsize=(9, 5))\n",
    "x = np.arange(len(metrics))\n",
    "width = 0.25\n",
    "\n",
    "for i, model in enumerate(df.index):\n",
    "    plt.bar(x + (i-1)*width, df.loc[model].values, width=width, label=model)\n",
    "\n",
    "plt.xticks(x, metrics)\n",
    "plt.ylim(0, 1)\n",
    "plt.ylabel('Score')\n",
    "plt.title('Overall Metrics on Resampled Test')\n",
    "plt.legend(loc='upper right')\n",
    "\n",
    "for i, model in enumerate(df.index):\n",
    "    vals = df.loc[model].values\n",
    "    for xi, v in zip(x + (i-1)*width, vals):\n",
    "        plt.text(xi, v + 0.01, f'{v:.2f}', ha='center', va='bottom', fontsize=9)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ST-RTA",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
