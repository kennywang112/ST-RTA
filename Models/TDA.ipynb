{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20592ef2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "current_dir = os.getcwd()\n",
    "parent_dir = os.path.dirname(current_dir)\n",
    "analyze_path = os.path.join(parent_dir, \"utils\")\n",
    "\n",
    "os.chdir(analyze_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "924f3e57",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA\n",
    "from tdam.cover import CubicalCover\n",
    "from tdam.clustering import FailSafeClustering\n",
    "from tdam.core_old import MapperAlgorithm\n",
    "\n",
    "from TrafficTDApythonUtils.utils_v3 import *\n",
    "from TrafficTDApythonUtils.plots import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01b53bc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "from shapely import wkt\n",
    "from utils import read_data\n",
    "\n",
    "combined_data = read_data()\n",
    "TM2 = 3826\n",
    "taiwan = gpd.read_file('../Data/OFiles_9e222fea-bafb-4436-9b17-10921abc6ef2/TOWN_MOI_1140318.shp')\n",
    "taiwan = taiwan[(~taiwan['TOWNNAME'].isin(['旗津區', '頭城鎮', '蘭嶼鄉', '綠島鄉', '琉球鄉'])) & \n",
    "                (~taiwan['COUNTYNAME'].isin(['金門縣', '連江縣', '澎湖縣']))].to_crs(TM2)\n",
    "taiwan_cnty = taiwan[['COUNTYNAME','geometry']].dissolve(by='COUNTYNAME')\n",
    "taiwan_cnty['geometry'] = taiwan_cnty.buffer(0)\n",
    "\n",
    "# 原始以 0.001 grid 計算出的區域事故及對應索引, 依照 hex_grid 計算出來的GI\n",
    "grid_gi_df = pd.read_csv('../ComputedData/Grid/grid_gi.csv')\n",
    "grid_gi_df['accident_indices'] = grid_gi_df['accident_indices'].apply(ast.literal_eval)\n",
    "grid_gi_df['geometry'] = grid_gi_df['geometry'].apply(wkt.loads)\n",
    "grid_gi  = gpd.GeoDataFrame(grid_gi_df, geometry='geometry').set_crs(TM2, allow_override=True)\n",
    "grid_gi['geometry'] = grid_gi.geometry.centroid\n",
    "\n",
    "county_join = gpd.sjoin(grid_gi[['geometry']], taiwan_cnty, how='left', predicate='within')\n",
    "grid_gi['COUNTYNAME'] = county_join['COUNTYNAME']\n",
    "\n",
    "grid_filter = grid_gi[grid_gi['accident_indices'].str.len() > 0]\n",
    "grid_filter.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0986c79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from utils_model import extract_features\n",
    "\n",
    "# select_group = [\n",
    "#     # 氣候暫不討論\n",
    "#     # '天候名稱', '光線名稱',\n",
    "\n",
    "#     # 道路問題\n",
    "#     # '路面狀況-路面鋪裝名稱', '路面狀況-路面狀態名稱', '路面狀況-路面缺陷名稱',\n",
    "#     # '道路障礙-障礙物名稱', '道路障礙-視距品質名稱', '道路障礙-視距名稱',\n",
    "\n",
    "#     # 號誌\n",
    "#     '號誌-號誌種類名稱', '號誌-號誌動作名稱',\n",
    "\n",
    "#     # 車道劃分\n",
    "#     '車道劃分設施-分道設施-快車道或一般車道間名稱',\n",
    "#     '車道劃分設施-分道設施-快慢車道間名稱', '車道劃分設施-分道設施-路面邊線名稱',\n",
    "\n",
    "#     # 大類別\n",
    "#     # '肇因研判大類別名稱-主要', '肇因研判大類別名稱-個別', # 聚焦道路類型\n",
    "#     # '當事者區分-類別-大類別名稱-車種', # 聚焦道路類型\n",
    "#     # '當事者行動狀態大類別名稱', # 聚焦道路類型\n",
    "#     '車輛撞擊部位大類別名稱-最初', #'車輛撞擊部位大類別名稱-其他',\n",
    "#     '事故類型及型態大類別名稱', '車道劃分設施-分向設施大類別名稱',\n",
    "#     '事故位置大類別名稱', '道路型態大類別名稱',\n",
    "    \n",
    "#     # 子類別\n",
    "#     # '肇因研判子類別名稱-主要', '肇因研判子類別名稱-個別', # 聚焦道路類型\n",
    "#     # '當事者區分-類別-子類別名稱-車種', # 聚焦道路類型\n",
    "#     # '當事者行動狀態子類別名稱', # 聚焦道路類型\n",
    "#     # '車輛撞擊部位子類別名稱-最初', '車輛撞擊部位子類別名稱-其他', # 道路類型很大程度影響撞擊部位，所以不考慮\n",
    "#     # '事故類型及型態子類別名稱', '車道劃分設施-分向設施子類別名稱', \n",
    "#     # '事故位置子類別名稱', '道路型態子類別名稱',\n",
    "\n",
    "#     # 其他\n",
    "#     # '當事者屬-性-別名稱', '當事者事故發生時年齡', \n",
    "#     '速限-第1當事者', '道路類別-第1當事者-名稱',\n",
    "#     # '保護裝備名稱', '行動電話或電腦或其他相類功能裝置名稱', '肇事逃逸類別名稱-是否肇逃',\n",
    "\n",
    "#     # 設施\n",
    "#     'youbike_100m_count', 'mrt_100m_count', 'parkinglot_100m_count',\n",
    "\n",
    "#     # A1 or A2\n",
    "#     # 'source',\n",
    "#     ]\n",
    "\n",
    "# all_features_list = []\n",
    "\n",
    "# for rows in range(grid_filter.shape[0]):\n",
    "#     features = extract_features(grid_filter, combined_data, select_group, rows)\n",
    "#     all_features_list.append(features)\n",
    "\n",
    "# all_features_df = pd.concat(all_features_list, ignore_index=True)\n",
    "# all_features_df.fillna(0, inplace=True)\n",
    "\n",
    "# all_features_df[['mrt_100m_count_mean', 'youbike_100m_count_mean', 'parkinglot_100m_count_mean', '速限-第1當事者_mean']] =\\\n",
    "#       all_features_df[['mrt_100m_count_mean', 'youbike_100m_count_mean', 'parkinglot_100m_count_mean', '速限-第1當事者_mean']].\\\n",
    "#         apply(lambda x: (x - x.min()) / (x.max() - x.min()))\n",
    "        \n",
    "# all_features_df.to_csv(\"../ComputedData/ForModel/all_features_filtered.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ea8fc92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_features_df = pd.read_csv(\"../ComputedData/ForModel/all_features.csv\")\n",
    "all_features_df = pd.read_csv(\"../ComputedData/ForModel/all_features_filtered.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a50e0008",
   "metadata": {},
   "source": [
    "## Start Mapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02c20c48",
   "metadata": {},
   "outputs": [],
   "source": [
    "pc = 9\n",
    "\n",
    "lens = PCA(pc).fit_transform(all_features_df)\n",
    "\n",
    "pca = PCA(pc).fit(all_features_df)\n",
    "ratios = pca.explained_variance_ratio_\n",
    "print(ratios)\n",
    "print(ratios.sum()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71c12b3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49e6290e",
   "metadata": {},
   "outputs": [],
   "source": [
    "overlaps = [2, 5]\n",
    "intervals = [7, 8, 9, 10]\n",
    "detailed_results = []\n",
    "silhouette_for_intervals = []\n",
    "\n",
    "for overlap in overlaps:\n",
    "    for interval in intervals:\n",
    "        print(f\"Processing overlap {overlap}, interval {interval}\")\n",
    "        mapper_algo = MapperAlgorithm(\n",
    "            cover=CubicalCover(\n",
    "                n_intervals=interval,\n",
    "                overlap_frac=overlap / 10\n",
    "            ),\n",
    "            clustering=FailSafeClustering(\n",
    "                KMeans(\n",
    "                    n_clusters=2,\n",
    "                    random_state=42\n",
    "                )\n",
    "            ),\n",
    "            n_jobs=14\n",
    "        )\n",
    "\n",
    "        mapper_info = mapper_algo.fit_transform(all_features_df.to_numpy(), lens)\n",
    "\n",
    "        silhouette_for_intervals.append(mapper_info[1])\n",
    "        result = {\n",
    "            \"overlap\": overlap,\n",
    "            \"interval\": interval,\n",
    "            \"silhouette\": mapper_info[1],\n",
    "            \"mapper_info\": mapper_info\n",
    "        }\n",
    "        detailed_results.append(result)\n",
    "\n",
    "        with open(f\"../ComputedData/ForMatrixFilter/o{overlap}i{interval}.pkl\", 'wb') as file:\n",
    "            pickle.dump(result, file)\n",
    "\n",
    "detailed_results_df = pd.DataFrame(detailed_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eced9ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_features_df['hotspot'] = grid_filter['hotspot']\n",
    "all_features_df['hotspot'] = all_features_df['hotspot'].apply(lambda x: 'Hotspot' if 'Hotspot' in str(x) else 'Not Hotspot')\n",
    "all_features_df['youbike'] = all_features_df['youbike_100m_count_mean'].apply(lambda x: 'Facility' if x>0 else 'No Facility')\n",
    "all_features_df['hotspot_youbike'] = all_features_df['hotspot'] + '_' + all_features_df['youbike']\n",
    "\n",
    "for overlap in overlaps:\n",
    "    for interval in intervals:\n",
    "        \n",
    "        detailed_results_df = pickle.load(open(f\"../ComputedData/ForMatrixFilter/o{overlap}i{interval}.pkl\", \"rb\"))\n",
    "        choose = 'hotspot_youbike'\n",
    "        mapper_plotter = MapperPlotter(detailed_results_df['mapper_info'], \n",
    "                                    all_features_df, seed=87, iterations=30, dim=3,\n",
    "                                        range_lst=[-0.5, 0.5, 0.5, -0.5])\n",
    "\n",
    "        # def avg_label(data):\n",
    "        #     return sum(data) / len(data) if len(data) > 0 else 0\n",
    "        def most_common_encoded_label(data):\n",
    "            most_common_item = Counter(data).most_common(1)[0][0]\n",
    "            return most_common_item\n",
    "\n",
    "        mapper_plot = mapper_plotter.create_mapper_plot(choose, most_common_encoded_label, avg=False)\n",
    "        full_info = mapper_plotter.extract_data()\n",
    "        mapper_plotter.map_colors(choose, size=10, threshold=0)\n",
    "        mapper_plotter.plot(choose, avg=False, set_label=True, size=1000, anchor=1.33,\n",
    "                            save_path=f\"../ComputedData/ForMatrixFilter/Plots/o{overlap}i{interval}.png\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ST-RTA",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
