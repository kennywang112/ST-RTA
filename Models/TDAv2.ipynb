{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "59265153",
   "metadata": {},
   "source": [
    "This code is to optimize TDA.ipynb file, the main change is using three main function as the filter function:\n",
    "1. eccentricity\n",
    "2. PCA\n",
    "3. KDE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10894c08",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "current_dir = os.getcwd()\n",
    "parent_dir = os.path.dirname(current_dir)\n",
    "analyze_path = os.path.join(parent_dir, \"utils\")\n",
    "\n",
    "os.chdir(analyze_path)\n",
    "\n",
    "import ast\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import pickle\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA\n",
    "from tdam.cover import CubicalCover\n",
    "from tdam.clustering import FailSafeClustering\n",
    "from tdam.core_old import MapperAlgorithm\n",
    "from sklearn.metrics import pairwise_distances\n",
    "from sklearn.neighbors import KernelDensity\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import StandardScaler, normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79249fdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "from shapely import wkt\n",
    "\n",
    "TM2 = 3826\n",
    "taiwan = gpd.read_file('../Data/OFiles_9e222fea-bafb-4436-9b17-10921abc6ef2/TOWN_MOI_1140318.shp')\n",
    "taiwan = taiwan[(~taiwan['TOWNNAME'].isin(['旗津區', '頭城鎮', '蘭嶼鄉', '綠島鄉', '琉球鄉'])) & \n",
    "                (~taiwan['COUNTYNAME'].isin(['金門縣', '連江縣', '澎湖縣']))].to_crs(TM2)\n",
    "taiwan_cnty = taiwan[['COUNTYNAME','geometry']].dissolve(by='COUNTYNAME')\n",
    "taiwan_cnty['geometry'] = taiwan_cnty.buffer(0)\n",
    "\n",
    "# 原始以 0.001 grid 計算出的區域事故及對應索引, 依照 hex_grid 計算出來的GI\n",
    "grid_gi_df = pd.read_csv('../ComputedData/Grid/grid_gi.csv')\n",
    "grid_gi_df['accident_indices'] = grid_gi_df['accident_indices'].apply(ast.literal_eval)\n",
    "grid_gi_df['geometry'] = grid_gi_df['geometry'].apply(wkt.loads)\n",
    "grid_gi  = gpd.GeoDataFrame(grid_gi_df, geometry='geometry').set_crs(TM2, allow_override=True)\n",
    "grid_gi['geometry'] = grid_gi.geometry.centroid\n",
    "\n",
    "county_join = gpd.sjoin(grid_gi[['geometry']], taiwan_cnty, how='left', predicate='within')\n",
    "grid_gi['COUNTYNAME'] = county_join['COUNTYNAME']\n",
    "\n",
    "grid_filter = grid_gi[grid_gi['accident_indices'].str.len() > 0]\n",
    "grid_filter.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2db44984",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_features_df = pd.read_csv(\"../ComputedData/ForModel/all_featuresV2.csv\")\n",
    "cols = all_features_df.columns[all_features_df.columns.str.contains('事故位置大類別名稱')] # 高共線\n",
    "all_features_df.drop(columns=cols, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85621596",
   "metadata": {},
   "outputs": [],
   "source": [
    "def linf_centrality_exact(df, block_size = 2000):\n",
    "    \"\"\"\n",
    "    回傳 shape=(n,1) 的 L∞ centrality（每點到最遠點的距離）。\n",
    "    - metric: \"cosine\" 或 \"euclidean\"\n",
    "    - block_size: 控制記憶體 (block_size * n distances)\n",
    "    \"\"\"\n",
    "    X = df.to_numpy(dtype=float)\n",
    "    n = X.shape[0]\n",
    "    # 對每一列作 L2 正規化才能用 cosine 距離\n",
    "    X = normalize(X, norm=\"l2\", axis=1)\n",
    "\n",
    "    # 準備結果陣列，初始為無窮小\n",
    "    max_d = np.full(n, -np.inf, dtype=float)\n",
    "    order = np.arange(n) # 保留原順序\n",
    "    \n",
    "    # 分塊計算 pairwise 距離以控制記憶體\n",
    "    for start in range(0, n, block_size):\n",
    "        idx = order[start:start+block_size]\n",
    "        D_blk = pairwise_distances(X[idx], X, metric='cosine')  # (b, n)\n",
    "        # 自身距離設為 -inf，避免影響 max\n",
    "        D_blk[np.arange(D_blk.shape[0]), idx] = -np.inf\n",
    "        # 針對每個 i（在 idx 中），更新它的全域最遠距離\n",
    "        max_d[idx] = np.maximum(max_d[idx], D_blk.max(axis=1))\n",
    "\n",
    "    return max_d.reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3104165",
   "metadata": {},
   "source": [
    "## 1. PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4508e330",
   "metadata": {},
   "outputs": [],
   "source": [
    "pc=5\n",
    "filter_pca = PCA(pc).fit_transform(all_features_df)\n",
    "\n",
    "pca = PCA(pc).fit(all_features_df)\n",
    "ratios = pca.explained_variance_ratio_\n",
    "print(ratios)\n",
    "print(ratios.sum()) \n",
    "# pc_z = StandardScaler().fit_transform(filter_pca[:, :pc])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ce51cab",
   "metadata": {},
   "source": [
    "## 2. KDE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c58e927c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = filter_pca # pc_z\n",
    "kde = KernelDensity(kernel='gaussian').fit(X)\n",
    "\n",
    "log_density = kde.score_samples(X)\n",
    "\n",
    "density = np.exp(log_density)\n",
    "# rank-normalize\n",
    "rank = (np.argsort(np.argsort(density)).astype(float) / (len(density)-1))\n",
    "filter_kde = rank.reshape(-1, 1) \n",
    "# kde_z = StandardScaler().fit_transform(filter_kde)\n",
    "\n",
    "### check for correlation\n",
    "lin = LinearRegression().fit(X, filter_kde.ravel())\n",
    "print(\"Linear R^2 (PC1-5 -> KDE) =\", lin.score(X, filter_kde.ravel()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2695f554",
   "metadata": {},
   "source": [
    "## 3. Centrality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4414792",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Centrality')\n",
    "filter_centrality = linf_centrality_exact(all_features_df)\n",
    "# linf_z = StandardScaler().fit_transform(filter_centrality)\n",
    "\n",
    "# filter_full = np.concatenate([linf_z, kde_z, pc_z], axis=1)\n",
    "filter_full = np.concatenate([filter_centrality, filter_kde, filter_pca], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d39cc1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_full = pd.DataFrame(filter_full, columns=['centrality', 'kde', 'pc1', 'pc2', 'pc3', 'pc4', 'pc5'])\n",
    "filter_full.to_csv(\"../ComputedData/ForModel/filtered_data.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a16bb0d",
   "metadata": {},
   "source": [
    "# Mapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4377e9e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_full = pd.read_csv(\"../ComputedData/ForModel/filtered_data.csv\")\n",
    "filter_full.drop(columns=['pc4', 'pc5'], inplace=True)\n",
    "filter_full.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba34267a",
   "metadata": {},
   "outputs": [],
   "source": [
    "overlaps = [2, 3]\n",
    "intervals = [8, 10]\n",
    "detailed_results = []\n",
    "silhouette_for_intervals = []\n",
    "\n",
    "for overlap in overlaps:\n",
    "    for interval in intervals:\n",
    "        print(f\"Processing overlap {overlap}, interval {interval}\")\n",
    "        mapper_algo = MapperAlgorithm(\n",
    "            cover=CubicalCover(\n",
    "                n_intervals=interval,\n",
    "                overlap_frac=overlap / 10\n",
    "            ),\n",
    "            clustering=FailSafeClustering(\n",
    "                KMeans(\n",
    "                    n_clusters=2,\n",
    "                    random_state=42\n",
    "                )\n",
    "            ),\n",
    "            n_jobs=-1\n",
    "        )\n",
    "\n",
    "        mapper_info = mapper_algo.fit_transform(all_features_df.to_numpy(), filter_full)\n",
    "\n",
    "        silhouette_for_intervals.append(mapper_info[1])\n",
    "        result = {\n",
    "            \"overlap\": overlap,\n",
    "            \"interval\": interval,\n",
    "            \"silhouette\": mapper_info[1],\n",
    "            \"mapper_info\": mapper_info\n",
    "        }\n",
    "        detailed_results.append(result)\n",
    "\n",
    "        with open(f\"../ComputedData/ForMatrixV2/o{overlap}i{interval}.pkl\", 'wb') as file:\n",
    "            pickle.dump(result, file)\n",
    "\n",
    "detailed_results_df = pd.DataFrame(detailed_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20584cc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "col = '撞擊部位'\n",
    "\n",
    "def get_max_categories(row):\n",
    "\n",
    "    cols = all_features_df.columns[all_features_df.columns.str.contains(col)]\n",
    "\n",
    "    max_val = row[cols].max()\n",
    "    max_cols = row[cols][row[cols] == max_val].index\n",
    "    # 取底線後面的類別名稱，用逗號串起來\n",
    "    return ','.join(col.split('_')[-1] for col in max_cols)\n",
    "\n",
    "all_features_df['最高類別'] = all_features_df.apply(get_max_categories, axis=1)\n",
    "all_features_df['最高類別'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2063ef50",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_features_df['county'] = grid_filter['COUNTYNAME']\n",
    "all_features_df['hotspot'] = grid_filter['hotspot']\n",
    "all_features_df['hotspot'] = all_features_df['hotspot'].apply(lambda x: 'Hotspot' if 'Hotspot' in str(x) else 'Not Hotspot')\n",
    "all_features_df['facility'] = all_features_df[['youbike_100m_count_mean', 'mrt_100m_count_mean', 'parkinglot_100m_count_mean']].apply(\n",
    "    lambda row: '1' if (row > 0).any() else '0', axis=1\n",
    ")\n",
    "all_features_df['hotspot_facility'] = all_features_df['hotspot'] + '_' + all_features_df['facility']\n",
    "all_features_df['county_city'] = all_features_df['county'].apply(lambda x: 'City' if '市' in str(x) else 'County')\n",
    "\n",
    "all_features_df_speed = pd.read_csv('../ComputedData/ForModel/all_features_df-速限.csv')\n",
    "all_features_df['original_speed'] = all_features_df_speed['速限-第1當事者_mean']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9616fef",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "def avg_label(data):\n",
    "    return sum(data) / len(data) if len(data) > 0 else 0\n",
    "\n",
    "def most_common_encoded_label(data):\n",
    "    return Counter(data).most_common(1)[0][0]\n",
    "\n",
    "# conditional probability\n",
    "def cond_prob_mixed(subdf, a_col, a_is, b_col, b_rule=\">0\", alpha=0.5, min_den=0):\n",
    "    \"\"\"\n",
    "    回傳 P(B | A) ，其中：\n",
    "    - A : 類別欄位, a_is 可為 str 或 可迭代(多類別集合)\n",
    "    - B : 可為數值/比例欄位，用 b_rule 指定成立條件(或傳入 callable)\n",
    "    alpha : Laplace smoothing\n",
    "    min_den : A 成立的樣本至少要有幾個，否則回 NaN\n",
    "    \"\"\"\n",
    "    Aset = {a_is} if isinstance(a_is, str) else set(a_is)\n",
    "    A = subdf[a_col].astype(str)\n",
    "    mask_A = A.isin(Aset)\n",
    "\n",
    "    if mask_A.sum() < min_den:\n",
    "        return float('nan')\n",
    "\n",
    "    s = pd.to_numeric(subdf[b_col], errors='coerce')  # 比例/數值\n",
    "    if callable(b_rule):\n",
    "        mask_B = b_rule(s)  # 例如：lambda x: x >= 0.2\n",
    "    else:\n",
    "        rule = str(b_rule).strip()\n",
    "        if rule == \">0\":\n",
    "            mask_B = (s > 0)\n",
    "        elif rule == \">=0\":\n",
    "            mask_B = (s >= 0)\n",
    "        elif rule.startswith(\">=\"):\n",
    "            thr = float(rule[2:]); mask_B = (s >= thr)\n",
    "        elif rule.startswith(\">\"):\n",
    "            thr = float(rule[1:]); mask_B = (s > thr)\n",
    "        elif rule.startswith(\"<=\"):\n",
    "            thr = float(rule[2:]); mask_B = (s <= thr)\n",
    "        elif rule.startswith(\"<\"):\n",
    "            thr = float(rule[1:]); mask_B = (s < thr)\n",
    "        elif rule.startswith(\"==\"):\n",
    "            thr = float(rule[2:]); mask_B = (s == thr)\n",
    "        else:\n",
    "            raise ValueError(\"Unknown b_rule\")\n",
    "\n",
    "    num = (mask_A & mask_B).sum()\n",
    "    den = mask_A.sum()\n",
    "    return float((num + alpha) / (den + 2 * alpha))\n",
    "\n",
    "def node_cond_prob(subdf):\n",
    "    return cond_prob_mixed(\n",
    "        subdf=subdf,\n",
    "        # 有設施的情況下為熱點的機率\n",
    "        a_col='hotspot', a_is='Hotspot',\n",
    "        b_col='facility', b_rule='>0',\n",
    "        # 行車管制號誌的情況下為熱點的機率\n",
    "        # a_col='hotspot', a_is='Hotspot',\n",
    "        # b_col='號誌-號誌種類名稱_行車管制號誌', b_rule='>0',\n",
    "        # 無路面邊線的情況下為熱點的機率\n",
    "        # a_col='hotspot', a_is='Hotspot',\n",
    "        # b_col='車道劃分設施-分道設施-路面邊線名稱_無', b_rule='>0',\n",
    "        alpha=0.5\n",
    "    )\n",
    "\n",
    "# use this for finding specific value ratios in a column\n",
    "def ratio_in_data(data, col='county_city', values='City'):\n",
    "\n",
    "    import pandas as pd\n",
    "\n",
    "    # 取出要判斷的 Series\n",
    "    if isinstance(data, pd.DataFrame):\n",
    "        s = data[col].astype(str)\n",
    "    else:\n",
    "        s = pd.Series(data).astype(str)\n",
    "\n",
    "    # 正規化欲比對的值集合\n",
    "    if isinstance(values, (list, tuple, set)):\n",
    "        target = set(map(str, values))\n",
    "        mask = s.isin(target)\n",
    "    else:\n",
    "        mask = (s == str(values))\n",
    "\n",
    "    return float(mask.mean())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24ca413c",
   "metadata": {},
   "source": [
    "**node_cond_prob**\n",
    "條件機率\n",
    "- ('hotspot', '號誌-號誌種類名稱_行車管制號誌')\n",
    "- ('hotspot', '車道劃分設施-分道設施-路面邊線名稱_無')\n",
    "- ('hotspot', 'facility')\n",
    "\n",
    "**most_common_encoded_label**\n",
    "最常出現的值\n",
    "- 'hotspot_facility'\n",
    "\n",
    "**ratio_in_data**\n",
    "在特定欄位中的值出現的比例，例如縣市中'市'的比例\n",
    "- 'county_city'\n",
    "\n",
    "**avg_label**\n",
    "節點中平均值\n",
    "- original_speed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5967eea3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from TrafficTDApythonUtils.plotsv2 import MapperPlotterSpring\n",
    "\n",
    "overlaps = [3]\n",
    "intervals = [10]\n",
    "seeds = [47]\n",
    "# seeds = [i for i in range(10, 50)]\n",
    "choose = '最高類別'\n",
    "\n",
    "for seed in seeds:\n",
    "    for overlap in overlaps:\n",
    "        for interval in intervals:\n",
    "            detailed_results_df = pickle.load(open(f\"../ComputedData/ForMatrixV2/o{overlap}i{interval}.pkl\", \"rb\"))\n",
    "            mapper_plotter = MapperPlotterSpring(\n",
    "                detailed_results_df['mapper_info'],\n",
    "                all_features_df,\n",
    "                seed=seed, iterations=130, dim=2,\n",
    "                range_lst=[-0.5, 0.5, 0.5, -0.5],\n",
    "                cmap=\"Greens\",\n",
    "                # encoded_label=node_cond_prob\n",
    "                encoded_label=most_common_encoded_label\n",
    "                # encoded_label=ratio_in_data\n",
    "                # encoded_label=avg_label\n",
    "            )\n",
    "            mapper_plotter.create_mapper_plot(choose, avg=False, size_threshold=50, plot_type='spring')\n",
    "            full_info, outliers = mapper_plotter.extract_data()\n",
    "            mapper_plotter.map_colors(threshold=0)\n",
    "            mapper_plotter.plot(set_label=True, size=500, anchor=(0,0),\n",
    "                                # save_path=f\"../ComputedData/ForMatrixV2/Plots/o{overlap}i{interval}s{seed}_{choose}.png\"\n",
    "                                )\n",
    "            # mapper_plotter.plot3d_matplotlib(\n",
    "            #     choose,\n",
    "            #     avg=False,\n",
    "            #     save_path=f\"../ComputedData/ForMatrixV2/Plots/o{overlap}i{interval}s{seed}_{choose}.png\",\n",
    "            #     size=1200, elev=22, azim=35, dpi=180\n",
    "            # )\n",
    "            # mapper_plotter.pvis(\n",
    "            #     path=\"mapper_interactive.html\",\n",
    "            #     physics_mode=\"off\",\n",
    "            #     edge_length_from_layout=True,\n",
    "            #     scale_xy=900,\n",
    "            #     node_size_cap=20,\n",
    "            #     open_browser=True\n",
    "            # )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d05a549a",
   "metadata": {},
   "source": [
    "### Deprecated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0d0cced",
   "metadata": {},
   "outputs": [],
   "source": [
    "# overlaps = [4]\n",
    "# intervals = [12]\n",
    "# seeds = [i for i in range(55, 80)]\n",
    "\n",
    "# for seed in [52]:\n",
    "#     for overlap in overlaps:\n",
    "#         for interval in intervals:\n",
    "            \n",
    "#             detailed_results_df = pickle.load(open(f\"../ComputedData/ForMatrixV2/o{overlap}i{interval}.pkl\", \"rb\"))\n",
    "#             choose = 'hotspot_youbike' # county, hotspot_youbike\n",
    "#             mapper_plotter = MapperPlotter(detailed_results_df['mapper_info'], \n",
    "#                                         all_features_df, seed=seed, iterations=50, dim=2,\n",
    "#                                             range_lst=[-0.5, 0.5, 0.5, -0.5])\n",
    "\n",
    "#             def avg_label(data):\n",
    "#                 return sum(data) / len(data) if len(data) > 0 else 0\n",
    "#             def most_common_encoded_label(data):\n",
    "#                 most_common_item = Counter(data).most_common(1)[0][0]\n",
    "#                 return most_common_item\n",
    "\n",
    "#             mapper_plot = mapper_plotter.create_mapper_plot(choose, most_common_encoded_label, avg=False)\n",
    "#             full_info = mapper_plotter.extract_data()\n",
    "#             mapper_plotter.map_colors(choose, size=30, threshold=0)\n",
    "#             mapper_plotter.plot(choose, avg=False, set_label=True, size=500, anchor=1,\n",
    "#                                 # save_path=f\"../ComputedData/ForMatrixV2/Plots/o{overlap}i{interval}s{seed}_{choose}.png\"\n",
    "#                                 )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ST-RTA",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
