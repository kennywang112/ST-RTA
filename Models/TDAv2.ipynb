{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "59265153",
   "metadata": {},
   "source": [
    "This code is to optimize TDA.ipynb file, the main change is using three main function as the filter function:\n",
    "1. eccentricity\n",
    "2. PCA\n",
    "3. KDE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10894c08",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "current_dir = os.getcwd()\n",
    "parent_dir = os.path.dirname(current_dir)\n",
    "analyze_path = os.path.join(parent_dir, \"utils\")\n",
    "\n",
    "os.chdir(analyze_path)\n",
    "\n",
    "import ast\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import pickle\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA\n",
    "from tdam.cover import CubicalCover\n",
    "from tdam.clustering import FailSafeClustering\n",
    "from tdam.core_old import MapperAlgorithm\n",
    "from sklearn.metrics import pairwise_distances\n",
    "from sklearn.neighbors import KernelDensity\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import StandardScaler, normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79249fdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "from shapely import wkt\n",
    "\n",
    "TM2 = 3826\n",
    "\n",
    "# 原始以 0.001 grid 計算出的區域事故及對應索引, 依照 hex_grid 計算出來的GI\n",
    "grid_gi_df = pd.read_csv('../ComputedData/Grid/grid_gi.csv')\n",
    "grid_gi_df['accident_indices'] = grid_gi_df['accident_indices'].apply(ast.literal_eval)\n",
    "grid_gi_df['geometry'] = grid_gi_df['geometry'].apply(wkt.loads)\n",
    "grid_gi  = gpd.GeoDataFrame(grid_gi_df, geometry='geometry').set_crs(TM2, allow_override=True)\n",
    "grid_gi['geometry'] = grid_gi.geometry.centroid\n",
    "\n",
    "# 熱點屬於哪一個城市\n",
    "taiwan = gpd.read_file('../Data/OFiles_9e222fea-bafb-4436-9b17-10921abc6ef2/TOWN_MOI_1140318.shp')\n",
    "taiwan = taiwan[(~taiwan['TOWNNAME'].isin(['旗津區', '頭城鎮', '蘭嶼鄉', '綠島鄉', '琉球鄉'])) & \n",
    "                (~taiwan['COUNTYNAME'].isin(['金門縣', '連江縣', '澎湖縣']))].to_crs(TM2)\n",
    "taiwan_cnty = taiwan[['COUNTYNAME','geometry']].dissolve(by='COUNTYNAME')\n",
    "taiwan_cnty['geometry'] = taiwan_cnty.buffer(0)\n",
    "\n",
    "county_join = gpd.sjoin(grid_gi[['geometry']], taiwan_cnty, how='left', predicate='within')\n",
    "grid_gi['COUNTYNAME'] = county_join['COUNTYNAME']\n",
    "\n",
    "grid_filter = grid_gi[grid_gi['accident_indices'].str.len() > 0]\n",
    "grid_filter.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2db44984",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is same as all_features but adding hotspot only\n",
    "all_features_df = pd.read_csv(\"../ComputedData/ForModel/all_featuresV2.csv\")\n",
    "cols = all_features_df.columns[all_features_df.columns.str.contains('事故位置大類別名稱')] # 高共線\n",
    "all_features_df.drop(columns=cols, inplace=True)\n",
    "all_features_df.drop(columns=['hotspot'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a16bb0d",
   "metadata": {},
   "source": [
    "# Mapper\n",
    "Get filtered_data by running FilterforMapper.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26c6727f",
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_full = pd.read_csv(\"../ComputedData/ForModel/filtered_data.csv\")\n",
    "filter_full.drop(columns=['pc4', 'pc5'], inplace=True)\n",
    "filter_full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba34267a",
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_full = pd.read_csv(\"../ComputedData/ForModel/filtered_data.csv\")\n",
    "filter_full.drop(columns=['pc4', 'pc5'], inplace=True)\n",
    "\n",
    "overlaps = [3]\n",
    "intervals = [10]\n",
    "detailed_results = []\n",
    "silhouette_for_intervals = []\n",
    "\n",
    "for overlap in overlaps:\n",
    "    for interval in intervals:\n",
    "        print(f\"Processing overlap {overlap}, interval {interval}\")\n",
    "        mapper_algo = MapperAlgorithm(\n",
    "            cover=CubicalCover(\n",
    "                n_intervals=interval,\n",
    "                overlap_frac=overlap / 10\n",
    "            ),\n",
    "            clustering=FailSafeClustering(\n",
    "                KMeans(\n",
    "                    n_clusters=2,\n",
    "                    random_state=42\n",
    "                )\n",
    "            ),\n",
    "            n_jobs=-1\n",
    "        )\n",
    "\n",
    "        mapper_info = mapper_algo.fit_transform(all_features_df.to_numpy(), filter_full)\n",
    "\n",
    "        silhouette_for_intervals.append(mapper_info[1])\n",
    "        result = {\n",
    "            \"overlap\": overlap,\n",
    "            \"interval\": interval,\n",
    "            \"silhouette\": mapper_info[1],\n",
    "            \"mapper_info\": mapper_info\n",
    "        }\n",
    "        detailed_results.append(result)\n",
    "\n",
    "        # with open(f\"../ComputedData/ForMatrixV2/o{overlap}i{interval}.pkl\", 'wb') as file:\n",
    "        #     pickle.dump(result, file)\n",
    "\n",
    "detailed_results_df = pd.DataFrame(detailed_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2063ef50",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils_tda import get_max_categories\n",
    "\n",
    "col = '道路型態大類別名稱'\n",
    "all_features_df['最高類別'] = all_features_df.apply(get_max_categories, axis=1)\n",
    "all_features_df['最高類別'].value_counts()\n",
    "\n",
    "all_features_df['county'] = grid_filter['COUNTYNAME']\n",
    "all_features_df['hotspot'] = grid_filter['hotspot']\n",
    "all_features_df['hotspot'] = all_features_df['hotspot'].apply(lambda x: 'Hotspot' if 'Hotspot' in str(x) else 'Not Hotspot')\n",
    "all_features_df['facility'] = all_features_df[['youbike_100m_count_mean', 'mrt_100m_count_mean', 'parkinglot_100m_count_mean']].apply(\n",
    "    lambda row: '1' if (row > 0).any() else '0', axis=1\n",
    ")\n",
    "all_features_df['hotspot_facility'] = all_features_df['hotspot'] + '_' + all_features_df['facility']\n",
    "all_features_df['facility'] = all_features_df['facility'].astype(int) \n",
    "all_features_df['county_city'] = all_features_df['county'].apply(lambda x: 'City' if '市' in str(x) else 'County')\n",
    "\n",
    "all_features_df_speed = pd.read_csv('../ComputedData/ForModel/all_features_df-速限.csv')\n",
    "all_features_df['original_speed'] = all_features_df_speed['速限-第1當事者_mean']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba59a9d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_features_df['bn_feature'] = all_features_df.apply(\n",
    "    lambda row: 1 if (\n",
    "        (\n",
    "        (\n",
    "            (row['道路型態大類別名稱_單路部分'] > 0) or\n",
    "            (row['道路型態大類別名稱_其他'] > 0) or\n",
    "            (row['道路型態大類別名稱_圓環廣場'] > 0) or\n",
    "            (row['道路型態大類別名稱_平交道'] > 0) or\n",
    "            (row['道路型態大類別名稱_交岔路'] > 0)\n",
    "            ) and\n",
    "        (\n",
    "            (row['號誌-號誌種類名稱_行車管制號誌(附設行人專用號誌)'] > 0) or\n",
    "            (row['號誌-號誌種類名稱_行車管制號誌'] > 0) or\n",
    "            (row['號誌-號誌種類名稱_閃光號誌'] > 0) or\n",
    "            (row['號誌-號誌種類名稱_無號誌'] > 0)\n",
    "            ) and\n",
    "        (\n",
    "            (row['道路類別-第1當事者-名稱_市區道路'] > 0)\n",
    "            ) and\n",
    "        (\n",
    "            (row['original_speed'] < 50)\n",
    "            ) and\n",
    "        (\n",
    "            (row['facility'] > 0)\n",
    "            )\n",
    "        )\n",
    "    ) else 0,\n",
    "    axis=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9616fef",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "from utils_tda import avg_label, most_common_encoded_label, cond_prob_mixed\n",
    "\n",
    "# use this for finding specific value ratios in a column\n",
    "def ratio_in_data(data, col='hotspot', values='Hotspot'):\n",
    "    \"\"\"\n",
    "    choose = 'county_city'\n",
    "    \"\"\"\n",
    "    # 取出要判斷的 Series\n",
    "    if isinstance(data, pd.DataFrame):\n",
    "        s = data[col].astype(str)\n",
    "    else:\n",
    "        s = pd.Series(data).astype(str)\n",
    "\n",
    "    # 正規化欲比對的值集合\n",
    "    if isinstance(values, (list, tuple, set)):\n",
    "        target = set(map(str, values))\n",
    "        mask = s.isin(target)\n",
    "    else:\n",
    "        mask = (s == str(values))\n",
    "\n",
    "    return float(mask.mean())\n",
    "\n",
    "def node_cond_prob(subdf):\n",
    "    \"\"\"\n",
    "    This is conditional probability\n",
    "    choose = ('hotspot', 'facility')\n",
    "    choose = ('hotspot', '車道劃分設施-分道設施-路面邊線名稱_無')\n",
    "    choose = ('hotspot', '號誌-號誌種類名稱_行車管制號誌')\n",
    "    \"\"\"\n",
    "\n",
    "    return cond_prob_mixed(\n",
    "        subdf=subdf,\n",
    "        # 有設施的情況下為熱點的機率\n",
    "        # a_col='hotspot', a_is='Hotspot',\n",
    "        # b_col='facility', b_rule='>0',\n",
    "        # 行車管制號誌的情況下為熱點的機率\n",
    "        # a_col='hotspot', a_is='Hotspot',\n",
    "        # b_col='號誌-號誌種類名稱_行車管制號誌', b_rule='>0',\n",
    "        # 無路面邊線的情況下為熱點的機率\n",
    "        # a_col='hotspot', a_is='Hotspot',\n",
    "        # b_col='車道劃分設施-分道設施-路面邊線名稱_無', b_rule='>0',\n",
    "        # 交岔路的情況下為熱點的機率\n",
    "        # a_col='hotspot', a_is='Hotspot',\n",
    "        # b_col='道路型態大類別名稱_交岔路', b_rule='>0',\n",
    "        # 針對bn分析做的圖\n",
    "        a_col='hotspot', a_is='Hotspot',\n",
    "        b_col='bn_feature', b_rule='>0',\n",
    "        alpha=0.5,\n",
    "        condition=\"B|A\"\n",
    "    )\n",
    "\n",
    "# # 用來檢查條件機率效果\n",
    "# test = all_features_df[['hotspot', '號誌-號誌種類名稱_行車管制號誌']].copy()\n",
    "# test['號誌-號誌種類名稱_行車管制號誌'] = test['號誌-號誌種類名稱_行車管制號誌'].apply(lambda x: 1 if x > 0.5 else 0)\n",
    "# test[['hotspot', '號誌-號誌種類名稱_行車管制號誌']].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5967eea3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from TrafficTDApythonUtils.plotsv2 import MapperPlotterSpring\n",
    "\n",
    "oi = 'o3i10'\n",
    "choose = 'hotspot'\n",
    "\n",
    "detailed_results_df = pickle.load(open(f\"../ComputedData/ForMatrixV2/{oi}.pkl\", \"rb\"))\n",
    "mapper_plotter = MapperPlotterSpring(\n",
    "    detailed_results_df['mapper_info'],\n",
    "    all_features_df,\n",
    "    seed=47, iterations=130, dim=2,\n",
    "    range_lst=[-0.5, 0.5, 0.5, -0.5],\n",
    "    cmap=\"Reds\",\n",
    "    encoded_label=ratio_in_data\n",
    ")\n",
    "mapper_plotter.create_mapper_plot(choose, avg=True, size_threshold=50, plot_type='spring')\n",
    "full_info, outliers = mapper_plotter.extract_data()\n",
    "mapper_plotter.map_colors(threshold=0)\n",
    "mapper_plotter.plot(set_label=True, size=500, anchor=(0,0),\n",
    "                    # save_path=f\"../ComputedData/ForMatrixV2/Plots/{oi}.png\"\n",
    "                    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "391c8e6f",
   "metadata": {},
   "source": [
    "### 這是用來找出哪兩種特徵下熱點集中區有組合"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22ac5710",
   "metadata": {},
   "outputs": [],
   "source": [
    "from TrafficTDApythonUtils.plotsv2 import MapperPlotterSpring\n",
    "\n",
    "As = ['道路型態大類別名稱_單路部分', '道路型態大類別名稱_交岔路', '道路型態大類別名稱_其他', '道路型態大類別名稱_圓環廣場', '道路型態大類別名稱_平交道']\n",
    "Bs = ['號誌-號誌種類名稱_無號誌', '號誌-號誌種類名稱_行車管制號誌', '號誌-號誌種類名稱_閃光號誌', '號誌-號誌種類名稱_行車管制號誌(附設行人專用號誌)']\n",
    "\n",
    "# choose = ('hotspot', 'bn_feature')\n",
    "choose = 'bn_feature'\n",
    "overlap = 3\n",
    "interval = 10\n",
    "seed = 47\n",
    "\n",
    "for a in As:\n",
    "    for b in Bs:\n",
    "\n",
    "        all_features_df['bn_feature'] = all_features_df.apply(\n",
    "            lambda row: 1 if (\n",
    "                (row[a] > 0) and\n",
    "                (row[b] > 0)\n",
    "            ) else 0,\n",
    "            axis=1\n",
    "        )\n",
    "        detailed_results_df = pickle.load(open(f\"../ComputedData/ForMatrixV2/o{overlap}i{interval}.pkl\", \"rb\"))\n",
    "        mapper_plotter = MapperPlotterSpring(\n",
    "            detailed_results_df['mapper_info'],\n",
    "            all_features_df,\n",
    "            seed=seed, iterations=130, dim=2,\n",
    "            range_lst=[-0.5, 0.5, 0.5, -0.5],\n",
    "            cmap=\"Greens\",\n",
    "            # encoded_label=node_cond_prob\n",
    "            encoded_label=ratio_in_data\n",
    "        )\n",
    "        mapper_plotter.create_mapper_plot(choose, avg=True, size_threshold=50, plot_type='spring')\n",
    "        full_info, outliers = mapper_plotter.extract_data()\n",
    "        mapper_plotter.map_colors(threshold=0)\n",
    "        mapper_plotter.plot(set_label=True, size=500, anchor=(0,0),\n",
    "                            save_path=f\"../ComputedData/ForMatrixV2/PlotsRatio/o{overlap}i{interval}s{seed}_{choose}_{a}_{b}.png\"\n",
    "                            )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15c35209",
   "metadata": {},
   "source": [
    "### 這是用來grid search的"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb6e24f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from TrafficTDApythonUtils.plotsv2 import MapperPlotterSpring\n",
    "\n",
    "overlaps = [3]\n",
    "intervals = [10]\n",
    "seeds = [47]\n",
    "# seeds = [i for i in range(10, 50)]\n",
    "# choose = ('hotspot', 'bn_feature')\n",
    "choose = 'hotspot'\n",
    "\n",
    "for seed in seeds:\n",
    "    for overlap in overlaps:\n",
    "        for interval in intervals:\n",
    "            detailed_results_df = pickle.load(open(f\"../ComputedData/ForMatrixV2/o{overlap}i{interval}.pkl\", \"rb\"))\n",
    "            mapper_plotter = MapperPlotterSpring(\n",
    "                detailed_results_df['mapper_info'],\n",
    "                all_features_df,\n",
    "                seed=seed, iterations=130, dim=2,\n",
    "                range_lst=[-0.5, 0.5, 0.5, -0.5],\n",
    "                cmap=\"Reds\",\n",
    "                # encoded_label=node_cond_prob\n",
    "                # encoded_label=most_common_encoded_label\n",
    "                encoded_label=ratio_in_data\n",
    "                # encoded_label=avg_label\n",
    "            )\n",
    "            mapper_plotter.create_mapper_plot(choose, avg=True, size_threshold=50, plot_type='spring')\n",
    "            full_info, outliers = mapper_plotter.extract_data()\n",
    "            mapper_plotter.map_colors(threshold=0)\n",
    "            mapper_plotter.plot(set_label=True, size=500, anchor=(0,0),\n",
    "                                # save_path=f\"../ComputedData/ForMatrixV2/Plots/o{overlap}i{interval}s{seed}_{choose}.png\"\n",
    "                                )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ST-RTA",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
