{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "59265153",
   "metadata": {},
   "source": [
    "This code is to optimize TDA.ipynb file, the main change is using three main function as the filter function:\n",
    "1. Eccentricity\n",
    "2. PCA\n",
    "3. KDE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10894c08",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "current_dir = os.getcwd()\n",
    "parent_dir = os.path.dirname(current_dir)\n",
    "analyze_path = os.path.join(parent_dir, \"utils\")\n",
    "\n",
    "os.chdir(analyze_path)\n",
    "\n",
    "import ast\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import pickle\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA\n",
    "from tdam.cover import CubicalCover\n",
    "from tdam.clustering import FailSafeClustering\n",
    "from tdam.core_old import MapperAlgorithm\n",
    "from sklearn.metrics import pairwise_distances\n",
    "from sklearn.neighbors import KernelDensity\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import StandardScaler, normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79249fdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "from shapely import wkt\n",
    "\n",
    "TM2 = 3826\n",
    "\n",
    "# 原始以 0.001 grid 計算出的區域事故及對應索引, 依照 hex_grid 計算出來的GI\n",
    "grid_gi_df = pd.read_csv('../ComputedData/Grid/grid_giV2.csv')\n",
    "grid_gi_df['accident_indices'] = grid_gi_df['accident_indices'].apply(ast.literal_eval)\n",
    "grid_gi_df['geometry'] = grid_gi_df['geometry'].apply(wkt.loads)\n",
    "grid_gi = gpd.GeoDataFrame(grid_gi_df, geometry='geometry').set_crs(TM2, allow_override=True)\n",
    "grid_gi['geometry'] = grid_gi.geometry.centroid\n",
    "\n",
    "# 熱點屬於哪一個城市\n",
    "taiwan = gpd.read_file('../Data/OFiles_9e222fea-bafb-4436-9b17-10921abc6ef2/TOWN_MOI_1140318.shp')\n",
    "taiwan = taiwan[(~taiwan['TOWNNAME'].isin(['旗津區', '頭城鎮', '蘭嶼鄉', '綠島鄉', '琉球鄉'])) & \n",
    "                (~taiwan['COUNTYNAME'].isin(['金門縣', '連江縣', '澎湖縣']))].to_crs(TM2)\n",
    "taiwan_cnty = taiwan[['COUNTYNAME','geometry']].dissolve(by='COUNTYNAME')\n",
    "taiwan_cnty['geometry'] = taiwan_cnty.buffer(0)\n",
    "\n",
    "county_join = gpd.sjoin(grid_gi[['geometry']], taiwan_cnty, how='left', predicate='within')\n",
    "grid_gi['COUNTYNAME'] = county_join['COUNTYNAME']\n",
    "\n",
    "grid_filter = grid_gi[grid_gi['accident_indices'].str.len() > 0]\n",
    "grid_filter.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2db44984",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is same as all_features but adding hotspot only\n",
    "all_features_df = pd.read_csv(\"../ComputedData/ForModel/all_featuresV2.csv\")\n",
    "\n",
    "cols1 = all_features_df.columns[all_features_df.columns.str.contains('事故位置大類別名稱')]\n",
    "all_features_df.drop(columns=cols1, inplace=True)\n",
    "\n",
    "cols2 = all_features_df.columns[all_features_df.columns.str.contains('號誌動作')]\n",
    "cols3 = all_features_df.columns[all_features_df.columns.str.contains('hotspot')]\n",
    "all_features_df.drop(columns=cols2, inplace=True)\n",
    "all_features_df.drop(columns=cols3, inplace=True)\n",
    "\n",
    "forspeed = pd.read_csv(\"../ComputedData/ForModel/all_featuresV2.csv\")\n",
    "speed = forspeed['original_speed']\n",
    "all_features_df.drop(columns=['original_speed'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a16bb0d",
   "metadata": {},
   "source": [
    "# Mapper\n",
    "Get filtered_data by running FilterforMapper.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba34267a",
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_full = pd.read_csv(\"../ComputedData/ForModel/filtered_data_test.csv\")\n",
    "filter_full.drop(columns=['pc4', 'pc5'], inplace=True)\n",
    "\n",
    "overlaps = [3]\n",
    "intervals = [11]\n",
    "detailed_results = []\n",
    "silhouette_for_intervals = []\n",
    "\n",
    "for overlap in overlaps:\n",
    "    for interval in intervals:\n",
    "        print(f\"Processing overlap {overlap}, interval {interval}\")\n",
    "        mapper_algo = MapperAlgorithm(\n",
    "            cover=CubicalCover(\n",
    "                n_intervals=interval,\n",
    "                overlap_frac=overlap / 10\n",
    "            ),\n",
    "            clustering=FailSafeClustering(\n",
    "                KMeans(\n",
    "                    n_clusters=2,\n",
    "                    random_state=42\n",
    "                )\n",
    "            ),\n",
    "            n_jobs=-1\n",
    "        )\n",
    "\n",
    "        mapper_info = mapper_algo.fit_transform(all_features_df.to_numpy(), filter_full)\n",
    "\n",
    "        silhouette_for_intervals.append(mapper_info[1])\n",
    "        result = {\n",
    "            \"overlap\": overlap,\n",
    "            \"interval\": interval,\n",
    "            \"silhouette\": mapper_info[1],\n",
    "            \"mapper_info\": mapper_info\n",
    "        }\n",
    "        detailed_results.append(result)\n",
    "\n",
    "        with open(f\"../ComputedData/ForMatrixV2/o{overlap}i{interval}_test.pkl\", 'wb') as file:\n",
    "            pickle.dump(result, file)\n",
    "\n",
    "detailed_results_df = pd.DataFrame(detailed_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2063ef50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from utils_tda import get_max_categories\n",
    "def get_max_categories(row):\n",
    "\n",
    "    cols = all_features_df.columns[all_features_df.columns.str.contains(col)]\n",
    "\n",
    "    max_val = row[cols].max()\n",
    "    max_cols = row[cols][row[cols] == max_val].index\n",
    "    # 取底線後面的類別名稱，用逗號串起來\n",
    "    return ','.join(col.split('_')[-1] for col in max_cols)\n",
    "\n",
    "col = '道路類別-第1當事者-名稱'\n",
    "all_features_df['最高類別'] = all_features_df.apply(get_max_categories, axis=1)\n",
    "all_features_df['最高類別'].value_counts()\n",
    "\n",
    "all_features_df['county'] = grid_filter['COUNTYNAME']\n",
    "all_features_df['hotspot'] = grid_filter['hotspot']\n",
    "all_features_df['county_city'] = all_features_df['county'].apply(lambda x: 'City' if '市' in str(x) else 'County')\n",
    "all_features_df['hotspot'] = all_features_df['hotspot'].apply(lambda x: 'Hotspot' if 'Hotspot' in str(x) else 'Not Hotspot')\n",
    "\n",
    "all_features_df['facility'] = all_features_df[['youbike_100m_count_mean', 'mrt_100m_count_mean', 'parkinglot_100m_count_mean']].apply(\n",
    "    lambda row: '1' if (row > 0).any() else '0', axis=1\n",
    ")\n",
    "all_features_df['hotspot_facility'] = all_features_df['hotspot'] + '_' + all_features_df['facility']\n",
    "all_features_df['facility'] = all_features_df['facility'].astype(int) \n",
    "all_features_df['original_speed'] = speed\n",
    "\n",
    "all_features_df['最高類別2'] = all_features_df.apply(\n",
    "    lambda row: '市區道路' if (row['最高類別'] == '市區道路') else '非市區道路',\n",
    "    axis=1\n",
    ")\n",
    "all_features_df['bn_feature'] = all_features_df.apply(\n",
    "    lambda row: 1 if (\n",
    "        (\n",
    "        (\n",
    "            (row['道路型態大類別名稱_單路部分'] > 0) or\n",
    "            (row['道路型態大類別名稱_其他'] > 0) or\n",
    "            (row['道路型態大類別名稱_圓環廣場'] > 0) or\n",
    "            (row['道路型態大類別名稱_平交道'] > 0) or\n",
    "            (row['道路型態大類別名稱_交岔路'] > 0)\n",
    "            ) and\n",
    "        (\n",
    "            (row['號誌-號誌種類名稱_行車管制號誌(附設行人專用號誌)'] > 0) or\n",
    "            (row['號誌-號誌種類名稱_行車管制號誌'] > 0) or\n",
    "            (row['號誌-號誌種類名稱_閃光號誌'] > 0) or\n",
    "            (row['號誌-號誌種類名稱_無號誌'] > 0)\n",
    "            ) and\n",
    "        (\n",
    "            (row['道路類別-第1當事者-名稱_市區道路'] > 0)\n",
    "            ) and\n",
    "        (\n",
    "            (row['original_speed'] < 50)\n",
    "            ) and\n",
    "        (\n",
    "            (row['facility'] > 0)\n",
    "            )\n",
    "        )\n",
    "    ) else 0,\n",
    "    axis=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f9e9171",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "from sklearn.metrics import pairwise_distances\n",
    "from sklearn.preprocessing import normalize\n",
    "# from utils_tda import avg_label, most_common_encoded_label, cond_prob_mixed\n",
    "\n",
    "# use this for finding specific value ratios in a column\n",
    "def ratio_in_data(data, col='county_city', values='City'):\n",
    "    \"\"\"\n",
    "    choose = 'county_city'\n",
    "    \"\"\"\n",
    "    # 取出要判斷的 Series\n",
    "    if isinstance(data, pd.DataFrame):\n",
    "        s = data[col].astype(str)\n",
    "    else:\n",
    "        s = pd.Series(data).astype(str)\n",
    "\n",
    "    # 正規化欲比對的值集合\n",
    "    if isinstance(values, (list, tuple, set)):\n",
    "        target = set(map(str, values))\n",
    "        mask = s.isin(target)\n",
    "    else:\n",
    "        mask = (s == str(values))\n",
    "\n",
    "    return float(mask.mean())\n",
    "\n",
    "def linf_centrality_exact(df, block_size = 2000):\n",
    "    \"\"\"\n",
    "    回傳 shape=(n,1) 的 L∞ centrality（每點到最遠點的距離）。\n",
    "    - metric: \"cosine\" 或 \"euclidean\"\n",
    "    - block_size: 控制記憶體 (block_size * n distances)\n",
    "    \"\"\"\n",
    "    X = df.to_numpy(dtype=float)\n",
    "    n = X.shape[0]\n",
    "    # 對每一列作 L2 正規化才能用 cosine 距離\n",
    "    X = normalize(X, norm=\"l2\", axis=1)\n",
    "\n",
    "    # 準備結果陣列，初始為無窮小\n",
    "    max_d = np.full(n, -np.inf, dtype=float)\n",
    "    order = np.arange(n) # 保留原順序\n",
    "    \n",
    "    # 分塊計算 pairwise 距離以控制記憶體\n",
    "    for start in range(0, n, block_size):\n",
    "        idx = order[start:start+block_size]\n",
    "        D_blk = pairwise_distances(X[idx], X, metric='cosine')  # (b, n)\n",
    "        # 自身距離設為 -inf，避免影響 max\n",
    "        D_blk[np.arange(D_blk.shape[0]), idx] = -np.inf\n",
    "        # 針對每個 i（在 idx 中），更新它的全域最遠距離\n",
    "        max_d[idx] = np.maximum(max_d[idx], D_blk.max(axis=1))\n",
    "\n",
    "    return max_d.reshape(-1, 1)\n",
    "\n",
    "def get_max_categories(row):\n",
    "\n",
    "    cols = all_features_df.columns[all_features_df.columns.str.contains(col)]\n",
    "\n",
    "    max_val = row[cols].max()\n",
    "    max_cols = row[cols][row[cols] == max_val].index\n",
    "    # 取底線後面的類別名稱，用逗號串起來\n",
    "    return ','.join(col.split('_')[-1] for col in max_cols)\n",
    "\n",
    "def avg_label(data):\n",
    "    \"\"\"\n",
    "    choose = 'original_speed'\n",
    "    \"\"\"\n",
    "    return sum(data) / len(data) if len(data) > 0 else 0\n",
    "\n",
    "def most_common_encoded_label(data):\n",
    "    \"\"\"\n",
    "    choose = 'hotspot_facility'\n",
    "    \"\"\"\n",
    "    return Counter(data).most_common(1)[0][0]\n",
    "\n",
    "# conditional probability\n",
    "def cond_prob_mixed(\n",
    "        subdf, \n",
    "        a_col='hotspot', \n",
    "        a_is='Hotspot', \n",
    "        b_col='bn_feature', \n",
    "        b_rule=\">0\",\n",
    "        alpha=0.5, min_den=0, condition=\"B|A\"\n",
    "    ):\n",
    "    \"\"\"\n",
    "    回傳條件機率：\n",
    "        - A : 類別欄位, a_is 可為 str 或 可迭代(多類別集合)\n",
    "        - B : 可為數值/比例欄位，用 b_rule 指定成立條件(或傳入 callable)\n",
    "        - alpha : Laplace smoothing\n",
    "        - min_den : A 成立的樣本至少要有幾個，否則回 NaN\n",
    "        - condition=\"B|A\": P(B | A)(預設；與你原本一致，分母=|A|)\n",
    "        - condition=\"A|B\": P(A | B)(反過來，分母=|B|)\n",
    "\n",
    "    其他參數說明同前。\n",
    "    \"\"\"\n",
    "\n",
    "    # A: 類別欄位是否落在 a_is 這個集合\n",
    "    Aset = {a_is} if isinstance(a_is, str) else set(a_is)\n",
    "    A = subdf[a_col].astype(str)\n",
    "    mask_A = A.isin(Aset)\n",
    "\n",
    "    # B: 數值/比例欄位是否滿足 b_rule\n",
    "    s = pd.to_numeric(subdf[b_col], errors='coerce')\n",
    "    if callable(b_rule):\n",
    "        mask_B = b_rule(s)\n",
    "    else:\n",
    "        rule = str(b_rule).strip()\n",
    "        if rule == \">0\":\n",
    "            mask_B = (s > 0)\n",
    "        elif rule == \">=0\":\n",
    "            mask_B = (s >= 0)\n",
    "        elif rule.startswith(\">=\"):\n",
    "            thr = float(rule[2:]); mask_B = (s >= thr)\n",
    "        elif rule.startswith(\">\"):\n",
    "            thr = float(rule[1:]); mask_B = (s > thr)\n",
    "        elif rule.startswith(\"<=\"):\n",
    "            thr = float(rule[2:]); mask_B = (s <= thr)\n",
    "        elif rule.startswith(\"<\"):\n",
    "            thr = float(rule[1:]); mask_B = (s < thr)\n",
    "        elif rule.startswith(\"==\"):\n",
    "            thr = float(rule[2:]); mask_B = (s == thr)\n",
    "        else:\n",
    "            raise ValueError(\"Unknown b_rule\")\n",
    "\n",
    "    # 共同分子\n",
    "    num = (mask_A & mask_B).sum()\n",
    "\n",
    "    # 選擇分母（誰是條件）\n",
    "    if condition.upper() == \"B|A\":\n",
    "        den = mask_A.sum()    # P(B|A)\n",
    "    elif condition.upper() == \"A|B\":\n",
    "        den = mask_B.sum()    # P(A|B)\n",
    "    else:\n",
    "        raise ValueError(\"condition must be 'B|A' or 'A|B'\")\n",
    "\n",
    "    if den < min_den:\n",
    "        return float('nan')\n",
    "\n",
    "    # 對稱的拉普拉斯平滑\n",
    "    return float((num + alpha) / (den + 2 * alpha))\n",
    "\n",
    "# # 用來檢查條件機率效果\n",
    "# test = all_features_df[['hotspot', '號誌-號誌種類名稱_行車管制號誌']].copy()\n",
    "# test['號誌-號誌種類名稱_行車管制號誌'] = test['號誌-號誌種類名稱_行車管制號誌'].apply(lambda x: 1 if x > 0.5 else 0)\n",
    "# test[['hotspot', '號誌-號誌種類名稱_行車管制號誌']].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5967eea3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from TrafficTDApythonUtils.plotsv2 import MapperPlotterSpring\n",
    "\n",
    "oi = 'o3i10'\n",
    "choose = '最高類別'\n",
    "\n",
    "# detailed_results_df = pickle.load(open(f\"../ComputedData/ForMatrixV2/{oi}.pkl\", \"rb\"))\n",
    "mapper_plotter = MapperPlotterSpring(\n",
    "    detailed_results_df['mapper_info'][0],\n",
    "    all_features_df,\n",
    "    seed=47, iterations=100, dim=2,\n",
    "    range_lst=[-0.5, 0.5, 0.5, -0.5],\n",
    "    cmap=\"Reds\",\n",
    "    encoded_label=most_common_encoded_label\n",
    ")\n",
    "mapper_plotter.create_mapper_plot(choose, avg=False, size_threshold=50, plot_type='spring')\n",
    "full_info, outliers = mapper_plotter.extract_data()\n",
    "mapper_plotter.map_colors(threshold=0)\n",
    "mapper_plotter.plot(set_label=True, size=500, anchor=(0,0),\n",
    "                    # save_path=f\"../ComputedData/ForMatrixV2/Plots/{oi}.png\"\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46ff9cb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from TrafficTDApythonUtils.plotsv2 import MapperPlotterSpring\n",
    "\n",
    "choose = 'county_city'\n",
    "\n",
    "detailed_results_df = pickle.load(open(f\"../ComputedData/ForMatrixV2/o3i10_test.pkl\", \"rb\"))\n",
    "\n",
    "for i in range(50, 160, 10):\n",
    "    mapper_plotter = MapperPlotterSpring(\n",
    "        detailed_results_df['mapper_info'],\n",
    "        all_features_df,\n",
    "        seed=54, iterations=i, dim=2,\n",
    "        range_lst=[-0.5, 0.5, 0.5, -0.5],\n",
    "        cmap=\"Greens\",\n",
    "        encoded_label=ratio_in_data\n",
    "    )\n",
    "    mapper_plotter.create_mapper_plot(choose, avg=True, size_threshold=50, plot_type='spring')\n",
    "    full_info, outliers = mapper_plotter.extract_data()\n",
    "    mapper_plotter.map_colors(threshold=0)\n",
    "    mapper_plotter.plot(set_label=True, size=500, anchor=(0,0),\n",
    "                        save_path=f\"../ComputedData/ForMatrixTest/138_{i}.png\"\n",
    "                        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "251c4f5c",
   "metadata": {},
   "source": [
    "### 這是在獲取最佳拓樸圖後要跑的結果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6a2b035",
   "metadata": {},
   "outputs": [],
   "source": [
    "books = { \n",
    "    '最高類別': {\n",
    "        'label': most_common_encoded_label,\n",
    "        'avg': False,\n",
    "        'color': 'jet',\n",
    "    },\n",
    "    ('hotspot', '車道劃分設施-分道設施-路面邊線名稱_無'): {\n",
    "        'label': cond_prob_mixed,\n",
    "        'avg': True,\n",
    "        'params': {'a_col': 'hotspot', 'a_is': 'Hotspot',\n",
    "                   'b_col': '車道劃分設施-分道設施-路面邊線名稱_無', 'b_rule': '>0'},\n",
    "        'color': 'Blues'\n",
    "    },\n",
    "    ('hotspot', '號誌-號誌種類名稱_行車管制號誌'): {\n",
    "        'label': cond_prob_mixed,\n",
    "        'avg': True,\n",
    "        'params': {'a_col': 'hotspot', 'a_is': 'Hotspot',\n",
    "                   'b_col': '號誌-號誌種類名稱_行車管制號誌', 'b_rule': '>0'},\n",
    "        'color': 'Blues'\n",
    "    },\n",
    "    ('hotspot', 'facility'): {\n",
    "        'label': cond_prob_mixed,\n",
    "        'avg': True,\n",
    "        'params': {'a_col': 'hotspot', 'a_is': 'Hotspot',\n",
    "                   'b_col': 'facility', 'b_rule': '>0'},\n",
    "        'color': 'Blues'\n",
    "    },\n",
    "    'hotspot': {\n",
    "        'label': ratio_in_data,\n",
    "        'avg': True,\n",
    "        'params': {'col': 'hotspot', 'values': 'Hotspot'},\n",
    "        'color': 'Greens'\n",
    "        },\n",
    "    'bn_feature': {\n",
    "        'label': ratio_in_data,\n",
    "        'avg': True,\n",
    "        'params': {'col': 'bn_feature', 'values': 1},\n",
    "        'color': 'Reds'\n",
    "    },\n",
    "    'county_city': {\n",
    "        'label': ratio_in_data,\n",
    "        'avg': True,\n",
    "        'params': {'col': 'county_city', 'values': 'City'},\n",
    "        'color': 'Greens'\n",
    "    },\n",
    "    'original_speed': {\n",
    "        'label': avg_label,\n",
    "        'avg': True,\n",
    "        'color': 'Greens'\n",
    "    },\n",
    "}\n",
    "\n",
    "from functools import partial\n",
    "\n",
    "for name, book in books.items():\n",
    "\n",
    "    func = book['label']\n",
    "    if 'params' in book:\n",
    "        func = partial(func, **book['params'])\n",
    "\n",
    "    mapper_plotter = MapperPlotterSpring(\n",
    "        detailed_results_df['mapper_info'][0],\n",
    "        all_features_df,\n",
    "        seed=47, iterations=100, dim=2,\n",
    "        range_lst=[-0.5, 0.5, 0.5, -0.5],\n",
    "        cmap=book['color'],\n",
    "        encoded_label=func\n",
    "    )\n",
    "    mapper_plotter.create_mapper_plot(choose=name, avg=book['avg'], size_threshold=50, plot_type='spring')\n",
    "    full_info, outliers = mapper_plotter.extract_data()\n",
    "    mapper_plotter.map_colors(threshold=0)\n",
    "    mapper_plotter.plot(set_label=True, size=500, anchor=(0,0),\n",
    "                        # save_path=f\"../ComputedData/ForMatrixV2/Plots/{oi}.png\"\n",
    "                        save_path=f\"../ComputedData/ForMatrixTest/47_{name}.png\"\n",
    "                        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "391c8e6f",
   "metadata": {},
   "source": [
    "### 這是用來找出哪兩種特徵下熱點集中區有組合"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22ac5710",
   "metadata": {},
   "outputs": [],
   "source": [
    "from TrafficTDApythonUtils.plotsv2 import MapperPlotterSpring\n",
    "\n",
    "As = ['道路型態大類別名稱_單路部分', '道路型態大類別名稱_交岔路', '道路型態大類別名稱_其他', '道路型態大類別名稱_圓環廣場', '道路型態大類別名稱_平交道']\n",
    "Bs = ['號誌-號誌種類名稱_無號誌', '號誌-號誌種類名稱_行車管制號誌', '號誌-號誌種類名稱_閃光號誌', '號誌-號誌種類名稱_行車管制號誌(附設行人專用號誌)']\n",
    "\n",
    "# choose = ('hotspot', 'bn_feature')\n",
    "choose = 'bn_feature'\n",
    "overlap = 3\n",
    "interval = 10\n",
    "seed = 47\n",
    "\n",
    "for a in As:\n",
    "    for b in Bs:\n",
    "\n",
    "        all_features_df['bn_feature'] = all_features_df.apply(\n",
    "            lambda row: 1 if (\n",
    "                (row[a] > 0) and\n",
    "                (row[b] > 0)\n",
    "            ) else 0,\n",
    "            axis=1\n",
    "        )\n",
    "        detailed_results_df = pickle.load(open(f\"../ComputedData/ForMatrixV2/o{overlap}i{interval}.pkl\", \"rb\"))\n",
    "        mapper_plotter = MapperPlotterSpring(\n",
    "            detailed_results_df['mapper_info'],\n",
    "            all_features_df,\n",
    "            seed=seed, iterations=130, dim=2,\n",
    "            range_lst=[-0.5, 0.5, 0.5, -0.5],\n",
    "            cmap=\"Greens\",\n",
    "            # encoded_label=cond_prob_mixed\n",
    "            encoded_label=ratio_in_data\n",
    "        )\n",
    "        mapper_plotter.create_mapper_plot(choose, avg=True, size_threshold=50, plot_type='spring')\n",
    "        full_info, outliers = mapper_plotter.extract_data()\n",
    "        mapper_plotter.map_colors(threshold=0)\n",
    "        mapper_plotter.plot(set_label=True, size=500, anchor=(0,0),\n",
    "                            save_path=f\"../ComputedData/ForMatrixV2/PlotsRatio/o{overlap}i{interval}s{seed}_{choose}_{a}_{b}.png\"\n",
    "                            )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15c35209",
   "metadata": {},
   "source": [
    "### 這是用來grid search的"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb6e24f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from TrafficTDApythonUtils.plotsv2 import MapperPlotterSpring\n",
    "\n",
    "overlaps = [3]\n",
    "intervals = [10]\n",
    "seeds = [47]\n",
    "# seeds = [i for i in range(10, 50)]\n",
    "# choose = ('hotspot', 'bn_feature')\n",
    "choose = 'hotspot'\n",
    "\n",
    "for seed in seeds:\n",
    "    for overlap in overlaps:\n",
    "        for interval in intervals:\n",
    "            detailed_results_df = pickle.load(open(f\"../ComputedData/ForMatrixV2/o{overlap}i{interval}.pkl\", \"rb\"))\n",
    "            mapper_plotter = MapperPlotterSpring(\n",
    "                detailed_results_df['mapper_info'],\n",
    "                all_features_df,\n",
    "                seed=seed, iterations=130, dim=2,\n",
    "                range_lst=[-0.5, 0.5, 0.5, -0.5],\n",
    "                cmap=\"Reds\",\n",
    "                # encoded_label=cond_prob_mixed\n",
    "                # encoded_label=most_common_encoded_label\n",
    "                encoded_label=ratio_in_data\n",
    "                # encoded_label=avg_label\n",
    "            )\n",
    "            mapper_plotter.create_mapper_plot(choose, avg=True, size_threshold=50, plot_type='spring')\n",
    "            full_info, outliers = mapper_plotter.extract_data()\n",
    "            mapper_plotter.map_colors(threshold=0)\n",
    "            mapper_plotter.plot(set_label=True, size=500, anchor=(0,0),\n",
    "                                # save_path=f\"../ComputedData/ForMatrixV2/Plots/o{overlap}i{interval}s{seed}_{choose}.png\"\n",
    "                                )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ST-RTA",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
