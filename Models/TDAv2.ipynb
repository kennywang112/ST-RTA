{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "59265153",
   "metadata": {},
   "source": [
    "This code is to optimize TDA.ipynb file, the main change is using three main function as the filter function:\n",
    "1. eccentricity\n",
    "2. PCA\n",
    "3. KDE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10894c08",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "current_dir = os.getcwd()\n",
    "parent_dir = os.path.dirname(current_dir)\n",
    "analyze_path = os.path.join(parent_dir, \"utils\")\n",
    "\n",
    "os.chdir(analyze_path)\n",
    "\n",
    "import ast\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import pickle\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA\n",
    "from tdam.cover import CubicalCover\n",
    "from tdam.clustering import FailSafeClustering\n",
    "from tdam.core_old import MapperAlgorithm\n",
    "from sklearn.metrics import pairwise_distances\n",
    "from sklearn.neighbors import KernelDensity\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import StandardScaler, normalize\n",
    "\n",
    "from TrafficTDApythonUtils.utils_v3 import *\n",
    "from TrafficTDApythonUtils.plots import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79249fdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "from shapely import wkt\n",
    "from utils import read_data\n",
    "\n",
    "TM2 = 3826\n",
    "taiwan = gpd.read_file('../Data/OFiles_9e222fea-bafb-4436-9b17-10921abc6ef2/TOWN_MOI_1140318.shp')\n",
    "taiwan = taiwan[(~taiwan['TOWNNAME'].isin(['旗津區', '頭城鎮', '蘭嶼鄉', '綠島鄉', '琉球鄉'])) & \n",
    "                (~taiwan['COUNTYNAME'].isin(['金門縣', '連江縣', '澎湖縣']))].to_crs(TM2)\n",
    "taiwan_cnty = taiwan[['COUNTYNAME','geometry']].dissolve(by='COUNTYNAME')\n",
    "taiwan_cnty['geometry'] = taiwan_cnty.buffer(0)\n",
    "\n",
    "# 原始以 0.001 grid 計算出的區域事故及對應索引, 依照 hex_grid 計算出來的GI\n",
    "grid_gi_df = pd.read_csv('../ComputedData/Grid/grid_gi.csv')\n",
    "grid_gi_df['accident_indices'] = grid_gi_df['accident_indices'].apply(ast.literal_eval)\n",
    "grid_gi_df['geometry'] = grid_gi_df['geometry'].apply(wkt.loads)\n",
    "grid_gi  = gpd.GeoDataFrame(grid_gi_df, geometry='geometry').set_crs(TM2, allow_override=True)\n",
    "grid_gi['geometry'] = grid_gi.geometry.centroid\n",
    "\n",
    "county_join = gpd.sjoin(grid_gi[['geometry']], taiwan_cnty, how='left', predicate='within')\n",
    "grid_gi['COUNTYNAME'] = county_join['COUNTYNAME']\n",
    "\n",
    "grid_filter = grid_gi[grid_gi['accident_indices'].str.len() > 0]\n",
    "grid_filter.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2db44984",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_features_df = pd.read_csv(\"../ComputedData/ForModel/all_features.csv\")\n",
    "cols = all_features_df.columns[all_features_df.columns.str.contains('事故位置大類別名稱')] # 高共線\n",
    "all_features_df.drop(columns=cols, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85621596",
   "metadata": {},
   "outputs": [],
   "source": [
    "def linf_centrality_exact(df, block_size = 2000):\n",
    "    \"\"\"\n",
    "    回傳 shape=(n,1) 的 L∞ centrality（每點到最遠點的距離）。\n",
    "    - metric: \"cosine\" 或 \"euclidean\"\n",
    "    - block_size: 控制記憶體 (block_size * n distances)\n",
    "    \"\"\"\n",
    "    X = df.to_numpy(dtype=float)\n",
    "    n = X.shape[0]\n",
    "    # 對每一列作 L2 正規化才能用 cosine 距離\n",
    "    X = normalize(X, norm=\"l2\", axis=1)\n",
    "\n",
    "    # 準備結果陣列，初始為無窮小\n",
    "    max_d = np.full(n, -np.inf, dtype=float)\n",
    "    order = np.arange(n) # 保留原順序\n",
    "    \n",
    "    # 分塊計算 pairwise 距離以控制記憶體\n",
    "    for start in range(0, n, block_size):\n",
    "        idx = order[start:start+block_size]\n",
    "        D_blk = pairwise_distances(X[idx], X, metric='cosine')  # (b, n)\n",
    "        # 自身距離設為 -inf，避免影響 max\n",
    "        D_blk[np.arange(D_blk.shape[0]), idx] = -np.inf\n",
    "        # 針對每個 i（在 idx 中），更新它的全域最遠距離\n",
    "        max_d[idx] = np.maximum(max_d[idx], D_blk.max(axis=1))\n",
    "\n",
    "    return max_d.reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3104165",
   "metadata": {},
   "source": [
    "## 1. PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4508e330",
   "metadata": {},
   "outputs": [],
   "source": [
    "pc=5\n",
    "filter_pca = PCA(pc).fit_transform(all_features_df)\n",
    "\n",
    "pca = PCA(pc).fit(all_features_df)\n",
    "ratios = pca.explained_variance_ratio_\n",
    "print(ratios)\n",
    "print(ratios.sum()) \n",
    "# pc_z = StandardScaler().fit_transform(filter_pca[:, :pc])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ce51cab",
   "metadata": {},
   "source": [
    "## 2. KDE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c58e927c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = filter_pca # pc_z\n",
    "kde = KernelDensity(kernel='gaussian').fit(X)\n",
    "\n",
    "log_density = kde.score_samples(X)\n",
    "\n",
    "density = np.exp(log_density)\n",
    "# rank-normalize\n",
    "rank = (np.argsort(np.argsort(density)).astype(float) / (len(density)-1))\n",
    "filter_kde = rank.reshape(-1, 1) \n",
    "# kde_z = StandardScaler().fit_transform(filter_kde)\n",
    "\n",
    "### check for correlation\n",
    "lin = LinearRegression().fit(X, filter_kde.ravel())\n",
    "print(\"Linear R^2 (PC1-5 -> KDE) =\", lin.score(X, filter_kde.ravel()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2695f554",
   "metadata": {},
   "source": [
    "## 3. Centrality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4414792",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Centrality')\n",
    "filter_centrality = linf_centrality_exact(all_features_df)\n",
    "# linf_z = StandardScaler().fit_transform(filter_centrality)\n",
    "\n",
    "# filter_full = np.concatenate([linf_z, kde_z, pc_z], axis=1)\n",
    "filter_full = np.concatenate([filter_centrality, filter_kde, filter_pca], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d39cc1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_full = pd.DataFrame(filter_full, columns=['centrality', 'kde', 'pc1', 'pc2', 'pc3', 'pc4', 'pc5'])\n",
    "filter_full.to_csv(\"../ComputedData/ForModel/filtered_data.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4377e9e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_full = pd.read_csv(\"../ComputedData/ForModel/filtered_data.csv\")\n",
    "filter_full.drop(columns=['pc4', 'pc5'], inplace=True)\n",
    "filter_full.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a16bb0d",
   "metadata": {},
   "source": [
    "# Mapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba34267a",
   "metadata": {},
   "outputs": [],
   "source": [
    "overlaps = [2, 3]\n",
    "intervals = [8, 10]\n",
    "detailed_results = []\n",
    "silhouette_for_intervals = []\n",
    "\n",
    "for overlap in overlaps:\n",
    "    for interval in intervals:\n",
    "        print(f\"Processing overlap {overlap}, interval {interval}\")\n",
    "        mapper_algo = MapperAlgorithm(\n",
    "            cover=CubicalCover(\n",
    "                n_intervals=interval,\n",
    "                overlap_frac=overlap / 10\n",
    "            ),\n",
    "            clustering=FailSafeClustering(\n",
    "                KMeans(\n",
    "                    n_clusters=2,\n",
    "                    random_state=42\n",
    "                )\n",
    "            ),\n",
    "            n_jobs=-1\n",
    "        )\n",
    "\n",
    "        mapper_info = mapper_algo.fit_transform(all_features_df.to_numpy(), filter_full)\n",
    "\n",
    "        silhouette_for_intervals.append(mapper_info[1])\n",
    "        result = {\n",
    "            \"overlap\": overlap,\n",
    "            \"interval\": interval,\n",
    "            \"silhouette\": mapper_info[1],\n",
    "            \"mapper_info\": mapper_info\n",
    "        }\n",
    "        detailed_results.append(result)\n",
    "\n",
    "        with open(f\"../ComputedData/ForMatrixV2/o{overlap}i{interval}.pkl\", 'wb') as file:\n",
    "            pickle.dump(result, file)\n",
    "\n",
    "detailed_results_df = pd.DataFrame(detailed_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be3e0cf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "col = '號誌動作'\n",
    "\n",
    "def get_max_categories(row):\n",
    "\n",
    "    cols = all_features_df.columns[all_features_df.columns.str.contains(col)]\n",
    "\n",
    "    max_val = row[cols].max()\n",
    "    max_cols = row[cols][row[cols] == max_val].index\n",
    "    # 取底線後面的類別名稱，用逗號串起來\n",
    "    return ','.join(col.split('_')[-1] for col in max_cols)\n",
    "\n",
    "all_features_df['最高類別'] = all_features_df.apply(get_max_categories, axis=1)\n",
    "all_features_df['最高類別'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5967eea3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from TrafficTDApythonUtils.plotsv2 import MapperPlotterSpring\n",
    "\n",
    "plt.rcParams['font.family'] = ['Arial Unicode Ms']\n",
    "\n",
    "all_features_df['county'] = grid_filter['COUNTYNAME']\n",
    "all_features_df['hotspot'] = grid_filter['hotspot']\n",
    "all_features_df['hotspot'] = all_features_df['hotspot'].apply(lambda x: 'Hotspot' if 'Hotspot' in str(x) else 'Not Hotspot')\n",
    "all_features_df['youbike'] = all_features_df['youbike_100m_count_mean'].apply(lambda x: 'Facility' if x>0 else 'No Facility')\n",
    "all_features_df['hotspot_youbike'] = all_features_df['hotspot'] + '_' + all_features_df['youbike']\n",
    "\n",
    "overlaps = [3]\n",
    "intervals = [10]\n",
    "# seeds = [i for i in range(10, 50)]\n",
    "seeds = [47]\n",
    "for seed in seeds:\n",
    "    for overlap in overlaps:\n",
    "        for interval in intervals:\n",
    "            detailed_results_df = pickle.load(open(f\"../ComputedData/ForMatrixV2/o{overlap}i{interval}.pkl\", \"rb\"))\n",
    "            choose = '最高類別'\n",
    "            mapper_plotter = MapperPlotterSpring(\n",
    "                detailed_results_df['mapper_info'],\n",
    "                all_features_df,\n",
    "                seed=seed, iterations=100, dim=2,\n",
    "                range_lst=[-0.5, 0.5, 0.5, -0.5]\n",
    "            )\n",
    "\n",
    "            def avg_label(data):\n",
    "                return sum(data) / len(data) if len(data) > 0 else 0\n",
    "            def most_common_encoded_label(data):\n",
    "                return Counter(data).most_common(1)[0][0]\n",
    "\n",
    "            mapper_plotter.create_mapper_plot(choose, most_common_encoded_label, avg=False, size_threshold=50)\n",
    "            full_info, outliers = mapper_plotter.extract_data()\n",
    "            mapper_plotter.map_colors(choose, size=50, threshold=0)\n",
    "            mapper_plotter.plot(choose, avg=False, set_label=True, size=500, anchor=1,\n",
    "                                # save_path=f\"../ComputedData/ForMatrixV2/Plots/o{overlap}i{interval}s{seed}_{choose}.png\"\n",
    "                                )\n",
    "            # mapper_plotter.plot3d_matplotlib(\n",
    "            #     choose,\n",
    "            #     avg=False,\n",
    "            #     save_path=f\"../ComputedData/ForMatrixV2/Plots/o{overlap}i{interval}s{seed}_{choose}.png\",\n",
    "            #     size=1200, elev=22, azim=35, dpi=180\n",
    "            # )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0d0cced",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.rcParams['font.family'] = ['Arial Unicode Ms']\n",
    "\n",
    "# all_features_df['county'] = grid_filter['COUNTYNAME']\n",
    "# all_features_df['hotspot'] = grid_filter['hotspot']\n",
    "# all_features_df['hotspot'] = all_features_df['hotspot'].apply(lambda x: 'Hotspot' if 'Hotspot' in str(x) else 'Not Hotspot')\n",
    "# all_features_df['youbike'] = all_features_df['youbike_100m_count_mean'].apply(lambda x: 'Facility' if x>0 else 'No Facility')\n",
    "# all_features_df['hotspot_youbike'] = all_features_df['hotspot'] + '_' + all_features_df['youbike']\n",
    "\n",
    "# overlaps = [4]\n",
    "# intervals = [12]\n",
    "# seeds = [i for i in range(55, 80)]\n",
    "\n",
    "# for seed in [52]:\n",
    "#     for overlap in overlaps:\n",
    "#         for interval in intervals:\n",
    "            \n",
    "#             detailed_results_df = pickle.load(open(f\"../ComputedData/ForMatrixV2/o{overlap}i{interval}.pkl\", \"rb\"))\n",
    "#             choose = 'hotspot_youbike' # county, hotspot_youbike\n",
    "#             mapper_plotter = MapperPlotter(detailed_results_df['mapper_info'], \n",
    "#                                         all_features_df, seed=seed, iterations=50, dim=2,\n",
    "#                                             range_lst=[-0.5, 0.5, 0.5, -0.5])\n",
    "\n",
    "#             def avg_label(data):\n",
    "#                 return sum(data) / len(data) if len(data) > 0 else 0\n",
    "#             def most_common_encoded_label(data):\n",
    "#                 most_common_item = Counter(data).most_common(1)[0][0]\n",
    "#                 return most_common_item\n",
    "\n",
    "#             mapper_plot = mapper_plotter.create_mapper_plot(choose, most_common_encoded_label, avg=False)\n",
    "#             full_info = mapper_plotter.extract_data()\n",
    "#             mapper_plotter.map_colors(choose, size=30, threshold=0)\n",
    "#             mapper_plotter.plot(choose, avg=False, set_label=True, size=500, anchor=1,\n",
    "#                                 # save_path=f\"../ComputedData/ForMatrixV2/Plots/o{overlap}i{interval}s{seed}_{choose}.png\"\n",
    "#                                 )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ST-RTA",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
