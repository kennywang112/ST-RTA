{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "59265153",
   "metadata": {},
   "source": [
    "This code is to optimize TDA.ipynb file, the main change is using three main function as the filter function:\n",
    "1. eccentricity\n",
    "2. PCA\n",
    "3. KDE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10894c08",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "current_dir = os.getcwd()\n",
    "parent_dir = os.path.dirname(current_dir)\n",
    "analyze_path = os.path.join(parent_dir, \"utils\")\n",
    "\n",
    "os.chdir(analyze_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fefd2eb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "import pandas as pd\n",
    "\n",
    "import pickle\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA\n",
    "from tdam.cover import CubicalCover\n",
    "from tdam.clustering import FailSafeClustering\n",
    "from tdam.core_old import MapperAlgorithm\n",
    "\n",
    "from TrafficTDApythonUtils.utils_v3 import *\n",
    "from TrafficTDApythonUtils.plots import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79249fdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "from shapely import wkt\n",
    "from utils import read_data\n",
    "\n",
    "combined_data = read_data()\n",
    "TM2 = 3826\n",
    "taiwan = gpd.read_file('../Data/OFiles_9e222fea-bafb-4436-9b17-10921abc6ef2/TOWN_MOI_1140318.shp')\n",
    "taiwan = taiwan[(~taiwan['TOWNNAME'].isin(['旗津區', '頭城鎮', '蘭嶼鄉', '綠島鄉', '琉球鄉'])) & \n",
    "                (~taiwan['COUNTYNAME'].isin(['金門縣', '連江縣', '澎湖縣']))].to_crs(TM2)\n",
    "taiwan_cnty = taiwan[['COUNTYNAME','geometry']].dissolve(by='COUNTYNAME')\n",
    "taiwan_cnty['geometry'] = taiwan_cnty.buffer(0)\n",
    "\n",
    "# 原始以 0.001 grid 計算出的區域事故及對應索引, 依照 hex_grid 計算出來的GI\n",
    "grid_gi_df = pd.read_csv('../ComputedData/Grid/grid_gi.csv')\n",
    "grid_gi_df['accident_indices'] = grid_gi_df['accident_indices'].apply(ast.literal_eval)\n",
    "grid_gi_df['geometry'] = grid_gi_df['geometry'].apply(wkt.loads)\n",
    "grid_gi  = gpd.GeoDataFrame(grid_gi_df, geometry='geometry').set_crs(TM2, allow_override=True)\n",
    "grid_gi['geometry'] = grid_gi.geometry.centroid\n",
    "\n",
    "county_join = gpd.sjoin(grid_gi[['geometry']], taiwan_cnty, how='left', predicate='within')\n",
    "grid_gi['COUNTYNAME'] = county_join['COUNTYNAME']\n",
    "\n",
    "grid_filter = grid_gi[grid_gi['accident_indices'].str.len() > 0]\n",
    "grid_filter.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2db44984",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_features_df = pd.read_csv(\"../ComputedData/ForModel/all_features_filtered.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4ed36fd",
   "metadata": {},
   "source": [
    "## 1. PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c58e927c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pc = 3\n",
    "filter_pca = PCA(pc).fit_transform(all_features_df)\n",
    "\n",
    "pca = PCA(pc).fit(all_features_df)\n",
    "ratios = pca.explained_variance_ratio_\n",
    "print(ratios)\n",
    "print(ratios.sum()) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e005fca9",
   "metadata": {},
   "source": [
    "## 2. KDE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa323a15",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KernelDensity\n",
    "\n",
    "X = filter_pca # 3 pc\n",
    "kde = KernelDensity(kernel='gaussian').fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb399771",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_density = kde.score_samples(X)\n",
    "\n",
    "density = np.exp(log_density)\n",
    "# rank-normalize\n",
    "rank = (np.argsort(np.argsort(density)).astype(float) / (len(density)-1))\n",
    "filter_kde = rank.reshape(-1, 1) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d3691ce",
   "metadata": {},
   "source": [
    "## 3. Centrality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c7ef234",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import pairwise_distances\n",
    "from sklearn.preprocessing import normalize\n",
    "\n",
    "def linf_centrality_exact(df, block_size = 2000):\n",
    "    \"\"\"\n",
    "    回傳 shape=(n,1) 的 L∞ centrality（每點到最遠點的距離）。\n",
    "    - metric: \"cosine\" 或 \"euclidean\"\n",
    "    - block_size: 控制記憶體 (block_size * n distances)\n",
    "    \"\"\"\n",
    "    X = df.to_numpy(dtype=float)\n",
    "    n = X.shape[0]\n",
    "    # 對每一列作 L2 正規化才能用 cosine 距離\n",
    "    X = normalize(X, norm=\"l2\", axis=1)\n",
    "\n",
    "    # 準備結果陣列，初始為無窮小\n",
    "    max_d = np.full(n, -np.inf, dtype=float)\n",
    "    order = np.arange(n) # 保留原順序\n",
    "    \n",
    "    # 分塊計算 pairwise 距離以控制記憶體\n",
    "    for start in range(0, n, block_size):\n",
    "        idx = order[start:start+block_size]\n",
    "        D_blk = pairwise_distances(X[idx], X, metric='cosine')  # (b, n)\n",
    "        # 自身距離設為 -inf，避免影響 max\n",
    "        D_blk[np.arange(D_blk.shape[0]), idx] = -np.inf\n",
    "        # 針對每個 i（在 idx 中），更新它的全域最遠距離\n",
    "        max_d[idx] = np.maximum(max_d[idx], D_blk.max(axis=1))\n",
    "\n",
    "    return max_d.reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2170d3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_centrality = linf_centrality_exact(all_features_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "137dfcdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_full = np.concatenate([filter_centrality, filter_kde, filter_pca], axis=1)\n",
    "filter_full.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a16bb0d",
   "metadata": {},
   "source": [
    "# Mapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba34267a",
   "metadata": {},
   "outputs": [],
   "source": [
    "overlaps = [2]\n",
    "intervals = [10]\n",
    "detailed_results = []\n",
    "silhouette_for_intervals = []\n",
    "\n",
    "for overlap in overlaps:\n",
    "    for interval in intervals:\n",
    "        print(f\"Processing overlap {overlap}, interval {interval}\")\n",
    "        mapper_algo = MapperAlgorithm(\n",
    "            cover=CubicalCover(\n",
    "                n_intervals=interval,\n",
    "                overlap_frac=overlap / 10\n",
    "            ),\n",
    "            clustering=FailSafeClustering(\n",
    "                KMeans(\n",
    "                    n_clusters=2,\n",
    "                    random_state=42\n",
    "                )\n",
    "            ),\n",
    "            n_jobs=14\n",
    "        )\n",
    "\n",
    "        mapper_info = mapper_algo.fit_transform(all_features_df.to_numpy(), filter_full)\n",
    "\n",
    "        silhouette_for_intervals.append(mapper_info[1])\n",
    "        result = {\n",
    "            \"overlap\": overlap,\n",
    "            \"interval\": interval,\n",
    "            \"silhouette\": mapper_info[1],\n",
    "            \"mapper_info\": mapper_info\n",
    "        }\n",
    "        detailed_results.append(result)\n",
    "\n",
    "        with open(f\"../ComputedData/ForMatrixV2/o{overlap}i{interval}.pkl\", 'wb') as file:\n",
    "            pickle.dump(result, file)\n",
    "\n",
    "detailed_results_df = pd.DataFrame(detailed_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1170cc64",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_features_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cda8b27",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4535aa61",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_features_df['county'] = grid_filter['COUNTYNAME']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8624251",
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_features_df['hotspot'] = grid_filter['hotspot']\n",
    "# all_features_df['hotspot'] = all_features_df['hotspot'].apply(lambda x: 'Hotspot' if 'Hotspot' in str(x) else 'Not Hotspot')\n",
    "# all_features_df['youbike'] = all_features_df['youbike_100m_count_mean'].apply(lambda x: 'Facility' if x>0 else 'No Facility')\n",
    "# all_features_df['hotspot_youbike'] = all_features_df['hotspot'] + '_' + all_features_df['youbike']\n",
    "\n",
    "overlaps = [3]\n",
    "intervals = [9]\n",
    "seeds = [i for i in range(41, 300)]\n",
    "# o3i9s63\n",
    "for seed in [53]:\n",
    "    for overlap in overlaps:\n",
    "        for interval in intervals:\n",
    "            \n",
    "            detailed_results_df = pickle.load(open(f\"../ComputedData/ForMatrixV2/o{overlap}i{interval}.pkl\", \"rb\"))\n",
    "            # choose = 'hotspot_youbike'\n",
    "            choose = 'county'\n",
    "            mapper_plotter = MapperPlotter(detailed_results_df['mapper_info'], \n",
    "                                        all_features_df, seed=seed, iterations=50, dim=2,\n",
    "                                            range_lst=[-0.5, 0.5, 0.5, -0.5])\n",
    "\n",
    "            def avg_label(data):\n",
    "                return sum(data) / len(data) if len(data) > 0 else 0\n",
    "            def most_common_encoded_label(data):\n",
    "                most_common_item = Counter(data).most_common(1)[0][0]\n",
    "                return most_common_item\n",
    "\n",
    "            mapper_plot = mapper_plotter.create_mapper_plot(choose, most_common_encoded_label, avg=False)\n",
    "            full_info = mapper_plotter.extract_data()\n",
    "            mapper_plotter.map_colors(choose, size=50, threshold=0)\n",
    "            mapper_plotter.plot(choose, avg=False, set_label=True, size=500, anchor=1,\n",
    "                                # save_path=f\"../ComputedData/ForMatrixV2/Plots/o{overlap}i{interval}s{seed}.png\"\n",
    "                                )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ST-RTA",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
