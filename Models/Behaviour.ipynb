{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "465d341e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import bnlearn as bn\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['font.family'] = ['Arial Unicode Ms']\n",
    "\n",
    "current_dir = os.getcwd()\n",
    "parent_dir = os.path.dirname(current_dir)\n",
    "analyze_path = os.path.join(parent_dir, \"utils\")\n",
    "\n",
    "os.chdir(analyze_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22d9ee98",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils_behaviour import get_model, draw_bn_plotly, cpd_add_n, filter_cpd_for_hotspot, get_outlier\n",
    "from config import category_value_map, feature_name_map, select_group_behaviour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7082fed2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is from TDAv2\n",
    "combined_data = pd.read_csv('../ComputedData/ForModel/combined_data_with_hotspot.csv')\n",
    "combined_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a2badf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = combined_data[select_group_behaviour].copy()\n",
    "data['facility'] = data[['youbike_100m_count']].apply(lambda row: '1' if (row > 0).any() else '0', axis=1)\n",
    "data.drop(columns=['youbike_100m_count'], inplace=True)\n",
    "\n",
    "max_speed = data['速限-第1當事者'].max()\n",
    "bins = range(0, int(max_speed) + 11, 10)\n",
    "\n",
    "data['速限-第1當事者'] = pd.cut(\n",
    "    data['速限-第1當事者'],\n",
    "    bins=bins,\n",
    "    right=False, \n",
    "    include_lowest=True,\n",
    "    labels=[f\"{i}-{i+9}\" for i in bins[:-1]]\n",
    ")\n",
    "\n",
    "data0 = data[data['facility'] == '0']\n",
    "data1 = data[data['facility'] == '1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71ccb28e",
   "metadata": {},
   "outputs": [],
   "source": [
    "parent = [\n",
    "    '號誌-號誌種類名稱', '號誌-號誌動作名稱','車道劃分設施-分道設施-快車道或一般車道間名稱', '車道劃分設施-分道設施-快慢車道間名稱',\n",
    "    '車道劃分設施-分道設施-路面邊線名稱', '車道劃分設施-分向設施子類別名稱', '道路型態子類別名稱',\n",
    "    '速限-第1當事者', '道路類別-第1當事者-名稱', 'facility', 'COUNTYNAME'\n",
    "    ]\n",
    "cause = ['肇因研判子類別名稱-主要']\n",
    "result = ['事故類型及型態子類別名稱']\n",
    "\n",
    "white_list = [\n",
    "    ('速限-第1當事者', '肇因研判子類別名稱-主要'),\n",
    "    ('道路類別-第1當事者-名稱', '肇因研判子類別名稱-主要'),\n",
    "    ('道路型態子類別名稱', '肇因研判子類別名稱-主要'),\n",
    "    ('facility', '肇因研判子類別名稱-主要'),\n",
    "    ('號誌-號誌種類名稱', '肇因研判子類別名稱-主要'),\n",
    "    # ('肇因研判子類別名稱-主要', '事故類型及型態子類別名稱'),\n",
    "]\n",
    "\n",
    "black_list = []\n",
    "# cause -> parent\n",
    "black_list += [(c, p) for c in cause for p in parent]\n",
    "# result -> parent/cause\n",
    "black_list += [(r, x) for r in result for x in (parent + cause + result)]\n",
    "# 保險：parent -> result（避免直接 shortcut，如果只想透過肇因解釋）\n",
    "# black_list += [(p, r) for p in parent for r in result]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5f60d5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model0, model_param0, model_independence0 = get_model(data0)\n",
    "model1, model_param1, model_independence1 = get_model(data1)\n",
    "model_all, model_param_all, model_independence_all = get_model(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4abf99d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "draw_bn_plotly(model_independence_all, layout_algo='spring', en=False, width=600, height=400, seed=42, iter=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1471d429",
   "metadata": {},
   "source": [
    "## Inference\n",
    "這個方法針對特定的推論得出cpt，現在討論反向所以evidence會是肇因，討論特定特徵下不同設計的機率"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37ce1a11",
   "metadata": {},
   "outputs": [],
   "source": [
    "parent = ['速限-第1當事者', '道路類別-第1當事者-名稱', '道路型態子類別名稱', 'facility', '號誌-號誌種類名稱']\n",
    "child = '肇因研判子類別名稱-主要'\n",
    "evidence_v = list(data['肇因研判子類別名稱-主要'].value_counts().head(5).index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d7c6460",
   "metadata": {},
   "outputs": [],
   "source": [
    "for state, model_pm in enumerate ([model_param0, model_param1]):\n",
    "    dt = data0 if state == 0 else data1\n",
    "    for v in evidence_v:\n",
    "        q2 = bn.inference.fit(\n",
    "            model_pm, \n",
    "            variables=parent,\n",
    "            evidence={'肇因研判子類別名稱-主要': v})\n",
    "\n",
    "        model_df = q2.df\n",
    "        evidence_df = dt[dt['肇因研判子類別名稱-主要'] == v]\n",
    "        filtered_condition = cpd_add_n(parent, child, model_df, evidence_df, cpd=False, threshold=0)\n",
    "        final_filtered = filtered_condition[['號誌-號誌種類名稱', '速限-第1當事者', '道路型態子類別名稱', 'facility', 'p', 'n', '道路類別-第1當事者-名稱']]\n",
    "        final_filtered = final_filtered.sort_values(by=['號誌-號誌種類名稱', '速限-第1當事者', '道路型態子類別名稱', 'facility', 'p'], ascending=True)\n",
    "\n",
    "        final_filtered.to_csv(f'../ComputedData/Behaviour_split/{state}_{v}.csv', encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5050442b",
   "metadata": {},
   "source": [
    "### Full\n",
    "分別存每個肇因的離群"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0acb171",
   "metadata": {},
   "outputs": [],
   "source": [
    "parent_filtered = ['道路型態子類別名稱', '號誌-號誌種類名稱']\n",
    "\n",
    "for i in range(len(evidence_v)):\n",
    "    condition_0 = pd.read_csv(f'../ComputedData/Behaviour_split/0_{evidence_v[i]}.csv', encoding='utf-8')\n",
    "    condition_1 = pd.read_csv(f'../ComputedData/Behaviour_split/1_{evidence_v[i]}.csv', encoding='utf-8')\n",
    "    condition_concat = pd.concat([condition_0, condition_1], axis=0)\n",
    "    # All filters\n",
    "    hotspot = filter_cpd_for_hotspot(condition_concat)\n",
    "    final_filtered = hotspot[(hotspot['p'] >= 0.05) & (hotspot['n'] >= 100)]\n",
    "    # Filters end\n",
    "    final = final_filtered.sort_values(\n",
    "        by=['號誌-號誌種類名稱', '速限-第1當事者', '道路型態子類別名稱', 'facility', 'p'],\n",
    "        ascending=True)\n",
    "    # EN version\n",
    "    for col in parent_filtered:\n",
    "        final[col] = final[col].map(category_value_map[col])\n",
    "    final.rename(columns=feature_name_map, inplace=True)\n",
    "    final.to_excel(f'../ComputedData/Behaviour_split/full_{evidence_v[i]}.xlsx', encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2652865e",
   "metadata": {},
   "source": [
    "### Outlier Analysis\n",
    "存前五大常出現肇因中離群"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e51e23b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "outlier_data = pd.DataFrame()\n",
    "fac = 1\n",
    "parent_filtered = ['道路型態子類別名稱', '號誌-號誌種類名稱', '肇因研判子類別名稱-主要']\n",
    "\n",
    "for i in range(len(evidence_v)):\n",
    "    try:\n",
    "        original_condition = pd.read_csv(f'../ComputedData/Behaviour_split/{fac}_{evidence_v[i]}.csv', encoding='utf-8')\n",
    "        # origin是用來計算離群，所以不能對他篩選，應該要篩選outlier_data\n",
    "        new_condition = filter_cpd_for_hotspot(original_condition)\n",
    "        new_condition_out = get_outlier(original_condition, new_condition)\n",
    "        new_condition_out['肇因研判子類別名稱-主要'] = evidence_v[i]\n",
    "        outlier_data = pd.concat([outlier_data, new_condition_out], axis=0)\n",
    "        outlier_data = outlier_data[outlier_data['n'] >= 50]\n",
    "        # 由於outlier太多，增加更高的threshold\n",
    "        # outlier_data = outlier_data[outlier_data['p'] >= 0.03].nlargest(20, 'p')\n",
    "        threshold = outlier_data['p'].quantile(0.5) \n",
    "        outlier_data = outlier_data[outlier_data['p'] >= threshold]\n",
    "\n",
    "        outlier_data = outlier_data[['肇因研判子類別名稱-主要', '號誌-號誌種類名稱', '速限-第1當事者', '道路型態子類別名稱', 'facility', 'p', 'n']]\n",
    "        outlier_data = outlier_data.sort_values(by=['肇因研判子類別名稱-主要', '號誌-號誌種類名稱', '速限-第1當事者', '道路型態子類別名稱', 'p'], ascending=True)\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {evidence_v[i]}: {e}\")\n",
    "\n",
    "# en version\n",
    "for col in parent_filtered:\n",
    "    outlier_data[col] = outlier_data[col].map(category_value_map[col])\n",
    "outlier_data.rename(columns=feature_name_map, inplace=True)\n",
    "outlier_data.to_excel(f'../ComputedData/Behaviour_split/outlier_{fac}.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6893494d",
   "metadata": {},
   "source": [
    "### Hotspot Ratio Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fb88acf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_df(prefix, ev):\n",
    "    data_sum = {}\n",
    "    for i in range(len(ev)):\n",
    "        try:\n",
    "            condition = pd.read_csv(f'../ComputedData/Behaviour/{prefix}_{ev[i]}.csv', encoding='utf-8')\n",
    "            data = filter_cpd_for_hotspot(condition)\n",
    "            data_sum[ev[i]] = round(data['p'].sum(), 4)\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {ev[i]}: {e}\")\n",
    "\n",
    "    df_sum = pd.DataFrame(\n",
    "        list(data_sum.items()), \n",
    "        columns=['肇因研判子類別名稱-主要', 'p']\n",
    "    )\n",
    "    df_sum['facility'] = prefix\n",
    "    return df_sum\n",
    "\n",
    "df0 = make_df(\"0\", evidence_v)\n",
    "df1 = make_df(\"1\", evidence_v)\n",
    "final_df = pd.concat([df0, df1], ignore_index=True)\n",
    "\n",
    "final_df.sort_values(by=['肇因研判子類別名稱-主要'], ascending=True, inplace=True)\n",
    "final_df = final_df[['肇因研判子類別名稱-主要', 'facility', 'p']]\n",
    "\n",
    "for col in ['肇因研判子類別名稱-主要']:\n",
    "    final_df[col] = final_df[col].map(category_value_map[col])\n",
    "final_df.rename(columns=feature_name_map, inplace=True)\n",
    "\n",
    "final_df.to_excel(f'../ComputedData/Behaviour_split/final_sum.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f65c9b8",
   "metadata": {},
   "source": [
    "## This is for original data\n",
    "1. 分成原始資料做的原因在於分開比較可能因為道路組合數量不同造成整體機率下降，這樣會導致在有無設施下，相同組合下有設施不任何顯著組合都是高於無設施的，因為無設施組合更多。<br/>\n",
    "2. 但使用原始資料進行分析不能單純依照p和n去篩選，不然剩下的資料都會是無設施，因為有設施資料量本來就比較少。<br/>\n",
    "> 為了防止上述偏差，獲取outlier之後分開設施1和0並取前10大常見組合，n也需要設置，因為小樣本偏差還是應該去除\n",
    "> 問題：最終比較的還是p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34304b7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "parent = ['速限-第1當事者', '道路類別-第1當事者-名稱', '道路型態子類別名稱', 'facility', '號誌-號誌種類名稱']\n",
    "child = '肇因研判子類別名稱-主要'\n",
    "\n",
    "for v in evidence_v:\n",
    "    q2 = bn.inference.fit(\n",
    "        model_param_all, \n",
    "        variables=parent,\n",
    "        evidence={'肇因研判子類別名稱-主要': v})\n",
    "\n",
    "    model_df = q2.df\n",
    "    evidence_df = data[data['肇因研判子類別名稱-主要'] == v]\n",
    "    filtered_condition = cpd_add_n(parent, child, model_df, evidence_df, cpd=False, threshold=-1)\n",
    "    final_filtered = filtered_condition[['號誌-號誌種類名稱', '速限-第1當事者', '道路型態子類別名稱', 'facility', 'p', 'n', '道路類別-第1當事者-名稱']]\n",
    "    final_filtered = final_filtered.sort_values(by=['號誌-號誌種類名稱', '速限-第1當事者', '道路型態子類別名稱', 'facility', 'p'], ascending=True)\n",
    "\n",
    "    final_filtered.to_csv(f'../ComputedData/Behaviour/all_{v}.csv', encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e08fc0b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "parent_filtered = ['道路型態子類別名稱', '號誌-號誌種類名稱']\n",
    "\n",
    "for i in range(len(evidence_v)):\n",
    "    condition = pd.read_csv(f'../ComputedData/Behaviour/all_{evidence_v[i]}.csv', encoding='utf-8')\n",
    "    # All filters\n",
    "    hotspot = filter_cpd_for_hotspot(condition)\n",
    "    final_filtered = hotspot[(hotspot['p'] >= 0.03) & (hotspot['n'] >= 30)]\n",
    "    # Filters end\n",
    "    final = final_filtered.sort_values(\n",
    "        by=['號誌-號誌種類名稱', '速限-第1當事者', '道路型態子類別名稱', 'facility', 'p'],\n",
    "        ascending=True)\n",
    "    # EN version\n",
    "    for col in parent_filtered:\n",
    "        final[col] = final[col].map(category_value_map[col])\n",
    "    final.rename(columns=feature_name_map, inplace=True)\n",
    "    final.to_excel(f'../ComputedData/Behaviour/full_Origin_{evidence_v[i]}.xlsx', encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c201217",
   "metadata": {},
   "source": [
    "### Outlier analysis for original data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2118bb5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "outlier_data = pd.DataFrame()\n",
    "parent_filtered = ['道路型態子類別名稱', '號誌-號誌種類名稱', '肇因研判子類別名稱-主要']\n",
    "\n",
    "for i in range(len(evidence_v)):\n",
    "    original_data = pd.read_csv(f'../ComputedData/Behaviour/all_{evidence_v[i]}.csv', encoding='utf-8')\n",
    "    # origin是用來計算離群，所以不能對他篩選，應該要篩選outlier_data\n",
    "    new_condition = filter_cpd_for_hotspot(original_data)\n",
    "    outlier = get_outlier(original_data, new_condition)\n",
    "    outlier['肇因研判子類別名稱-主要'] = evidence_v[i]\n",
    "    outlier_data = pd.concat([outlier_data, outlier], axis=0)\n",
    "\n",
    "filtered_0 = outlier_data[(outlier_data['facility'] == 0) &\n",
    "                          (outlier_data['n'] > 30)].sort_values(by=['p'], ascending=False).head(25)\n",
    "filtered_1 = outlier_data[(outlier_data['facility'] == 1) &\n",
    "                          (outlier_data['n'] > 30)].sort_values(by=['p'], ascending=False).head(25)\n",
    "full_filter = pd.concat([filtered_0, filtered_1], axis=0)\n",
    "\n",
    "for col in parent_filtered:\n",
    "    full_filter[col] = full_filter[col].map(category_value_map[col])\n",
    "full_filter.rename(columns=feature_name_map, inplace=True)\n",
    "full_filter.to_excel(f'../ComputedData/Behaviour/Origin_outlier.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "888eac8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_df(ev, fac):\n",
    "    data_sum = {}\n",
    "    for i in range(len(ev)):\n",
    "        condition = pd.read_csv(f'../ComputedData/Behaviour/all_{ev[i]}.csv', encoding='utf-8')\n",
    "        condition = condition[condition['facility'] == fac]\n",
    "        data = filter_cpd_for_hotspot(condition)\n",
    "        data_sum[ev[i]] = round(data['p'].sum(), 4)\n",
    "\n",
    "    df_sum = pd.DataFrame(\n",
    "        list(data_sum.items()), \n",
    "        columns=['肇因研判子類別名稱-主要', 'p']\n",
    "    )\n",
    "    return df_sum\n",
    "\n",
    "df_0 = make_df(evidence_v, fac=0)\n",
    "df_1 = make_df(evidence_v, fac=1)\n",
    "df_0['facility'] = 0\n",
    "df_1['facility'] = 1\n",
    "df = pd.concat([df_0, df_1], ignore_index=True)\n",
    "df.sort_values(by=['肇因研判子類別名稱-主要'], ascending=True, inplace=True)\n",
    "\n",
    "for col in ['肇因研判子類別名稱-主要']:\n",
    "    df[col] = df[col].map(category_value_map[col])\n",
    "df.rename(columns=feature_name_map, inplace=True)\n",
    "df.to_excel(f'../ComputedData/Behaviour/final_sum.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "420bb3f7",
   "metadata": {},
   "source": [
    "## CPD\n",
    "沒有針對特徵，回傳肇因的因"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b929b5e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "CPDs = bn.print_CPD(model_param_all)\n",
    "dfprob_cause = CPDs[child]\n",
    "filtered = cpd_add_n(parent, child, dfprob_cause, data, threshold=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ae89a6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_n = filtered[(filtered['p'] > 0.1) & (filtered['n'] > 100)]\n",
    "filtered_n['facility'] = filtered_n['facility'].astype(int)\n",
    "final_filtered = filter_cpd_for_hotspot(filtered_n)\n",
    "final_filtered = final_filtered.nlargest(50, 'p')\n",
    "final_filtered = final_filtered[['號誌-號誌種類名稱', '速限-第1當事者', '道路型態子類別名稱', 'facility', '肇因研判子類別名稱-主要', 'p', 'n']]\n",
    "final_filtered = final_filtered.sort_values(by=['號誌-號誌種類名稱', '速限-第1當事者', '道路型態子類別名稱', 'facility', 'p'], ascending=True)\n",
    "# EN version\n",
    "for col in ['道路型態子類別名稱', '號誌-號誌種類名稱', '肇因研判子類別名稱-主要']:\n",
    "    final_filtered[col] = final_filtered[col].map(category_value_map[col])\n",
    "final_filtered.rename(columns=feature_name_map, inplace=True)\n",
    "final_filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04e7aca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openpyxl import load_workbook\n",
    "\n",
    "path = \"../BNtables/final_filtered_en.xlsx\"\n",
    "final_filtered.to_excel(path, index=False)\n",
    "wb = load_workbook(path)\n",
    "ws = wb.active\n",
    "\n",
    "for i in range(1, 4):\n",
    "    col_idx = i  # 1st column\n",
    "    merge_start = 2  # start from row 2 (header is in row 1)\n",
    "    current_value = ws.cell(row=merge_start, column=col_idx).value\n",
    "\n",
    "    for row in range(merge_start + 1, ws.max_row + 2):  # +2 是為了最後一個 flush\n",
    "        value = ws.cell(row=row, column=col_idx).value if row <= ws.max_row else None\n",
    "\n",
    "        if value != current_value:\n",
    "            # 合併區間\n",
    "            if row - merge_start > 1:\n",
    "                ws.merge_cells(start_row=merge_start, start_column=col_idx,\n",
    "                            end_row=row-1, end_column=col_idx)\n",
    "                # 垂直置中\n",
    "                ws.cell(row=merge_start, column=col_idx).alignment = ws.cell(row=merge_start, column=col_idx).alignment.copy(vertical=\"center\", horizontal=\"center\")\n",
    "            # 更新起點\n",
    "            merge_start = row\n",
    "            current_value = value\n",
    "\n",
    "    wb.save(path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddcde45a",
   "metadata": {},
   "source": [
    "### 確認CPT的機率"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "069ddcef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# parent 組合數\n",
    "q = dfprob_cause.groupby(parent, dropna=False).ngroups\n",
    "assert np.prod([data[col].nunique() for col in parent])==q\n",
    "# 每個 parent 組合底下的機率和都應該 ≈ 1\n",
    "chk = dfprob_cause.groupby(parent, dropna=False)['p'].sum().unique()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ST-RTA",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
