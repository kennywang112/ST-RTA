{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eeb03cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "current_dir = os.getcwd()\n",
    "parent_dir = os.path.dirname(current_dir)\n",
    "analyze_path = os.path.join(parent_dir, \"utils\")\n",
    "\n",
    "os.chdir(analyze_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09d1b50e",
   "metadata": {},
   "source": [
    "要先建立輸入到模型的資料\n",
    "- 若是要分類是否是熱點，應該要以一個區域的grid為單位\n",
    "- 所以建立得grid亦包含該地區的所有特徵資料，以比例顯示"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a2ccdee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['font.family'] = ['Arial Unicode Ms']\n",
    "# plt.rcParams['font.sans-serif'] = ['Microsoft YaHei']\n",
    "\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split, cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, f1_score, recall_score, precision_score\n",
    "from utils_model import eval_loop, to_tensors\n",
    "from utils import read_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e19c72a",
   "metadata": {},
   "source": [
    "## obtain hotspot's county\n",
    "這段使用將grid依照geometry找出個別在哪個城市"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de7952c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "from shapely import wkt\n",
    "\n",
    "combined_data = read_data()\n",
    "TM2 = 3826\n",
    "taiwan = gpd.read_file('../Data/OFiles_9e222fea-bafb-4436-9b17-10921abc6ef2/TOWN_MOI_1140318.shp')\n",
    "taiwan = taiwan[(~taiwan['TOWNNAME'].isin(['旗津區', '頭城鎮', '蘭嶼鄉', '綠島鄉', '琉球鄉'])) & \n",
    "                (~taiwan['COUNTYNAME'].isin(['金門縣', '連江縣', '澎湖縣']))].to_crs(TM2)\n",
    "taiwan_cnty = taiwan[['COUNTYNAME','geometry']].dissolve(by='COUNTYNAME')\n",
    "taiwan_cnty['geometry'] = taiwan_cnty.buffer(0)\n",
    "\n",
    "# 原始以 0.001 grid 計算出的區域事故及對應索引, 依照 hex_grid 計算出來的GI\n",
    "grid_gi_df = pd.read_csv('../ComputedData/Grid/grid_gi.csv')\n",
    "grid_gi_df['accident_indices'] = grid_gi_df['accident_indices'].apply(ast.literal_eval)\n",
    "grid_gi_df['geometry'] = grid_gi_df['geometry'].apply(wkt.loads)\n",
    "\n",
    "grid_gi  = gpd.GeoDataFrame(grid_gi_df, geometry='geometry').set_crs(TM2, allow_override=True)\n",
    "grid_gi['geometry'] = grid_gi.geometry.centroid\n",
    "\n",
    "county_join = gpd.sjoin(grid_gi[['geometry']], taiwan_cnty, how='left', predicate='within')\n",
    "grid_gi['COUNTYNAME'] = county_join['COUNTYNAME']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b478ada",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 這些都是離島資料，因為在taiwan被篩選掉了，所以會因為對應不到所以回傳空值\n",
    "print('NaN ratio:', county_join['COUNTYNAME'].isna().mean())\n",
    "\n",
    "# find all_features at DataPreprocess\n",
    "grid_filter = grid_gi[grid_gi['accident_indices'].str.len() > 0].reset_index()\n",
    "\n",
    "# all_featuresV2 為將離群替換為中位數\n",
    "all_features_df = pd.read_csv(\"../ComputedData/ForModel/all_featuresV2.csv\")\n",
    "\n",
    "# 移除高共線\n",
    "cols = all_features_df.columns[all_features_df.columns.str.contains('事故位置大類別名稱')]\n",
    "cols2 = all_features_df.columns[all_features_df.columns.str.contains('號誌動作')]\n",
    "all_features_df.drop(columns=cols, inplace=True)\n",
    "all_features_df.drop(columns=cols2, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a7ccea5",
   "metadata": {},
   "source": [
    "# Model Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c96d0074",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_grid = pd.concat([grid_filter[['COUNTYNAME']], all_features_df], axis=1)\n",
    "county_dummies = pd.get_dummies(new_grid['COUNTYNAME'], prefix='county')\n",
    "new_grid_encoded = pd.concat([new_grid.drop(['COUNTYNAME'], axis=1), county_dummies], axis=1)\n",
    "\n",
    "# binary hotspot\n",
    "new_grid_encoded['hotspot'] = new_grid_encoded['hotspot'].apply(lambda x: 'Hotspot' if 'Hotspot' in str(x) else 'Not Hotspot')\n",
    "le = LabelEncoder()\n",
    "# y = le.fit_transform(new_grid_encoded['hotspot'])\n",
    "y = new_grid_encoded['hotspot'].map({'Not Hotspot': 0, 'Hotspot': 1}).values\n",
    "X = new_grid_encoded.drop(columns=['hotspot'])\n",
    "\n",
    "# interaction\n",
    "from utils_model import get_interaction\n",
    "X = get_interaction(X)\n",
    "\n",
    "X.drop(columns='original_speed', inplace=True)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, stratify=y, random_state=42\n",
    ")\n",
    "y_train = pd.Series(y_train, index=X_train.index)\n",
    "y_test  = pd.Series(y_test,  index=X_test.index)\n",
    "\n",
    "# undersampling\n",
    "cls_counts = y_test.value_counts()\n",
    "min_count = cls_counts.min()\n",
    "rus_test = RandomUnderSampler(\n",
    "    sampling_strategy={int(c): int(min_count) for c in cls_counts.index},\n",
    "    random_state=42\n",
    ")\n",
    "X_resampled_test, y_resampled_test = rus_test.fit_resample(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2cbf8b3",
   "metadata": {},
   "source": [
    "# LR and RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dd47588",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "\n",
    "# load model\n",
    "lr = joblib.load('../ComputedData/ModelPerformance/lr_modelV4.pkl')\n",
    "\n",
    "proba_test_lr = lr.predict_proba(X_resampled_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21c85676",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils_model import print_results\n",
    "\n",
    "print_results(proba_test_lr, ['Not Hotspot', 'Hotspot'], y_resampled_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "855c8fa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_importance(model, df, specific_col=None):\n",
    "    # The importance doesn't consider interaction terms\n",
    "    if model.__class__.__name__ == 'LogisticRegression':\n",
    "        importances = model.coef_[0]\n",
    "    else:\n",
    "        importances = model.feature_importances_\n",
    "\n",
    "    feature_names = df.columns\n",
    "\n",
    "    if specific_col:\n",
    "        sel_idx = [i for i, name in enumerate(feature_names) if specific_col in name]\n",
    "        indices = np.argsort(importances[sel_idx])[::-1]\n",
    "        indices = [sel_idx[i] for i in indices] # 對應回原始 index\n",
    "    else:\n",
    "        indices = np.argsort(importances)[::-1]\n",
    "\n",
    "    importance_ungrouped = {}\n",
    "    for i in indices:\n",
    "        importance_ungrouped[feature_names[i]] = importances[i]\n",
    "\n",
    "    return importance_ungrouped\n",
    "\n",
    "importance_lr = get_importance(lr, X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c10890b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ts_youbike = pd.DataFrame()\n",
    "for i in importance_lr:\n",
    "    if ('youbike' in i) and 'county' not in i:\n",
    "        # print(i, np.exp(importance_lr[i]))\n",
    "        df_ts_youbike = pd.concat([df_ts_youbike, pd.DataFrame({'feature': [i], \n",
    "        'importance': [importance_lr[i]], 'exp_importance': [np.exp(importance_lr[i])]})], axis=0)\n",
    "\n",
    "df_ts_youbike['feature'] = df_ts_youbike['feature'].str.replace(' x youbike_100m_count_mean', '')\n",
    "df_ts_youbike['feature'] = df_ts_youbike['feature'].str.replace('youbike_100m_count_mean x ', '')\n",
    "df_ts_youbike.sort_values('exp_importance', ascending=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc6a0fb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ts_youbike"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b830b1bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from config import col_translation\n",
    "\n",
    "df_ts_youbike['feature_en'] = df_ts_youbike['feature'].map(col_translation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "930068ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.colors as mcolors\n",
    "\n",
    "df_sorted = df_ts_youbike.sort_values('exp_importance', ascending=True)\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "\n",
    "norm = mcolors.Normalize(vmin=df_sorted['exp_importance'].min(),\n",
    "                         vmax=df_sorted['exp_importance'].max())\n",
    "cmap = cm.get_cmap(\"Greens\")\n",
    "colors = [cmap(norm(val)) for val in df_sorted['exp_importance']]\n",
    "\n",
    "bars = plt.barh(df_sorted['feature'], df_sorted['exp_importance'], color=colors)\n",
    "\n",
    "for bar in bars:\n",
    "    width = bar.get_width()\n",
    "    plt.text(width + 0.02, bar.get_y() + bar.get_height()/2,\n",
    "             f\"{width:.3f}\", va='center', fontsize=9)\n",
    "plt.xlabel('Odds Ratio (Exp(Importance))', fontsize=12)\n",
    "plt.title('LR Youbike Interaction Feature Importance', fontsize=14, weight='bold')\n",
    "plt.grid(axis='x', linestyle='--', alpha=0.6)\n",
    "plt.gca().spines['top'].set_visible(False)\n",
    "plt.gca().spines['right'].set_visible(False)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ST-RTA",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
